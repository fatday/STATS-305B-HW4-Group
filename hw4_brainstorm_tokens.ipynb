{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/fatday/STATS-305B-HW4-Group/blob/main/hw4_brainstorm_tokens.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qZ-AwbZ4ySCJ"
      },
      "source": [
        "## Setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "_5IXGh6OOBZV"
      },
      "outputs": [],
      "source": [
        "# torch imports\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "from tqdm import tqdm\n",
        "import requests\n",
        "import os\n",
        "\n",
        "torch.manual_seed(305)\n",
        "\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fsgHl9JCuGBS"
      },
      "source": [
        "We set default values for some global hyperparameters, but feel free to change these during development as needed."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "A_Z5Jh74DH_E"
      },
      "outputs": [],
      "source": [
        "# Global hyperparameters\n",
        "SMALL_ITERS = 1000\n",
        "LARGE_ITERS = 2000\n",
        "EVAL_ITERS = 100\n",
        "CONTEXT_WINDOW_SIZE = 256"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "53dGz7ExDkUv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4042427f-5dd4-4618-cec4-f15cf2643760"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "length of dataset in characters: 1,115,394\n"
          ]
        }
      ],
      "source": [
        "# download the tiny shakespeare dataset\n",
        "input_file_path = 'input.txt'\n",
        "\n",
        "if not os.path.exists(input_file_path):\n",
        "    data_url = 'https://raw.githubusercontent.com/karpathy/char-rnn/master/data/tinyshakespeare/input.txt'\n",
        "    with open(input_file_path, 'w') as f:\n",
        "        f.write(requests.get(data_url).text)\n",
        "\n",
        "with open(input_file_path, 'r') as f:\n",
        "    data = f.read()\n",
        "print(f\"length of dataset in characters: {len(data):,}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "b2HuC2F9p_4K"
      },
      "outputs": [],
      "source": [
        "import re\n",
        "data_words = re.findall(r'\\w+|\\s+|[^\\w\\s]', data)\n",
        "vocabs_set = sorted(list(set(data_words).union(set(data))))\n",
        "vocab_size = len(vocabs_set)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "JEWx5jnKqDzT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b68f3b50-d82e-49ef-87b8-090503a2b660"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train has 419,020 tokens\n",
            "val has 46,558 tokens\n"
          ]
        }
      ],
      "source": [
        "# create a mapping from characters to integers\n",
        "stoi = { ch:i for i,ch in enumerate(vocabs_set) }\n",
        "itos = { i:ch for i,ch in enumerate(vocabs_set) }\n",
        "\n",
        "def encode(s):\n",
        "    return [stoi[c] for c in s] # encoder: take a string, output a list of integers\n",
        "def decode(l):\n",
        "    return ''.join([itos[i] for i in l]) # decoder: take a list of integers, output a string\n",
        "\n",
        "# create the train and test splits\n",
        "n = len(data)\n",
        "m = len(data_words)\n",
        "train_chars = data_words[:int(m*0.9)]\n",
        "val_chars = data_words[int(m*0.9):]\n",
        "\n",
        "# encode both to integers\n",
        "train_data = encode(train_chars)\n",
        "val_data = encode(val_chars)\n",
        "\n",
        "# cast as torch tensors\n",
        "train_data = torch.tensor(train_data)\n",
        "val_data = torch.tensor(val_data)\n",
        "\n",
        "print(f\"train has {len(train_data):,} tokens\")\n",
        "print(f\"val has {len(val_data):,} tokens\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "2RXhRQRZdDYu"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "O_eBPiT-Yy0q"
      },
      "outputs": [],
      "source": [
        "class Head(nn.Module):\n",
        "    \"\"\" one head of self-attention \"\"\"\n",
        "\n",
        "    def __init__(self, head_size, context_window_size, embed_size=384):\n",
        "        \"\"\"\n",
        "        Args:\n",
        "          head_size: int, size of the head embedding dimension (K)\n",
        "          context_window_size: int, number of tokens considered in the past for attention (T)\n",
        "          embed_size: int, size of the token embedding dimension (D)\n",
        "        \"\"\"\n",
        "        super().__init__()\n",
        "        self.head_size = head_size\n",
        "        self.key = nn.Linear(embed_size, head_size, bias=False)\n",
        "        self.query = nn.Linear(embed_size, head_size, bias=False)\n",
        "        self.value = nn.Linear(embed_size, embed_size, bias=False)\n",
        "\n",
        "        # not a param of the model, so registered as a buffer\n",
        "        self.register_buffer('tril', torch.tril(\n",
        "            torch.ones(context_window_size, context_window_size)))\n",
        "\n",
        "    def forward(self, x):\n",
        "        \"\"\"\n",
        "        Args:\n",
        "          x: (B,T,D) tensor of token embeddings\n",
        "\n",
        "        Returns:\n",
        "          (B,T,D) tensor of attention-weighted token embeddings\n",
        "        \"\"\"\n",
        "        # TODO: your code here\n",
        "        B,T,D = x.shape\n",
        "        k = self.key(x)\n",
        "        q = self.query(x)\n",
        "        v = self.value(x)\n",
        "        wei = q @ k.transpose(-2,-1) * self.head_size**-0.5\n",
        "        #tril = torch.tril(torch.ones(T, T, device=x.device))\n",
        "        wei = wei.masked_fill(self.tril[:T, :T] == 0, float('-inf'))\n",
        "        wei = F.softmax(wei, dim=-1)  ## wei.shape:\n",
        "        out = wei @ v\n",
        "        return out"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "REr3aWnS1xJL"
      },
      "outputs": [],
      "source": [
        "class SingleHeadedAttentionLM(nn.Module):\n",
        "\n",
        "    def __init__(self, vocab_size, context_window_size, head_size, embed_size=384):\n",
        "      \"\"\"\n",
        "      Args:\n",
        "        vocab_size: int, size of the vocabulary (V)\n",
        "        context_window_size: int, number of tokens considered in the past for attention (T)\n",
        "        head_size: int, size of the head embedding dimension (K)\n",
        "        embed_size: int, size of the token embedding dimension (D)\n",
        "      \"\"\"\n",
        "      super().__init__()\n",
        "      self.token_embedding_table = nn.Embedding(vocab_size, embed_size)\n",
        "      self.position_embedding_table = nn.Embedding(context_window_size, embed_size)\n",
        "      self.context_window_size = context_window_size\n",
        "\n",
        "      # TODO: your code below\n",
        "      self.atten_head = Head(head_size, context_window_size)\n",
        "      self.lm_head = nn.Linear(embed_size, vocab_size)\n",
        "      self.context_window_size = context_window_size\n",
        "\n",
        "    def forward(self, token_ids, targets=None):\n",
        "        \"\"\"\n",
        "        Args:\n",
        "          token_ids: (B, T) token ids that make up the context (batch has size B, each entry\n",
        "                     in the batch has length T)\n",
        "          targets: (B, T) token ids corresponding to the target of each context in token_ids\n",
        "\n",
        "        Returns:\n",
        "          logits: (B, T, V) logits[b,t] gives the length V vector of logits for the next token\n",
        "                   prediction in string b up to t tokens\n",
        "          loss: scalar, negative log likelihood of target given context\n",
        "        \"\"\"\n",
        "        B, T = token_ids.shape # (batch size, length)\n",
        "        tok_emb = self.token_embedding_table(token_ids) # (B,T,D)\n",
        "        pos_emb = self.position_embedding_table(torch.arange(T, device=device)) # (T,D)\n",
        "        x = tok_emb + pos_emb # (B,T,D)\n",
        "        x = self.atten_head(x) # (B,T,D)\n",
        "        logits = self.lm_head(x) # (B,T,V)\n",
        "\n",
        "        # TODO: your code here\n",
        "        B, T, V = logits.shape\n",
        "        logits = logits.view(B*T, V)\n",
        "        if targets is None:\n",
        "            loss = None\n",
        "        else:\n",
        "            targets = targets.view(B*T)\n",
        "            loss = -torch.mean(torch.log(F.softmax(logits, dim=1)[torch.arange(B*T), targets]))\n",
        "        return logits, loss\n",
        "\n",
        "    @torch.no_grad()\n",
        "    def generate(self, token_ids, max_new_tokens):\n",
        "        \"\"\"\n",
        "        Args:\n",
        "          token_ids: (B, T) tensor of token ids to provide as context\n",
        "          max_new_tokens: int, maximum number of new tokens to generate\n",
        "\n",
        "        Returns:\n",
        "          (B, T+max_new_tokens) tensor of context with new tokens appended\n",
        "        \"\"\"\n",
        "        #TODO\n",
        "        # your code below\n",
        "        B, T = token_ids.shape\n",
        "        new_token_sequences = torch.zeros((B, T+max_new_tokens), dtype=torch.long, device=token_ids.device)\n",
        "        new_token_sequences[:, :T] = token_ids\n",
        "        for t in range(max_new_tokens):\n",
        "          input_tokens = new_token_sequences[:, max(0, T + t - self.context_window_size): T + t]\n",
        "          logits, loss = self(input_tokens)\n",
        "          logits = logits.view(B, min(T + t, self.context_window_size), -1)\n",
        "          logits = logits[:, -1, :]\n",
        "          probs = F.softmax(logits, dim=-1)\n",
        "          new_token = torch.multinomial(probs, num_samples=1)\n",
        "          new_token_sequences[:, T + t] = new_token.squeeze(-1)\n",
        "        return new_token_sequences"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "6vb8NU_s6Vfg"
      },
      "outputs": [],
      "source": [
        "\n",
        "class MultiHeadAttention(nn.Module):\n",
        "    def __init__(self, context_window_size, num_heads, embed_size):\n",
        "        super().__init__()\n",
        "        self.num_heads = num_heads\n",
        "        self.head_size = embed_size // num_heads  # 确保总维度匹配\n",
        "\n",
        "        self.heads = nn.ModuleList(\n",
        "            [Head(self.head_size, context_window_size, embed_size) for _ in range(num_heads)]\n",
        "        )\n",
        "        self.proj = nn.Linear(embed_size * num_heads, embed_size)  # 确保总维度匹配\n",
        "        self.dropout = nn.Dropout(0.1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = torch.cat([h(x) for h in self.heads], dim=-1)  # 拼接 heads\n",
        "\n",
        "        out = self.dropout(self.proj(out))  # 投影回 embed_size\n",
        "        return out\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "LvWHwcCzI1yr"
      },
      "outputs": [],
      "source": [
        "class MultiHeadedAttentionLM(nn.Module):\n",
        "\n",
        "    def __init__(self, vocab_size, context_window_size, embed_size=384, num_heads=6):\n",
        "      super().__init__()\n",
        "      self.head_size = embed_size // num_heads\n",
        "      self.context_window_size = context_window_size\n",
        "      # TODO: your code below\n",
        "      self.token_embedding_table = nn.Embedding(vocab_size, embed_size)\n",
        "      self.position_embedding_table = nn.Embedding(context_window_size, embed_size)\n",
        "      self.atten_heads = MultiHeadAttention(context_window_size, num_heads, embed_size)\n",
        "      self.lm_head = nn.Linear(embed_size, vocab_size)\n",
        "\n",
        "\n",
        "    def forward(self, token_ids, targets=None):\n",
        "        \"\"\"\n",
        "        Args:\n",
        "          token_ids: (B, T) token ids that make up the context (batch has size B, each entry in the\n",
        "                     batch has length T)\n",
        "          targets: (B, T) token ids corresponding to the target of each context in token_ids\n",
        "\n",
        "        Returns:\n",
        "          logits: (B, T, V), logits[b,t] gives the length V vector of logits for the next token\n",
        "                  prediction in string b up to t tokens\n",
        "          loss: scalar, negative log likelihood of target given context\n",
        "        \"\"\"\n",
        "        # TODO: your code below\n",
        "        B, T = token_ids.shape\n",
        "        tok_emb = self.token_embedding_table(token_ids)\n",
        "        pos_emb = self.position_embedding_table(torch.arange(T, device=device))\n",
        "        x = tok_emb + pos_emb\n",
        "        x = self.atten_heads(x)\n",
        "        logits = self.lm_head(x)\n",
        "        if targets is None:\n",
        "            loss = None\n",
        "        else:\n",
        "            logits = logits.view(B*T, -1)\n",
        "            targets = targets.view(B*T)\n",
        "            loss = -torch.mean(torch.log(F.softmax(logits, dim=1)[torch.arange(B*T), targets]))\n",
        "\n",
        "        return logits, loss\n",
        "\n",
        "    @torch.no_grad()\n",
        "    def generate(self, token_ids, max_new_tokens):\n",
        "        \"\"\"\n",
        "        Args:\n",
        "          token_ids: (B, T) tensor of token ids to provide as context\n",
        "          max_new_tokens: int, maximum number of new tokens to generate\n",
        "\n",
        "        Returns:\n",
        "          (B, T+max_new_tokens) tensor of context with new tokens appended\n",
        "        \"\"\"\n",
        "        # TODO: your code below\n",
        "        B, T = token_ids.shape\n",
        "        new_token_sequences = torch.zeros((B, T+max_new_tokens), dtype=torch.long, device=token_ids.device)\n",
        "        new_token_sequences[:, :T] = token_ids\n",
        "        for t in range(max_new_tokens):\n",
        "          input_tokens = new_token_sequences[:, max(0, T + t - self.context_window_size): T + t]\n",
        "          logits, loss = self(input_tokens)\n",
        "          logits = logits.view(B,min(T + t, self.context_window_size), -1)\n",
        "          logits = logits[:, -1, :]\n",
        "          probs = F.softmax(logits, dim=-1)\n",
        "          new_token = torch.multinomial(probs, num_samples=1)\n",
        "          new_token_sequences[:, T + t] = new_token.squeeze(-1)\n",
        "        return new_token_sequences"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "1GbGqwKWJzOK"
      },
      "outputs": [],
      "source": [
        "# run this cell to initialize this deep learning module that you should use in the code your write later\n",
        "# you don't need to edit this layer\n",
        "class FeedForward(nn.Module):\n",
        "    \"\"\" a simple linear layer followed by a non-linearity\n",
        "        Given to you, you don't need to write any code here!\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, embed_size):\n",
        "        super().__init__()\n",
        "        self.net = nn.Sequential(\n",
        "            nn.Linear(embed_size, 4 * embed_size),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(4 * embed_size, embed_size),\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.net(x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "hUDbIv9eISkf"
      },
      "outputs": [],
      "source": [
        "class TransformerBlock(nn.Module):\n",
        "    \"\"\" Transformer block: communication across sequence length, followed by communication across embedding space\n",
        "        Uses multi-headed attention\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, vocab_size, context_window_size, embed_size=384, num_heads=6, dropout = 0.2):\n",
        "        super().__init__()\n",
        "        self.ln1 = nn.LayerNorm(embed_size)\n",
        "        self.ln2 = nn.LayerNorm(embed_size)\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "        # TODO: your code below\n",
        "        self.feed_forward = FeedForward(embed_size)\n",
        "        self.atten_heads = MultiHeadAttention(context_window_size, num_heads, embed_size)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = x + self.atten_heads(self.ln1(x)) # communication over sequence length\n",
        "        x = x + self.feed_forward(self.ln2(x)) # communication across embedding space\n",
        "        return x"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class TransformerLM(nn.Module):\n",
        "\n",
        "    def __init__(self, vocab_size, context_window_size, embed_size=384,\n",
        "                 num_heads=6, n_layers=6, dropout=0.2):\n",
        "        \"\"\"\n",
        "          Args:\n",
        "              vocab_size: int, number of tokens in the vocabulary (V)\n",
        "              context_window_size: int, size of the context window (T)\n",
        "              embed_size: int, embedding size (D)\n",
        "              num_heads: int, number of heads (H)\n",
        "              n_layers: int, number of layers (M)\n",
        "        \"\"\"\n",
        "        super().__init__()\n",
        "        self.token_embedding_table = nn.Embedding(vocab_size, embed_size)\n",
        "        self.position_embedding_table = nn.Embedding(context_window_size, embed_size)\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "        self.blocks = nn.Sequential(*[\n",
        "            TransformerBlock(vocab_size,\n",
        "                             context_window_size,\n",
        "                             embed_size=embed_size,\n",
        "                             num_heads=num_heads,\n",
        "                             dropout=dropout)\n",
        "            for _ in range(n_layers)])\n",
        "\n",
        "        # final layer norm\n",
        "\n",
        "        self.ln_f = nn.LayerNorm(embed_size)\n",
        "        self.lm_head = nn.Linear(embed_size, vocab_size)\n",
        "        self.context_window_size = context_window_size\n",
        "\n",
        "        # good initialization\n",
        "        self.apply(self._init_weights)\n",
        "\n",
        "    def _init_weights(self, module):\n",
        "        if isinstance(module, nn.Linear):\n",
        "            torch.nn.init.normal_(module.weight, mean=0.0, std=0.02)\n",
        "            if module.bias is not None:\n",
        "                torch.nn.init.zeros_(module.bias)\n",
        "        elif isinstance(module, nn.Embedding):\n",
        "            torch.nn.init.normal_(module.weight, mean=0.0, std=0.02)\n",
        "\n",
        "    def forward(self, token_ids, targets=None):\n",
        "        \"\"\"\n",
        "        Agrgs:\n",
        "            token_ids: tensor of integers, provides the contet, shape (B, T)\n",
        "            targets: tensor of integers, provides the tokens we are preidcitng, shape (B, T)\n",
        "        \"\"\"\n",
        "        B, T = token_ids.shape\n",
        "\n",
        "        # token_ids and targets are both (B, T) tensor of integers\n",
        "        tok_emb = self.token_embedding_table(token_ids) # (B, T, D)\n",
        "        pos_emb = self.position_embedding_table(torch.arange(T, device=device)) # (T, D)\n",
        "        x = tok_emb + pos_emb # (B, T, D)\n",
        "\n",
        "        # TODO: your code below\n",
        "        logits = ...\n",
        "        loss = ...\n",
        "\n",
        "        x = self.blocks(x)\n",
        "        x = self.ln_f(x)\n",
        "        logits = self.lm_head(x)\n",
        "\n",
        "        B, T, V = logits.shape\n",
        "        logits = logits.view(B*T, V)\n",
        "\n",
        "        if targets is None:\n",
        "            loss = None\n",
        "        else:\n",
        "            targets = targets.view(B*T)\n",
        "            loss = F.cross_entropy(logits, targets)\n",
        "\n",
        "        return logits, loss\n",
        "\n",
        "    @torch.no_grad()\n",
        "    def generate(self, token_ids, max_new_tokens):\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            token_ids: tensor of integers forming the context, shape (B, T)\n",
        "            max_new_tokens: int, max number of tokens to generate\n",
        "        \"\"\"\n",
        "        # TOOD, your code below\n",
        "        B, T = token_ids.shape\n",
        "        context_length = self.position_embedding_table.num_embeddings\n",
        "        new_token_sequences = torch.zeros((B, T+max_new_tokens), dtype=torch.long, device=token_ids.device)\n",
        "        new_token_sequences[:, :T] = token_ids\n",
        "        for t in range(max_new_tokens):\n",
        "            input_tokens = new_token_sequences[:, max(0,T + t - context_length):T + t]\n",
        "            logits, loss = self(input_tokens)\n",
        "            logits = logits.view(B,min(T + t, self.context_window_size), -1)\n",
        "            logits = logits[:, -1, :] # (B, V)\n",
        "            probs = F.softmax(logits, dim=-1) # (B, V)\n",
        "            new_token = torch.multinomial(probs, num_samples=1) # (B, 1)\n",
        "            new_token_sequences[:, T + t] = new_token.squeeze(-1) # (B, T+1)\n",
        "        return new_token_sequences"
      ],
      "metadata": {
        "id": "BhPDnwB7dd0A"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# function for getting batches of data\n",
        "def get_batch(split, context_window_size, device, batch_size=32):\n",
        "    \"\"\"\n",
        "    generate a small batch of data of inputs x and targets y\n",
        "\n",
        "    Args:\n",
        "        split: 'train' or 'val'\n",
        "        device: 'cpu' or 'cuda' (should be 'cuda' if available)\n",
        "    \"\"\"\n",
        "    data = train_data if split == 'train' else val_data\n",
        "    ix = torch.randint(len(data) - context_window_size, (batch_size,))\n",
        "    x = torch.stack([data[i:i+context_window_size] for i in ix])\n",
        "    y = torch.stack([data[i+1:i+context_window_size+1] for i in ix])\n",
        "    x = x.to(device)\n",
        "    y = y.to(device)\n",
        "    return x, y\n",
        "\n",
        "# helper function for tracking loss during training\n",
        "# given to you\n",
        "@torch.no_grad()\n",
        "def estimate_loss(model, eval_iters, context_window_size, device):\n",
        "    \"\"\"\n",
        "    Args:\n",
        "      model: model being evaluated\n",
        "      eval_iters: number of batches to average over\n",
        "      context_window_size: size of the context window\n",
        "      device: 'cpu' or 'cuda' (should be 'cuda' if available)\n",
        "    \"\"\"\n",
        "    out = {}\n",
        "    for split in ['train', 'val']:\n",
        "        losses = torch.zeros(eval_iters)\n",
        "        for k in range(eval_iters):\n",
        "            X, Y = get_batch(split, context_window_size, device)\n",
        "            logits, loss = model(X, Y)\n",
        "            losses[k] = loss.item()\n",
        "        out[split] = losses.mean()\n",
        "    return out"
      ],
      "metadata": {
        "id": "3QFPI8vVou6h"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JP8430nWKbZ6"
      },
      "source": [
        "Train your `TransformerLM` for `LARGE_ITERS` iterations and plot the loss curve. You may want to change the learning rate.\n",
        "\n",
        "We used a learning rate of `1e-4` and got to a final train loss of around 1.4 in around 15 minutes of training on a T4 GPU."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "jsnbDpdhLeKo",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4f1bd6e5-d2c4-4afc-f41e-de97ff90dd1f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/3000 [00:00<?, ?it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "iteration 0\n",
            "step 0: train loss 9.4975, val loss 9.5035\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  7%|▋         | 200/3000 [00:44<07:44,  6.02it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "iteration 200\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  7%|▋         | 201/3000 [00:55<2:38:41,  3.40s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "step 200: train loss 5.1048, val loss 5.2019\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 13%|█▎        | 400/3000 [01:28<07:07,  6.08it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "iteration 400\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 13%|█▎        | 401/3000 [01:39<2:27:15,  3.40s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "step 400: train loss 4.2150, val loss 4.3187\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 20%|██        | 600/3000 [02:12<06:36,  6.06it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "iteration 600\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 20%|██        | 601/3000 [02:23<2:16:00,  3.40s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "step 600: train loss 3.8157, val loss 3.9533\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 27%|██▋       | 800/3000 [02:56<06:02,  6.07it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "iteration 800\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 27%|██▋       | 801/3000 [03:07<2:04:34,  3.40s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "step 800: train loss 3.6351, val loss 3.7825\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 33%|███▎      | 1000/3000 [03:40<05:30,  6.05it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "iteration 1000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 33%|███▎      | 1001/3000 [03:50<1:53:16,  3.40s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "step 1000: train loss 3.5264, val loss 3.6841\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 40%|████      | 1200/3000 [04:23<04:57,  6.05it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "iteration 1200\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 40%|████      | 1201/3000 [04:34<1:42:02,  3.40s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "step 1200: train loss 3.4605, val loss 3.6332\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 47%|████▋     | 1400/3000 [05:07<04:24,  6.06it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "iteration 1400\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 47%|████▋     | 1401/3000 [05:18<1:30:38,  3.40s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "step 1400: train loss 3.4132, val loss 3.6002\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 53%|█████▎    | 1600/3000 [05:51<03:51,  6.06it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "iteration 1600\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 53%|█████▎    | 1601/3000 [06:02<1:19:12,  3.40s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "step 1600: train loss 3.3808, val loss 3.5683\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 60%|██████    | 1800/3000 [06:35<03:17,  6.06it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "iteration 1800\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 60%|██████    | 1801/3000 [06:46<1:07:58,  3.40s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "step 1800: train loss 3.3484, val loss 3.5506\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 67%|██████▋   | 1999/3000 [07:19<02:45,  6.05it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "iteration 1999\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 67%|██████▋   | 2000/3000 [07:29<56:36,  3.40s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "step 1999: train loss 3.3338, val loss 3.5308\n",
            "iteration 2000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 67%|██████▋   | 2001/3000 [07:40<1:34:13,  5.66s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "step 2000: train loss 3.3290, val loss 3.5337\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 73%|███████▎  | 2200/3000 [08:13<02:11,  6.06it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "iteration 2200\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 73%|███████▎  | 2201/3000 [08:24<45:13,  3.40s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "step 2200: train loss 3.3142, val loss 3.5161\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 80%|████████  | 2400/3000 [08:57<01:39,  6.04it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "iteration 2400\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 80%|████████  | 2401/3000 [09:08<33:54,  3.40s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "step 2400: train loss 3.2899, val loss 3.5170\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 87%|████████▋ | 2600/3000 [09:41<01:05,  6.08it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "iteration 2600\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 87%|████████▋ | 2601/3000 [09:52<22:34,  3.39s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "step 2600: train loss 3.2686, val loss 3.4962\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 93%|█████████▎| 2800/3000 [10:25<00:33,  6.04it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "iteration 2800\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 93%|█████████▎| 2801/3000 [10:36<11:15,  3.40s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "step 2800: train loss 3.2426, val loss 3.4759\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 3000/3000 [11:09<00:00,  4.48it/s]\n"
          ]
        }
      ],
      "source": [
        "trans = TransformerLM(vocab_size, context_window_size=256,\n",
        "                      embed_size=512, num_heads=6, n_layers=6, dropout= 0.2)\n",
        "tlm = trans.to(device)\n",
        "learning_rate = 1e-5\n",
        "# TODO, your code below\n",
        "\n",
        "optimizer = torch.optim.AdamW(trans.parameters(), lr=learning_rate, weight_decay=0.1)\n",
        "\n",
        "eval_interval = 200\n",
        "\n",
        "loss_list = []\n",
        "\n",
        "for it in tqdm(range(LARGE_ITERS+1000)):\n",
        "\n",
        "    # every once in a while evaluate the loss on train and val sets\n",
        "    if it % eval_interval == 0 or it == LARGE_ITERS - 1:\n",
        "      print(f\"iteration {it}\")\n",
        "      losses = estimate_loss(tlm, EVAL_ITERS, CONTEXT_WINDOW_SIZE, device)\n",
        "      print(f\"step {it}: train loss {losses['train']:.4f}, val loss {losses['val']:.4f}\")\n",
        "\n",
        "    # sample a batch of data\n",
        "    xb, yb = get_batch('train', CONTEXT_WINDOW_SIZE, device)\n",
        "\n",
        "    # evaluate the loss\n",
        "    logits, loss = tlm(xb, yb)\n",
        "    loss_list.append(loss.detach().item())\n",
        "    optimizer.zero_grad(set_to_none=True)\n",
        "    loss.backward()\n",
        "    optimizer.step()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## plot the loss_curve\n",
        "plt.plot(loss_list)\n",
        "plt.xlabel('Iteration')\n",
        "plt.ylabel('Loss')\n",
        "plt.title('Loss Curve')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "6-mnwj48rgMX",
        "outputId": "c9fc9f1a-4d44-4b3f-c1f0-3412b8f46af5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 472
        }
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1SYG_iDFSNys"
      },
      "source": [
        "#### Question 1.4.3: Generating text!\n",
        "\n",
        "Now with our trained model, we can generate some text that is somewhat like the style of Shakespeare! Below we will do both unconditional and conditional generation."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "-FX-eEZEDH-n",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4bf2daf1-3f1a-4549-ef7e-382505e7b104"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "ButHASTINGS, rivals I leave noble you, me will Earl not but well:\n",
            "You a us girls.\n",
            "\n",
            "HASTINGS:\n",
            "VOLUMNIA: married was friar his born provost! thenThen,-\n",
            "\n",
            "DUKE guiltless VINCENTIO:\n",
            "Why, thou be take back to Moreover,\n",
            "Even a serpents been denied forgive.\n",
            "\n",
            "Gardener:\n",
            "O full spirits 'll in villain,\n",
            "And to more a thee be her rest himown break obtain\n",
            "As mewhen come the the of not boy.\n",
            "Were Sinon, days GREY!\n",
            "\n",
            "FRIAR this:\n",
            "spoil but a will he have put profound did Sorrow fashions full father.\n",
            "They all as example the both meetadvice!\n",
            "posterity, sobs, award man to hath more our field\n",
            "distance! how shows cut know due Despite pilot keepnot woman'tis\n"
          ]
        }
      ],
      "source": [
        "# unconditional generation from the model\n",
        "start_context = torch.zeros((1, 1), dtype=torch.long, device=device)\n",
        "uncond_gen = (tlm.generate(start_context, max_new_tokens=CONTEXT_WINDOW_SIZE)[0].tolist())\n",
        "print(decode(uncond_gen))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "73du7-sWLH5c"
      },
      "outputs": [],
      "source": [
        "# conditional generation from the model\n",
        "\n",
        "context1 = \"\"\"ROMEO:\n",
        "He jests at scars that never felt a wound.\n",
        "But, soft! what light through yonder window breaks?\n",
        "It is the east, and Juliet is the sun.\n",
        "Arise, fair sun, and kill the envious moon,\n",
        "Who is already sick and pale with grief,\n",
        "That thou her maid art far more fair than she:\n",
        "Be not her maid, \"\"\"\n",
        "\n",
        "context1_tokens = torch.tensor(encode(context1), device=device).reshape(1, -1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "sZ4zkEJzMNA4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5b575f48-a1a4-4aef-d8cb-586740817e15"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ROMEO:\n",
            "He jests at scars that never felt a wound.\n",
            "But, soft! what light through yonder window breaks?\n",
            "It is the east, and Juliet is the sun.\n",
            "Arise, fair sun, and kill the envious moon,\n",
            "Who is already sick and pale with grief,\n",
            "That thou her maid art far more fair than she:\n",
            "Be not her maid, shame,loud make benefit\n",
            "businesses deliver them runs what to frame vaultIs long,\n",
            "held aught and fight; as now,\n",
            "I kill, revenged farewell, wasteful in been her:\n",
            "But, little we and make dedicate aching yet bed.\n",
            "Thou his the be like dedication,\n",
            "A that budge thou my the like come kindred doth lastly:\n",
            "With say rest brake a my of this\n",
            "Which ballad, they to wound with solemn this one;\n",
            "Art he speak with buildeth our comfort Tullus be:\n",
            "Than I to danger will newly I shall soldiers:\n",
            "Show your coming colour's theean: ten tell all vices;\n",
            "To shall one charitable purest flag soprivileges:\n",
            "What, in his 'd there as dismal nurse,\n",
            "That with writ general\n"
          ]
        }
      ],
      "source": [
        "cond_gen = (tlm.generate(context1_tokens, max_new_tokens=CONTEXT_WINDOW_SIZE)[0].tolist())\n",
        "print(decode(cond_gen))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HdA0IXMh15cc"
      },
      "source": [
        "TODO: Choose your own context from Shakespeare, and perform conditional generation from that text. Does this look reasonable to you? Why or why not?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "id": "cR_0hrAO2Am_"
      },
      "outputs": [],
      "source": [
        "# TODO: your code here\n",
        "my_text_con = \"\"\"First Citizen:\n",
        "Care for us! True, indeed! They ne'er cared for us\n",
        "yet: suffer us to famish, and their store-houses\n",
        "crammed with grain; make edicts for usury, to\n",
        "support usurers; repeal daily any wholesome act\n",
        "established against the rich, and provide more\n",
        "piercing statutes daily, to chain up and restrain\n",
        "the poor. If the wars eat us not up, they will; and\n",
        "there's all the love they bear us.\n",
        "\"\"\"\n",
        "\n",
        "my_text_target = \"\"\"MENENIUS: Either you must Confess yourselves wondrous malicious,\n",
        "Or be accused of folly. I shall tell you\n",
        "A pretty tale: it may be you have heard it;\n",
        "But, since it serves my purpose, I will venture\n",
        "To stale 't a little more.\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cond_text_token = encode(my_text_con)\n",
        "target_text_token = encode(my_text_target)\n",
        "\n",
        "# transfer back to text\n",
        "target_text_token_size = len(target_text_token)\n",
        "cond_text_token_size = len(cond_text_token)\n",
        "\n",
        "# transfer to torch\n",
        "cond_text_tokens = torch.tensor(cond_text_token, device=device).reshape(1, -1)"
      ],
      "metadata": {
        "id": "w1I9p9MalOnZ"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# My Input Text:"
      ],
      "metadata": {
        "id": "5-886_tYpf39"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(my_text_con)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xcoJe3v3ptnX",
        "outputId": "d95046a7-8f0d-4fb4-9e88-9d4c04b9803e"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "First Citizen:\n",
            "Care for us! True, indeed! They ne'er cared for us\n",
            "yet: suffer us to famish, and their store-houses\n",
            "crammed with grain; make edicts for usury, to\n",
            "support usurers; repeal daily any wholesome act\n",
            "established against the rich, and provide more\n",
            "piercing statutes daily, to chain up and restrain\n",
            "the poor. If the wars eat us not up, they will; and\n",
            "there's all the love they bear us.\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Target Text"
      ],
      "metadata": {
        "id": "kmlyABuinXhQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(my_text_con + \"\\n\" + my_text_target)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6Zqtb7zinayj",
        "outputId": "dbd97c3d-9022-4167-bdf7-f07b4fb0da49"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "First Citizen:\n",
            "Care for us! True, indeed! They ne'er cared for us\n",
            "yet: suffer us to famish, and their store-houses\n",
            "crammed with grain; make edicts for usury, to\n",
            "support usurers; repeal daily any wholesome act\n",
            "established against the rich, and provide more\n",
            "piercing statutes daily, to chain up and restrain\n",
            "the poor. If the wars eat us not up, they will; and\n",
            "there's all the love they bear us.\n",
            "\n",
            "MENENIUS: Either you must Confess yourselves wondrous malicious,\n",
            "Or be accused of folly. I shall tell you\n",
            "A pretty tale: it may be you have heard it;\n",
            "But, since it serves my purpose, I will venture\n",
            "To stale 't a little more.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Text Generated for Target"
      ],
      "metadata": {
        "id": "6Iy5f84FsCwv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "my_tar_gen = (tlm.generate(cond_text_tokens, max_new_tokens=target_text_token_size)[0].tolist())\n",
        "my_target_gen_text = decode(my_tar_gen)\n",
        "print(my_target_gen_text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CL5AG4ddlx2U",
        "outputId": "b5b6010a-ae96-4b4f-e020-140a57e59ece"
      },
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "First Citizen:\n",
            "Care for us! True, indeed! They ne'er cared for us\n",
            "yet: suffer us to famish, and their store-houses\n",
            "crammed with grain; make edicts for usury, to\n",
            "support usurers; repeal daily any wholesome act\n",
            "established against the rich, and provide more\n",
            "piercing statutes daily, to chain up and restrain\n",
            "the poor. If the wars eat us not up, they will; and\n",
            "there's all the love they bear us.\n",
            "\n",
            "MENENIUS: Either you must\n",
            "solemn pardon, I flight'sbowels me for'swidens toIt eyes.\n",
            "bear sir arm'fardel, not I forty ancestry\n",
            "Not rest he sun wilderness, sister:\n",
            "And truly spirit past here present:\n",
            "You skirts all me would in me;\n",
            "In war you, not drunkard to ignorant?\n",
            "I let should revive not not findings:\n",
            "When shall amongst this less'd now I fair wakes,\n",
            "Your worthy said Elbow's his deed died,\n",
            "Of is misery shall and my me live our poor\n",
            "How bandying matter souls dust, friends,\n",
            "He have must religious out, \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "intput = \"\"\"\n",
        "GONZALO:\n",
        "That our garments, being, as they were, drenched in\n",
        "the sea, hold notwithstanding their freshness and\n",
        "glosses, being rather new-dyed than stained with\n",
        "salt water.\n",
        "\n",
        "ANTONIO:\n",
        "If but one of his pockets could speak, would it not\n",
        "say he lies?\n",
        "\n",
        "SEBASTIAN:\n",
        "Ay, or very falsely pocket up his report.\n",
        "\"\"\"\n",
        "\n",
        "output = \"\"\"\n",
        "GONZALO:\n",
        "Methinks our garments are now as fresh as when we\n",
        "put them on first in Afric, at the marriage of\n",
        "the king's fair daughter Claribel to the King of Tunis.\n",
        "\n",
        "SEBASTIAN:\n",
        "'Twas a sweet marriage, and we prosper well in our return.\n",
        "\n",
        "ADRIAN:\n",
        "Tunis was never graced before with such a paragon to\n",
        "their queen.\n",
        "\n",
        "GONZALO:\n",
        "Not since widow Dido's time.\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "bOhOsySs0o6e"
      },
      "execution_count": 74,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "intput_tokens = torch.tensor(encode(intput), device=device).reshape(1, -1)"
      ],
      "metadata": {
        "id": "gyl2m0Rf0z5D"
      },
      "execution_count": 75,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "output_token = (tlm.generate(intput_tokens, max_new_tokens=target_text_token_size)[0].tolist())\n",
        "output_text = decode(output_token)\n",
        "print(output_text)"
      ],
      "metadata": {
        "id": "cr-Copkh1Epy",
        "outputId": "b0e91bd7-540c-49c8-f8f2-b839622d0c06",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 77,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "GONZALO:\n",
            "That our garments, being, as they were, drenched in\n",
            "the sea, hold notwithstanding their freshness and\n",
            "glosses, being rather new-dyed than stained with\n",
            "salt water.\n",
            "\n",
            "ANTONIO:\n",
            "If but one of his pockets could speak, would it not\n",
            "say he lies?\n",
            "\n",
            "SEBASTIAN:\n",
            "Ay, or very falsely pocket up his report.\n",
            "attends know I unfeigned this what Jack taketh I sue,\n",
            "what movehousekeeping sayest Tranio, our what this:\n",
            "I my gorged'cerns not think with bear and my the by to another.\n",
            "\n",
            "Stay.\n",
            "\n",
            "GLOUCESTER:\n",
            "I oracle, call I retire speak:\n",
            "dare my am maidens from Gremio;\n",
            "As eye but tongue predecessors mother's good,JULIET:\n",
            "A that'll art so this, a but wrong'!!\n",
            "\n",
            "MENENIUS:\n",
            "privy seethey know'll me, Caius days\n",
            "Could poor fly'pregnant? go better Alps,\n",
            "back'll a great me; new should-\n",
            "has Margaret'wrenchingare\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Caw-RM-J2Chj"
      },
      "source": [
        "---\n",
        "**Answer:** This looks not that reasonable to me, even it generates some content that looks like poetic style, but the output text contains gibberish phrases and does not match or similar to the text in Shakespeare.\n",
        "\n",
        "Here are some reasons:\n",
        "\n",
        "**Bad Decoding & Encoding Design**: The decoder and encoder are just the maps between the characters (Aa-Zz and some symbols) and integers; however, character-level tokenization does not capture the structure of words or grammar effectively. These decoding and encoding methods lack the context that word-level or subword tokenization methods provide. This makes it harder for the model to learn meaningful relationships between words, leading to gibberish text generation.\n",
        "\n",
        "**Inappropriate Model/Text Architecture for Text in Shakespeare**: The text in Shakespeare is very different from the current text we have seen, it has a unique syntax, structure, and vocabulary that a basic model cannot capture. Moreover, the model is too small or too naive to learn the structure of this type of text.\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LgOzvWFDx_yH"
      },
      "source": [
        "#### Question 1.4.4\n",
        "\n",
        "The negative log-likelihood (averaged per token) we have been using to train our models can be expressed as\n",
        "\\begin{equation*}\n",
        "  L = -\\frac{1}{T} \\sum_{t = 1}^{T} \\log p(s[t] | \\text{context})\n",
        "\\end{equation*}\n",
        "for some document $s$, where $s[t]$ is the $t$th token of the doc. The natural language processing (NLP) community often reports the quantity\n",
        "\\begin{equation*}\n",
        "  \\text{perplexity} = \\exp(L).\n",
        "\\end{equation*}\n",
        "\n",
        "Give an intuitive interpretation of what perplexity is. Why might it be a more intuitive or natual measure to report than negative log-likelihood? Does the reported perplexity of your trained `TransformerLM` model make sense in terms of samples it generates? (Be sure to distinguish betwen `train` and `validation` perplexity. Which of `train` and `val` perplexity is more helpful for understanding your generated samples? Why?). (*Hint: your answer to Question 1.1.6 may be helpful*)."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Answer:**\n",
        "\n",
        "First we write out the **perplexity**:\n",
        "\n",
        "$$\n",
        "\\text{perplexity}=\\exp(L)=\\left[\\prod_{t=1}^T p(s[t]\\mid \\text{context})\\right]^{-\\frac{1}{T}}=p(s)^{-\\frac{1}{T}}=\\frac{1}{p(s)^T}\n",
        "$$\n",
        "\n",
        "As we can see, when $p(s)$ increase the perplexity decrease and $\\text{perplexity} \\geq 1$.\n",
        "\n",
        "Then intuitively we can say perplexity is a measture that can tell how the documents $s$ contents are reasonable, coherent and logically make sense, more precisely it can interpret as how many similar \"reasonable\" or likely choices on average when predicting the next token in each step.\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "vPIEpY6IZ_XF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The reasons this might it be more intuitive or natual measure to report than negative log-likelihood is the numerical space of perplexity is easier to understand. In negative log-likelihood, the values are in negative and log space which is hard to interpret as a measure. However, the perplexity can interpret how many similar \"reasonable\" or likely choices on average when predicting the next token in each step, so we can have the sense like model prediction' average degree of varying."
      ],
      "metadata": {
        "id": "fXrhVw_ThG71"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Train & Validation Perplexity**"
      ],
      "metadata": {
        "id": "iD39sNPqmOgD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# train & validation negative log-likelihood reported\n",
        "train_nll, val_nll = losses['train'], losses['val']\n",
        "\n",
        "# perplexity\n",
        "train_perplexity = torch.exp(train_nll)\n",
        "val_perplexity = torch.exp(val_nll)\n",
        "\n",
        "print(f\"train perplexity: {train_perplexity}\\n\")\n",
        "print(f\"validation perplexity: {val_perplexity}\\n\")"
      ],
      "metadata": {
        "id": "Y2nyf1-fkR3o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The reported perplexity of the trained model is not make sense, it has considerably effective perplexity score (in both train and validation, and their score are close, difference around 1) which suggests that that the model should be able to generate somewhat coherent and reasonable text. However, the generated sample contains a lot of gibberish phrases, which not make sense. At here the validation perplexity is more helpful for understanding the generated samples as it can tell how the model will behave in unseen context, which is helpful for understanding the quality and coherence of the samples it generates."
      ],
      "metadata": {
        "id": "rdCTBeVZkNLK"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9Izr1wTOjzlo"
      },
      "source": [
        "## Part 2: Mini-Project"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5lF3jFrQj1f4"
      },
      "source": [
        "Quick recap: So far we have\n",
        "\n",
        "1. Preprocessed the Shakespeare dataset by encoding individual characters into integer tokens.\n",
        "2. Implemented single headed attention and then further generalized to multiheaded attention. We further combined multiheaded attention with deep learning to create the transformer architecture.\n",
        "3. Trained our transformer and generated output that looks to be in the style of Shakespeare.\n",
        "\n",
        "Up to this point, the performance of our simple language model has clearly made a lot of progress. We can see that our model has learned to generate text that is close to the style of Shakespeare, although there are still many quirks and room for improvement.\n",
        "\n",
        "### Project Outline\n",
        "\n",
        "Find some area of possible improvement.\n",
        "We interpret \"improvement\" quite loosely, but please state precisely why your proposed innovation might improve the model, and provide evidence that it does (or does not!) improve.\n",
        "For your idea, **formulate a hypothesis** for why this change should result in a better model. **Implement your changes** and **report any findings**.\n",
        "\n",
        "_Notes_: As this assignment is being treated as a project, you should expect training to take longer than previous assignments. However, please use your judgement to decide what is reasonable. We will not expect you to run training procedures that take more than 2 hours on the free Google Colab computing resources and we certainly do not expect you to acquire additional compute. The proposed improvements should not solely rely on increased computing demands.\n",
        "\n",
        "_Hints_: There are many aspects to assessing a model. For example, not only is quality of generated text important, it is also of interest to reduce costs associated with training.\n",
        "\n",
        "### Deliverables\n",
        "\n",
        "In addition to a pdf of your python notebook, the submission for this project will be a written report no more than 4 pages in length using the [NeurIPS LaTex template](https://neurips.cc/Conferences/2023/PaperInformation/StyleFiles). Your report should include detailed analysis of the hypotheses you chose to test along with any conclusions.\n",
        "\n",
        "The page limit for the report does not include bibliography or appendices. Make sure to keep the \"ready for submission\" option to help us grade anonymously. Your writeup should also contain a link to any code used to generate the project so that we can reference it while grading (Google Drive folder with colab notebooks or Github repo are both fine). You should have at least one plot in your main text (which is capped at 4 pages)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z7f7wY9I9jSF"
      },
      "source": [
        "## Submission Instructions\n",
        "\n",
        "You will generate two PDFs: one from Part 1, which involves completing this Colab to create a transformer baseline; and one from the mini-project in Part 2, which will be your write-up of no longer than 4 pages. Be sure to include a link to your code for Part 2 somewhere in your writeup.\n",
        "\n",
        "**Combine the two PDFs into a single PDF and submit on gradescope. Tag your PDF correctly.**\n",
        "\n",
        "If you work in a group of two, submit one assignment on gradescope and tag your group members. If you complete the assignment individually, submit as usual."
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "A100",
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.9"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}