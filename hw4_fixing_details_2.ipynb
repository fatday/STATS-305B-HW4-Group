{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/fatday/STATS-305B-HW4-Group/blob/main/hw4_fixing_details_2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eNeWF0uED8J2"
      },
      "source": [
        "# HW4: Large Language Models\n",
        "\n",
        "In this assignment, you will be implementing language models for next token prediction and generation of Shakespeare! This assignment will be in two parts. **For this final assignment, you have the option to work in pairs.**\n",
        "\n",
        "**Part 1:**\n",
        "\n",
        "In this part, you will review some key ingredients of sequence modeling. In the process, you will build a baseline transformer model for next token prediction trained on Shakespeare's works. We have provided the scaffoldin for the code in this part of the assignment, and your task will be to fill in the key implementation steps.\n",
        "\n",
        "**Part 2:**\n",
        "\n",
        "This part is an open-ended mini-project where you have the freedom to try sequence modeling approaches of your choice on this problem. You should feel free to try other architectures (HMMs, RNNs, transformers, state space layers, diffusion models etc.) or to invent new architectures. You may also experiment with new algorithms for fitting or training these models. The goal will be to find some area of possible improvement (we interpret \"improvement\" quite loosely, but it is up to you to state precisely why your proposed innovation might constitute an improvement and to show convincing evidence that your innovation does or does not); to formulate and state a precise hypothesis; and to falsify or support the hypothesis with rigorous empirical analyses.\n",
        "\n",
        "**Deliverables:**\n",
        "\n",
        "- Code for Parts 1 of the assignment\n",
        "- A written report of at most 4 pages for Part 2 (references not included in the page limit), with a link to code for Part 2.\n",
        "\n",
        "_Note: the code for Part 2 will not be graded, but we ask you to include a link to it for completeness._\n",
        "\n",
        "**Important: Choosing runtimes**\n",
        "\n",
        "Google Colab has limits on the free usage of GPU runtimes. For this assignment, **we strongly recommend doing the majority of your prototyping, testing, and small-scale experiments on CPU backend**. Then, once you are ready to train your models, you should switch to a T4 GPU.\n",
        "\n",
        "You can change runtime type by clicking **Runtime -> Change Runtime Type** in the tabs above. You can monitor your resource usages in the top right corner of the screen (it should say what backend you are using, how many compute units per hour you are using, etc.)\n",
        "\n",
        "**Make sure to turn off GPU runtime if you are not actively using it!**\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qZ-AwbZ4ySCJ"
      },
      "source": [
        "## Setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "_5IXGh6OOBZV"
      },
      "outputs": [],
      "source": [
        "# torch imports\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "from tqdm import tqdm\n",
        "import requests\n",
        "import os\n",
        "\n",
        "torch.manual_seed(305)\n",
        "\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fsgHl9JCuGBS"
      },
      "source": [
        "We set default values for some global hyperparameters, but feel free to change these during development as needed."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "A_Z5Jh74DH_E"
      },
      "outputs": [],
      "source": [
        "# Global hyperparameters\n",
        "SMALL_ITERS = 1000\n",
        "LARGE_ITERS = 2000\n",
        "EVAL_ITERS = 100\n",
        "CONTEXT_WINDOW_SIZE = 256"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lF6dgHnhOprg"
      },
      "source": [
        "## Part 0: Preprocessing\n",
        "\n",
        "As in the previous problem sets, a certain amount of preprocessing for textual data is required."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WF0_bhXNOxeS"
      },
      "source": [
        "### 0.1: Loading and preprocessing the dataset\n",
        "\n",
        "\n",
        "The first step is to download the dataset. We will be using a dataset from Andrej Karpathy consisting of a subset of works from Shakespeare.\n",
        "\n",
        "The dominant mode for preprocessing textual data is to tokenize it; that is, to split the dataset into a finite vocabulary of tokens. Then, we can set up a dictionaries mapping from counting numbers (representing tokens) to tokens and vice versa. Tokens can be characters, or words, or subwords; in fact, the \"best\" way to tokenize text is an active area of research.\n",
        "\n",
        "To keep things simple, we'll tokenize the text on a per-character level."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "53dGz7ExDkUv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c3ae1b13-9137-4b1c-b63e-c238a109cc09"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "length of dataset in characters: 1,115,394\n"
          ]
        }
      ],
      "source": [
        "# download the tiny shakespeare dataset\n",
        "input_file_path = 'input.txt'\n",
        "\n",
        "if not os.path.exists(input_file_path):\n",
        "    data_url = 'https://raw.githubusercontent.com/karpathy/char-rnn/master/data/tinyshakespeare/input.txt'\n",
        "    with open(input_file_path, 'w') as f:\n",
        "        f.write(requests.get(data_url).text)\n",
        "\n",
        "with open(input_file_path, 'r') as f:\n",
        "    data = f.read()\n",
        "print(f\"length of dataset in characters: {len(data):,}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "b2HuC2F9p_4K",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e0225236-15db-412c-ea50-c882ca5167e8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "all the unique characters: \n",
            " !$&',-.3:;?ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz\n",
            "vocab size: 65\n"
          ]
        }
      ],
      "source": [
        "# get all the unique characters that occur in this text\n",
        "chars = sorted(list(set(data)))\n",
        "vocab_size = len(chars)\n",
        "print(\"all the unique characters:\", ''.join(chars))\n",
        "print(f\"vocab size: {vocab_size:,}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "JEWx5jnKqDzT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1dc3890c-1575-4439-9862-c63fb367f412"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train has 1,003,854 tokens\n",
            "val has 111,540 tokens\n"
          ]
        }
      ],
      "source": [
        "# create a mapping from characters to integers\n",
        "stoi = { ch:i for i,ch in enumerate(chars) }\n",
        "itos = { i:ch for i,ch in enumerate(chars) }\n",
        "\n",
        "def encode(s):\n",
        "    return [stoi[c] for c in s] # encoder: take a string, output a list of integers\n",
        "def decode(l):\n",
        "    return ''.join([itos[i] for i in l]) # decoder: take a list of integers, output a string\n",
        "\n",
        "# create the train and test splits\n",
        "n = len(data)\n",
        "train_chars = data[:int(n*0.9)]\n",
        "val_chars = data[int(n*0.9):]\n",
        "\n",
        "# encode both to integers\n",
        "train_data = encode(train_chars)\n",
        "val_data = encode(val_chars)\n",
        "\n",
        "# cast as torch tensors\n",
        "train_data = torch.tensor(train_data)\n",
        "val_data = torch.tensor(val_data)\n",
        "\n",
        "print(f\"train has {len(train_data):,} tokens\")\n",
        "print(f\"val has {len(val_data):,} tokens\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nsOs0_diEcjY"
      },
      "source": [
        "We also write helper functions to get batches of data and to evaluate the loss of various models on them."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "AkAD0PfiEfjG"
      },
      "outputs": [],
      "source": [
        "# function for getting batches of data\n",
        "def get_batch(split, context_window_size, device, batch_size=32):\n",
        "    \"\"\"\n",
        "    generate a small batch of data of inputs x and targets y\n",
        "\n",
        "    Args:\n",
        "        split: 'train' or 'val'\n",
        "        device: 'cpu' or 'cuda' (should be 'cuda' if available)\n",
        "    \"\"\"\n",
        "    data = train_data if split == 'train' else val_data\n",
        "    ix = torch.randint(len(data) - context_window_size, (batch_size,))\n",
        "    x = torch.stack([data[i:i+context_window_size] for i in ix])\n",
        "    y = torch.stack([data[i+1:i+context_window_size+1] for i in ix])\n",
        "    x = x.to(device)\n",
        "    y = y.to(device)\n",
        "    return x, y\n",
        "\n",
        "# helper function for tracking loss during training\n",
        "# given to you\n",
        "@torch.no_grad()\n",
        "def estimate_loss(model, eval_iters, context_window_size, device):\n",
        "    \"\"\"\n",
        "    Args:\n",
        "      model: model being evaluated\n",
        "      eval_iters: number of batches to average over\n",
        "      context_window_size: size of the context window\n",
        "      device: 'cpu' or 'cuda' (should be 'cuda' if available)\n",
        "    \"\"\"\n",
        "    out = {}\n",
        "    for split in ['train', 'val']:\n",
        "        losses = torch.zeros(eval_iters)\n",
        "        for k in range(eval_iters):\n",
        "            X, Y = get_batch(split, context_window_size, device)\n",
        "            logits, loss = model(X, Y)\n",
        "            losses[k] = loss.item()\n",
        "        out[split] = losses.mean()\n",
        "    return out"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ercCUt_d07FX"
      },
      "source": [
        "## Part 1: Language Modeling\n",
        "\n",
        "In this first part of the assignment, we will implement a baseline for code modeling.\n",
        "\n",
        "In the process of building this baseline, we will review 4 key ideas of sequence modeling that have become the backbone of modern language models such as ChatGPT:\n",
        "\n",
        "1. Framing language modeling as next token prediction, and next token prediction as multiclass logistic regression\n",
        "2. Embedding discrete tokens in continuous latent spaces (word embeddings)\n",
        "3. Use the attention mechanism to move beyond Markovian models for sequences (we of course pay for this greater expressivity with increased compute, which is made possible in part by using matrix multiplications on hardware accelerators like GPUs. Reducing the compute burden while maintaining the expressivity needed for good sequence modeling is an active area of research).\n",
        "4. Combining attention with deep learning in the Transformer architecture."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kh1kX0pw1bR2"
      },
      "source": [
        "### 1.1: Next token prediction as multiclass logistic regression\n",
        "\n",
        "Our first language model will simply be a lookup table. That is, given that we have token with value $v$, we will simply \"look up\" the logits that correspond to our prediction for the next token. This model is often known as a \"bigram model\" because it can be derived from the relative proportions of different bigrams (ordered pairs of tokens) occurring in a large text corpus.\n",
        "\n",
        "Let us be a bit more precise in our definition of the bigram model. Let's say that the total size of our vocabulary (the number of tokens we are using) is $V$. Let $A$ be a matrix in $\\mathbb{R}^{V \\times V}$, where each row $A_v$ corresponds to the logits for the prediction of which token would follow a token that has value $v$.\n",
        "Thus, we are modeling the distribution of the token following a token that has value $v$ as\n",
        "\\begin{align*}\n",
        "y_{t+1} \\mid y_t &= v \\sim \\mathrm{Cat}(\\mathbf{\\pi}) \\\\\n",
        "\\pi &=\\mathrm{softmax}(A_v)\n",
        "\\end{align*}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5kNWISNQ9bbH"
      },
      "source": [
        "#### Question 1.1.1\n",
        "\n",
        "$\\mathbf{\\pi} \\in \\Delta_{V-1}$ is the vector of probabilities used to parameterize the categorical distribution for the next token prediction. Explain why we parameterize\n",
        "\\begin{equation*}\n",
        "  \\mathbf{\\pi} = \\mathrm{softmax}(A_v),\n",
        "\\end{equation*}\n",
        "and could not just use\n",
        "\\begin{equation*}\n",
        "  \\mathbf{\\pi} = A_v.\n",
        "\\end{equation*}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nkHP8-T3zJ3D"
      },
      "source": [
        "**Answer:**\n",
        "The vector $\\pi$ represents a probability distribution over the next token in the sequence. This means that $\\pi$ must satisfy the following properties:\n",
        "1. Non-negativity: Each element of $\\pi$ must be non-negative, i.e., $\\pi_i \\geq 0$ for all $i$.\n",
        "2. Sum to one: The probabilities must sum to one, i.e., $\\sum_i \\pi_i=1$.\n",
        "\n",
        "The values in $A_v$ are logits, meaning they are unconstrained real values. If we were to directly set $\\pi=A_v$, then $\\pi$ would not necessarily satisfy the constraints of a probability distribution because the elements of $A_v$ can be arbitrary real numbers.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DtAjylIF-SwQ"
      },
      "source": [
        "#### Question 1.1.2\n",
        "\n",
        "Discuss the relationship between the bigram model and contigency tables (discussed in Lecture 1)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ehdR52pnzZHl"
      },
      "source": [
        "**Answer**:\n",
        "\n",
        "Contingency table represents a sample from a **joint distribution** two categorical random variables:\n",
        "\n",
        "$$\n",
        "X\\in \\{ 1,2,....,I\\} \\ \\ \\ \\ \\ \\text{and} \\ \\ \\  \\ \\ \\ Y\\in \\{1,2,...,J\\}\n",
        "$$\n",
        "\n",
        "where the table can be written as\n",
        "\n",
        "$$\n",
        "\\Pi=\n",
        "\\begin{bmatrix}\n",
        "\\pi_{11}&\\ldots&\\pi_{1J}\\\\\n",
        "\\vdots&&\\vdots\\\\\n",
        "\\pi_{1I}&\\ldots&\\pi_{IJ}\n",
        "\\end{bmatrix}\n",
        "\\ \\ \\ \\ \\ \\text{where} \\ \\ \\  \\ \\ \\ \\pi_{ij}=P(X=i,Y=j)\n",
        "$$\n",
        "\n",
        "A bigram model estimates the probability of a token given the previous token, typically represented as a conditional probability:\n",
        "\n",
        "$$\n",
        "P(y_{t+1} | y_t).\n",
        "$$\n",
        "\n",
        "This can be similarly represented as a contingency table for the case $I=J=V$, where rows correspond to the previous token $ y_t $ and columns correspond to the next token $ y_{t+1} $. Each cell in the table contains the probability:\n",
        "\n",
        "$$\n",
        "P(y_{t+1} =w| y_t=v)=\\frac{\\exp(A_{v,w})}{\\sum_{w}\\exp(A_{v,w})}\n",
        "$$\n",
        "\n",
        "which has the similar structure as $\\pi_{w\\mid v}$ in contingency table. Thus, the bigram model can be viewed as a normalized (in row) contingency table representing transition probabilities between tokens.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y4AzpB8M-u9o"
      },
      "source": [
        "#### Question 1.1.3\n",
        "\n",
        "Say I have a string of three tokens with ids $(7, 3, 6)$. If I use the bigram model as a generative model for language, given this information, what is distribution of the fourth token? Write your answer in terms of the matrix $A$ we defined in 1.1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fs4rWYjlzc7n"
      },
      "source": [
        "**Answer:**\n",
        "\n",
        "The bigram model determines the distribution of the next token based only on the most recent token. Given the sequence of token IDs $ (7, 3, 6) $, the last observed token is $ 6 $.\n",
        "\n",
        "According to the bigram model, the probability distribution of the fourth token is given by:\n",
        "\n",
        "$$\n",
        "P(y_4 | y_3 = 6) = \\text{Cat}(\\pi), \\quad \\text{where} \\quad \\pi = \\text{softmax}(A_6).\n",
        "$$\n",
        "\n",
        "Here, $ A_6 $ is the row of the matrix $ A $ corresponding to token $ 6 $, and applying the softmax function ensures that we obtain a valid probability distribution over possible next tokens.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "leN9gUxoEuhg"
      },
      "source": [
        "#### Question 1.1.4\n",
        "\n",
        "Remember back in Part 0 when we gave you the helper function `get_batch`? Run `get_batch` and look at the inputs `x` and the targets `y`. Explain any relation between them in the context of formulating language modeling in the context of next token prediction."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rzLupp2jExDS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fecd8824-9bab-4e00-92c7-315d87e7859b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "the features have token ids tensor([[47, 53, 59, 57,  1, 50, 53, 60, 43,  6]])\n",
            "\n",
            "\n",
            "the targets have token ids tensor([[53, 59, 57,  1, 50, 53, 60, 43,  6,  0]])\n"
          ]
        }
      ],
      "source": [
        "xb, yb = get_batch('train', 10, device, batch_size = 1)\n",
        "print(f\"the features have token ids {xb}\")\n",
        "print('\\n')\n",
        "print(f\"the targets have token ids {yb}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5hMuPAmcuGBV"
      },
      "source": [
        "**Anwser:**\n",
        "\n",
        "In the context of next-token prediction, the input tokens $ x $ serve as features, while the target tokens $ y $ represent the next tokens that should be predicted. Observing the printed tensors:\n",
        "\n",
        "$\n",
        "x = [47, 53, 59, 57, 1, 50, 53, 60, 43, 6]\n",
        "$\n",
        "\n",
        "$\n",
        "y = [53, 59, 57, 1, 50, 53, 60, 43, 6, 0]\n",
        "$\n",
        "\n",
        "we see that each element in $ y $ is simply the next token that follows the corresponding element in $ x $ (if consider from left to right). That is,\n",
        "\n",
        "$$\n",
        "y_t = x_{t+1}.\n",
        "$$\n",
        "\n",
        "This structure aligns with the bigram language model, where the goal is to learn the probability distribution $ P(y_t | x_t) $ so that given an input token $ x_t $, the model predicts the next token $ y_t $.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UyYl8QQt_Uhb"
      },
      "source": [
        "#### Question 1.1.5\n",
        "\n",
        "Discuss the strengths and weaknesses of the bigram model as a generative model for language."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7t6Hc2dhzdzL"
      },
      "source": [
        "**Answer:**\n",
        "\n",
        "\n",
        "**Strengths**:\n",
        "\n",
        "- Simplicity and Efficiency: The bigram model is easy to implement and computationally efficient compared to more complex models (e.g n-grams).\n",
        "- Interpretability: The transition probabilities can be directly calculated and analyzed by some simple metrics (e.g frequency counts), so it can easily interpret the model and distribution.\n",
        "- Works well with sufficient data: When trained on a large corpus, it captures basic statistical relationships between adjacent words.\n",
        "\n",
        "**Weaknesses**:\n",
        "\n",
        "- Limited Context (Markov Assumption): The model assumes that the probability of the next token depends only on the previous token, which ignores long-term dependencies that are crucial for understanding language.\n",
        "- Time-Invariant Transition Probabilities: The model assumes that transition probabilities do not change over time, which cannot reflect how language meaning changes based on context.\n",
        "- Data Sparsity & Poor Generalization: The model might struggles with rare or unseen bigrams, which would have poor generalization. **This is what when we project the discrete words into continuous embeddings might help, we can see this in 1.2.**\n",
        "\n",
        "\n",
        "**All in all, we should add more inductive bias that we know about language distibution when designing the models** Thus, while the bigram model is a simple and useful baseline, more sophisticated models such as n-grams, hidden Markov models, or neural language models are needed for better language modeling.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mjYO1XTM_8NE"
      },
      "source": [
        "#### Question 1.1.6\n",
        "\n",
        "Say I have a string $s$ of length $T$. Derive the formula for the negative log likelihood of $s$ under the bigram model in terms of the matrix of logits $A$. What would your answer be if the matrix of logits $A$ were all zeros? What would be the value of the negative log likelihood of $s$ under a model that always perfectly predicted the next token?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QuzLfI4Pzes6"
      },
      "source": [
        "**Answer**\n",
        "\n",
        "Given a sequence $ s = (y_1, y_2, \\dots, y_T) $, the negative log-likelihood (NLL) under the bigram model can be written in terms of the matrix of logits \\( A \\).\n",
        "\n",
        "1. **Derivation of the Negative Log-Likelihood (NLL):**  \n",
        "   The probability of the sequence under the bigram model is:\n",
        "\n",
        "   $$\n",
        "   P(s) = \\prod_{t=1}^{T-1} P(y_{t+1} | y_t)\n",
        "   $$\n",
        "\n",
        "   Using the softmax transformation on the logits $ A $, the probability of transitioning from token $y_t$ to $y_{t+1}$ is:\n",
        "\n",
        "   $$\n",
        "   P(y_{t+1} | y_t) = \\frac{\\exp(A_{y_t, y_{t+1}})}{\\sum_{j} \\exp(A_{y_t, j})}\n",
        "   $$\n",
        "\n",
        "   The negative log-likelihood is then:\n",
        "\n",
        "   $$\n",
        "   -\\log P(s) = -\\sum_{t=1}^{T-1} \\log P(y_{t+1} | y_t)\n",
        "   $$\n",
        "\n",
        "   Substituting the softmax probability:\n",
        "\n",
        "   $$\n",
        "   -\\sum_{t=1}^{T-1} \\log \\frac{\\exp(A_{y_t, y_{t+1}})}{\\sum_{j} \\exp(A_{y_t, j})}\n",
        "   $$\n",
        "\n",
        "   Which simplifies to:\n",
        "\n",
        "   $$\n",
        "   \\sum_{t=1}^{T-1} \\left[ \\log \\left(\\sum_{j} \\exp(A_{y_t, j}) \\right)- A_{y_t, y_{t+1}} \\right].\n",
        "   $$\n",
        "\n",
        "2. **Case when $ A $ is all zeros:**  \n",
        "   If all elements of $ A $ are zero, then:\n",
        "\n",
        "   $$\n",
        "   P(y_{t+1} | y_t) = \\frac{\\exp(0)}{\\sum_{j} \\exp(0)} = \\frac{1}{V}.\n",
        "   $$\n",
        "\n",
        "   so the next token follows a uniform discrete distribution, which is randomly picking word from vocabulary, and the negative loglikelihood can simplify to:\n",
        "\n",
        "   $$\n",
        "   \\sum_{t=1}^{T-1} \\left[ \\log \\left(\\sum_{j} \\exp(0) \\right)- 0 \\right]= \\sum_{t=1}^{T-1} \\log V = (T-1) \\log V.\n",
        "   $$\n",
        "\n",
        "3. **Case when the model predicts the next token perfectly:**  \n",
        "   If the model perfectly predicts the next token, then:\n",
        "\n",
        "   $$\n",
        "   P(y_{t+1} | y_t) = 1.\n",
        "   $$\n",
        "\n",
        "   This means:\n",
        "\n",
        "   $$\n",
        "   -\\sum_{t=1}^{T-1} \\log 1 = 0.\n",
        "   $$\n",
        "\n",
        "Thus, the negative log-likelihood is zero when the model makes perfect predictions in sequence $s$."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rfzoXAATAfwn"
      },
      "source": [
        "#### Question 1.1.7: Implement the BigramLanguageModel\n",
        "\n",
        "Implement the bigram language model below.\n",
        "\n",
        "Your TODOs:\n",
        "  * if the `forward` method is provided a target, the loss should be the negative log likelihood of the target (given the context)\n",
        "  * `generate` should take in (batched) contexts and a number of new tokens to generate, and then generate text autoregressively from your model. Note that in autoregressive text generation, you iteratively append the tokens you generate to your context.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_lJ1mR4K1aj_"
      },
      "outputs": [],
      "source": [
        "class BigramLanguageModel(nn.Module):\n",
        "\n",
        "    def __init__(self, vocab_size):\n",
        "        \"\"\"\n",
        "        Args:\n",
        "          vocab_size: size of the vocabulary (the number of tokens)\n",
        "        \"\"\"\n",
        "        super().__init__()\n",
        "        # each token directly reads off the logits for the next token from a lookup table\n",
        "        self.logits_table = nn.Embedding(vocab_size, vocab_size)\n",
        "        self.vocab_size = vocab_size\n",
        "\n",
        "    def forward(self, token_ids, targets=None):\n",
        "        \"\"\"\n",
        "        Args:\n",
        "          token_ids: Int(B, T), token ids that make up the context (batch has size B, each entry in the batch has length T)\n",
        "          targets: Int(B, T), token ids corresponding to the target of each context in token_ids\n",
        "\n",
        "        Returns:\n",
        "          logits: (B, T, V), logits[b,t, :] gives the length V vector of logits for the next token prediction in string b up to t tokens\n",
        "          loss: scalar, negative log likelihood of target given context\n",
        "        \"\"\"\n",
        "\n",
        "        # idx and targets are both (B,T) tensor of integers\n",
        "        logits = self.logits_table(token_ids) # (B,T,V)\n",
        "\n",
        "        if targets is None:\n",
        "            loss = None\n",
        "        else:\n",
        "            # TODO: what should the loss in this setting be?\n",
        "            # implement the log-likelihood\n",
        "            B, T, V = logits.shape\n",
        "            logits = logits.view(B*T, V)\n",
        "            targets = targets.view(B*T)\n",
        "            loss = F.cross_entropy(logits, targets)\n",
        "\n",
        "        return logits, loss\n",
        "\n",
        "    @torch.no_grad()\n",
        "    def generate(self, token_ids, max_new_tokens=CONTEXT_WINDOW_SIZE):\n",
        "        \"\"\"\n",
        "        Args:\n",
        "          token_ids: (B, T) tensor of token ids to provide as context\n",
        "          max_new_tokens: int, maximum number of new tokens to generate\n",
        "\n",
        "        Returns:\n",
        "          (B, T+max_new_tokens) tensor of context with new tokens appended\n",
        "        \"\"\"\n",
        "        # TODO: your code below\n",
        "        B,T = token_ids.shape\n",
        "        new_token_sequences = torch.zeros((B, T+max_new_tokens), dtype=torch.long, device=token_ids.device)\n",
        "        new_token_sequences[:, :T] = token_ids\n",
        "        for t in range(max_new_tokens):\n",
        "            logits, loss = self(token_ids)\n",
        "            logits = logits[:, -1, :]\n",
        "            probs = F.softmax(logits, dim=-1)\n",
        "            new_tokens = torch.multinomial(probs, num_samples=1)\n",
        "            new_token_sequences[:, T + t] = new_tokens\n",
        "\n",
        "        return new_token_sequences\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2MaUUxb0EQY1"
      },
      "source": [
        "#### Question 1.1.8: Evaluating the initialization.\n",
        "\n",
        "Evaluate the loss of your untrained bigram model on a batch of data. Make sure the loss (negative log likelihood) is per-token (i.e. you may need to average over both sequence length and batch). Does this loss make sense in the context of your answer to Question 1.1.6? Discuss."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xgSEGqKGEiOn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "eed38116-25a3-4596-92b0-fae3d4d81185"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loss (average per token): 4.623427867889404, vocab size = 65, T = 256\n",
            "loss (average per sequence): 1178.97412109375\n",
            "loss (when logit A are all 0 - random guess) = 1064.4687538233875\n"
          ]
        }
      ],
      "source": [
        "x,y = get_batch(\"train\", CONTEXT_WINDOW_SIZE, device)\n",
        "bigram_model = BigramLanguageModel(vocab_size)\n",
        "bm = bigram_model.to(device)\n",
        "\n",
        "# TODO: your code below\n",
        "import math\n",
        "logits, loss = bm(x,y)\n",
        "print(f\"loss (average per token): {loss}, vocab size = {vocab_size}, T = {CONTEXT_WINDOW_SIZE}\")\n",
        "print(f\"loss (average per sequence): {loss * (CONTEXT_WINDOW_SIZE - 1)}\")\n",
        "print(f\"loss (when logit A are all 0 - random guess) = {(CONTEXT_WINDOW_SIZE-1) * math.log(vocab_size)}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bS32m6egzg03"
      },
      "source": [
        "**Answer**:\n",
        "In 1.1.6 the loss of a sequence when logit are all $0$ is\n",
        "\n",
        "$$\n",
        "(T-1)\\log V=255\\cdot \\log 65\\approx 1064.469\n",
        "$$\n",
        "\n",
        "but our **average loss per sequence** from above result is **higher** than the $1064.469$. In this case, it make sense since this is the **untrained model** and the **initial** **nn.Embedding** will output the logit $A$ that each entry follow $N(0,1)$. This randomlization will possibly result the logit $A$ that worse than logit $A$ would randomly guess the next token."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IzxRpcgKE4_5"
      },
      "source": [
        "#### Question 1.1.9: Training your bigram model\n",
        "\n",
        "Train your bigram model for `SMALL_ITERS` iterations. Plot and interpret the loss curve.\n",
        "\n",
        "Our train loss gets down to around 2.5 after 1000 iterations."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "E2r390zbyz3O",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2f159cbe-ebb6-4526-d67f-cc7febc71f86"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/1000 [00:00<?, ?it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "iteration 0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  1%|▏         | 13/1000 [00:00<00:48, 20.40it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "step 0: train loss 4.6189, val loss 4.6175\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 19%|█▉        | 189/1000 [00:02<00:06, 127.11it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "iteration 200\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 22%|██▏       | 216/1000 [00:03<00:15, 51.89it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "step 200: train loss 2.9109, val loss 2.9177\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 39%|███▉      | 389/1000 [00:04<00:05, 122.03it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "iteration 400\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 41%|████▏     | 414/1000 [00:05<00:12, 46.94it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "step 400: train loss 2.5624, val loss 2.5822\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 59%|█████▉    | 593/1000 [00:06<00:03, 127.93it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "iteration 600\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 62%|██████▏   | 617/1000 [00:07<00:07, 48.84it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "step 600: train loss 2.4972, val loss 2.5245\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 80%|████████  | 800/1000 [00:09<00:02, 87.93it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "iteration 800\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 82%|████████▏ | 823/1000 [00:11<00:04, 36.97it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "step 800: train loss 2.4826, val loss 2.5061\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|█████████▉| 996/1000 [00:12<00:00, 124.09it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "iteration 999\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r100%|██████████| 1000/1000 [00:13<00:00, 76.05it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "step 999: train loss 2.4733, val loss 2.4975\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "# create a PyTorch optimizer\n",
        "learning_rate = 1e-2\n",
        "optimizer = torch.optim.AdamW(bigram_model.parameters(), lr=learning_rate)\n",
        "\n",
        "eval_interval = 200\n",
        "\n",
        "loss_list = []\n",
        "\n",
        "for it in tqdm(range(SMALL_ITERS)):\n",
        "\n",
        "    # every once in a while evaluate the loss on train and val sets\n",
        "    if it % eval_interval == 0 or it == SMALL_ITERS - 1:\n",
        "        print(f\"iteration {it}\")\n",
        "        losses = estimate_loss(bm, EVAL_ITERS, CONTEXT_WINDOW_SIZE, device)\n",
        "        print(f\"step {it}: train loss {losses['train']:.4f}, val loss {losses['val']:.4f}\")\n",
        "\n",
        "    # sample a batch of data\n",
        "    xb, yb = get_batch('train', CONTEXT_WINDOW_SIZE, device)\n",
        "\n",
        "    # evaluate the loss\n",
        "    logits, loss = bm(xb, yb)\n",
        "    loss_list.append(loss.detach().item())\n",
        "    optimizer.zero_grad(set_to_none=True)\n",
        "    loss.backward()\n",
        "    optimizer.step()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot and interpret the loss curve.\n",
        "plt.plot(loss_list)\n",
        "plt.xlabel('Iteration')\n",
        "plt.ylabel('Loss')\n",
        "plt.title('Loss Curve')\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 472
        },
        "id": "cjUuRKUFwQsN",
        "outputId": "7b2d4109-fbf6-4c2d-c837-402dc013aab5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAjcAAAHHCAYAAABDUnkqAAAAOnRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjEwLjAsIGh0dHBzOi8vbWF0cGxvdGxpYi5vcmcvlHJYcgAAAAlwSFlzAAAPYQAAD2EBqD+naQAAVlZJREFUeJzt3XlYVGX/BvB7hmVYZ1hkkV1FBcQNV8ytJE3JNM3MTNNWTUvft1XNssWwrN40S61+aplmtqjlmuG+iyIC7guCsoMwrAPMnN8f6JGRRcBhDgz357rmes8588zMd469zu1znvM8MkEQBBARERGZCLnUBRAREREZEsMNERERmRSGGyIiIjIpDDdERERkUhhuiIiIyKQw3BAREZFJYbghIiIik8JwQ0RERCaF4YaIiIhMCsMNERERmRSGGyKq0apVqyCTyRAVFSV1KbVy6tQpPPPMM/D29oZCoYCTkxPCwsKwcuVKaLVaqcsjIiMwl7oAIiJD+eGHHzBlyhS4ublhwoQJaNu2LfLy8hAZGYnnn38eKSkpmD17ttRlElEDY7ghIpNw5MgRTJkyBaGhodi6dSvs7e3F52bOnImoqCjExcUZ5LMKCgpga2trkPciIsPjZSkiMojo6GgMHToUSqUSdnZ2GDRoEI4cOaLXprS0FB988AHatm0LKysrODs7o2/fvti5c6fYJjU1FZMnT4aXlxcUCgVatmyJESNGICEhocbP/+CDDyCTybBmzRq9YHNb9+7dMWnSJADAnj17IJPJsGfPHr02CQkJkMlkWLVqlXhs0qRJsLOzw+XLlzFs2DDY29tj/PjxmD59Ouzs7FBYWFjps8aNGwd3d3e9y2Dbtm1Dv379YGtrC3t7e4SHhyM+Pr7G70RE9cNwQ0T3LT4+Hv369UNMTAzeeustzJ07F1evXsXAgQNx9OhRsd28efPwwQcf4MEHH8SSJUswZ84c+Pj44OTJk2Kb0aNHY8OGDZg8eTK+/fZbvPbaa8jLy0NiYmK1n19YWIjIyEj0798fPj4+Bv9+ZWVlGDJkCFxdXfH5559j9OjRGDt2LAoKCrBly5ZKtfz999944oknYGZmBgBYvXo1wsPDYWdnh08//RRz587FmTNn0Ldv33uGNiKqB4GIqAYrV64UAAjHjx+vts3IkSMFS0tL4fLly+Kx5ORkwd7eXujfv794rHPnzkJ4eHi173Pz5k0BgLBw4cI61RgTEyMAEGbMmFGr9rt37xYACLt379Y7fvXqVQGAsHLlSvHYs88+KwAQ3nnnHb22Op1O8PT0FEaPHq13fP369QIAYd++fYIgCEJeXp7g4OAgvPjii3rtUlNTBZVKVek4Ed0/9twQ0X3RarX4559/MHLkSLRu3Vo83rJlSzz99NM4cOAA1Go1AMDBwQHx8fG4ePFile9lbW0NS0tL7NmzBzdv3qx1Dbffv6rLUYYydepUvX2ZTIYxY8Zg69atyM/PF4//+uuv8PT0RN++fQEAO3fuRE5ODsaNG4fMzEzxYWZmhl69emH37t0NVjNRc8VwQ0T3JSMjA4WFhWjfvn2l5wIDA6HT6ZCUlAQA+PDDD5GTk4N27dqhY8eOePPNN3H69GmxvUKhwKeffopt27bBzc0N/fv3x2effYbU1NQaa1AqlQCAvLw8A36zO8zNzeHl5VXp+NixY1FUVIS//voLAJCfn4+tW7dizJgxkMlkACAGuYceegguLi56j3/++Qfp6ekNUjNRc8ZwQ0RG079/f1y+fBkrVqxAcHAwfvjhB4SEhOCHH34Q28ycORMXLlxAREQErKysMHfuXAQGBiI6Orra9/X394e5uTliY2NrVcft4HG36ubBUSgUkMsr/3XZu3dv+Pn5Yf369QCAv//+G0VFRRg7dqzYRqfTASgfd7Nz585Kj02bNtWqZiKqPYYbIrovLi4usLGxwfnz5ys9d+7cOcjlcnh7e4vHnJycMHnyZPzyyy9ISkpCp06dMG/ePL3XtWnTBq+//jr++ecfxMXFoaSkBF988UW1NdjY2OChhx7Cvn37xF6imjg6OgIAcnJy9I5fu3btnq+925NPPont27dDrVbj119/hZ+fH3r37q33XQDA1dUVYWFhlR4DBw6s82cSUc0YbojovpiZmWHw4MHYtGmT3p0/aWlpWLt2Lfr27SteNsrKytJ7rZ2dHfz9/aHRaACU32lUXFys16ZNmzawt7cX21Tn/fffhyAImDBhgt4YmNtOnDiBH3/8EQDg6+sLMzMz7Nu3T6/Nt99+W7svXcHYsWOh0Wjw448/Yvv27XjyySf1nh8yZAiUSiU++eQTlJaWVnp9RkZGnT+TiGrGSfyIqFZWrFiB7du3Vzo+Y8YMfPzxx9i5cyf69u2LV155Bebm5li+fDk0Gg0+++wzsW1QUBAGDhyIbt26wcnJCVFRUfj9998xffp0AMCFCxcwaNAgPPnkkwgKCoK5uTk2bNiAtLQ0PPXUUzXW16dPH3zzzTd45ZVXEBAQoDdD8Z49e/DXX3/h448/BgCoVCqMGTMGX3/9NWQyGdq0aYPNmzfXa/xLSEgI/P39MWfOHGg0Gr1LUkD5eKClS5diwoQJCAkJwVNPPQUXFxckJiZiy5YteOCBB7BkyZI6fy4R1UDq27WIqHG7fSt4dY+kpCRBEATh5MmTwpAhQwQ7OzvBxsZGePDBB4VDhw7pvdfHH38s9OzZU3BwcBCsra2FgIAAYf78+UJJSYkgCIKQmZkpTJs2TQgICBBsbW0FlUol9OrVS1i/fn2t6z1x4oTw9NNPCx4eHoKFhYXg6OgoDBo0SPjxxx8FrVYrtsvIyBBGjx4t2NjYCI6OjsLLL78sxMXFVXkruK2tbY2fOWfOHAGA4O/vX22b3bt3C0OGDBFUKpVgZWUltGnTRpg0aZIQFRVV6+9GRLUjEwRBkCxZERERERkYx9wQERGRSWG4ISIiIpPCcENEREQmheGGiIiITArDDREREZkUhhsiIiIyKc1uEj+dTofk5GTY29tXu74MERERNS6CICAvLw8eHh5VrvVWUbMLN8nJyXrr3BAREVHTkZSUBC8vrxrbNLtwY29vD6D85Nxe74aIiIgaN7VaDW9vb/F3vCbNLtzcvhSlVCoZboiIiJqY2gwp4YBiIiIiMikMN0RERGRSGG6IiIjIpDDcEBERkUlhuCEiIiKTwnBDREREJoXhhoiIiEwKww0RERGZFIYbIiIiMikMN0RERGRSGG6IiIjIpDDcEBERkUlhuDGg+ORcpOYWS10GERFRs8ZwYyCrDl7F8K8P4OMtZ6QuhYiIqFljuDGQHq2cIADYfDoFCZkFUpdDRETUbDHcGEgHDxXau9kDABKyGG6IiIikwnBjQC1VVgDAcTdEREQSYrgxIFf78nDzzp+x0OoEiashIiJqnhhuDMjS/M7pTMoulLASIiKi5ovhxoAmhPqK22lqXpoiIiKSAsONAbVzs0dPPycAQHqeRuJqiIiImieGGwNzVSoAMNwQERFJheHGwNyUt++YKpK4EiIiouaJ4cbAWrvYAgC+338VpVqdxNUQERE1Pww3BnZ7Ij8A+PPkdQkrISIiap4YbgwssKVS3D55LUe6QoiIiJophhsDs1WYY8agtgCArAIOKiYiIjK2RhNuFixYAJlMhpkzZ1bbZtWqVZDJZHoPKysr4xVZS119HAAA129yUDEREZGxmUtdAAAcP34cy5cvR6dOne7ZVqlU4vz58+K+TCZryNLqxc+5fFDx1cwClGl1MDdrNBmSiIjI5En+q5ufn4/x48fj+++/h6Oj4z3by2QyuLu7iw83NzcjVFk3Pk42sFOYQ1Omw+UMrhBORERkTJKHm2nTpiE8PBxhYWG1ap+fnw9fX194e3tjxIgRiI+Pr7G9RqOBWq3WezQ0uVyGwJbld02dS234zyMiIqI7JA0369atw8mTJxEREVGr9u3bt8eKFSuwadMm/Pzzz9DpdOjTpw+uX6/+luuIiAioVCrx4e3tbajya+TtaAMASM7hGlNERETGJFm4SUpKwowZM7BmzZpaDwoODQ3FxIkT0aVLFwwYMAB//vknXFxcsHz58mpfM2vWLOTm5oqPpKQkQ32FGrmrOFMxERGRFCQbUHzixAmkp6cjJCREPKbVarFv3z4sWbIEGo0GZmZmNb6HhYUFunbtikuXLlXbRqFQQKFQGKzu2mrpYA0ASMllzw0REZExSRZuBg0ahNjYWL1jkydPRkBAAN5+++17BhugPAzFxsZi2LBhDVVmvbW8tcZUEm8HJyIiMirJwo29vT2Cg4P1jtna2sLZ2Vk8PnHiRHh6eopjcj788EP07t0b/v7+yMnJwcKFC3Ht2jW88MILRq//XoI8ymcqvpCWh8KSMthYNoq77omIiExeo/7FTUxMhFx+Z1jQzZs38eKLLyI1NRWOjo7o1q0bDh06hKCgIAmrrFpLlRXclAqkqTU4k6xGdz8nqUsiIiJqFmSCIAhSF2FMarUaKpUKubm5UCqV937BfXjqu8M4ciUbi57qghFdPBv0s4iIiExZXX6/JZ/nxpR5qMoHFf8dkyxxJURERM0Hw00DcrCxBAD8ezYdaWreNUVERGQMDDcNyNHGQtxOzC6UsBIiIqLmg+GmAU3s4yduZxeUSFcIERFRM8Jw04BU1hYY2N4FAPDy6hPQ6prV2G0iIiJJMNw0sLziMnE7iZemiIiIGhzDTQNLybkzQ/F1zlZMRETU4BhuGtiEUD9xm4OKiYiIGh7DTQN7oV8rtHGxBQCcT1VLXA0REZHpY7hpYBZmcrw5JAAAsPt8BnQcVExERNSgGG6MoG/bFrBXmCMxuxD/nk2TuhwiIiKTxnBjBHYKczza2QMAEJ2UI20xREREJo7hxkgCW9oDAC6m5UtcCRERkWljuDESf1c7AMCl9DyJKyEiIjJtDDdG4udcfsfUjZwizlRMRETUgBhujMRNaQULMxlKtQJSuUI4ERFRg2G4MRIzuQyeDtYAgMQsTuZHRETUUBhujKidW/mg4iNXsiSuhIiIyHQx3BhRWJAbAODApUyJKyEiIjJdDDdGFOBe3nPD1cGJiIgaDsONEXk52gAA0vM00JRpJa6GiIjINDHcGJGjjQWsLcwAAMk5vGOKiIioITDcGJFMJoOXY/kdUzduFklcDRERkWliuDEyz1vh5vpNjrshIiJqCAw3Rib23OSw54aIiKghMNwYmadD+aDi+GS1xJUQERGZJoYbIxvQzgUyGbDrXDoSMgukLoeIiMjkMNwYWZCHEj18nQAAAz/fg+JS3hJORERkSAw3EhjexUPcfvh/eyWshIiIyPQw3EjgmV4+4nZSNgcWExERGRLDjQRkMpnefqlWJ1ElREREpofhRiKT+viJ2wWaMukKISIiMjEMNxKZPSxQ3M4rZrghIiIyFIYbiViay9HCTgEAyGfPDRERkcEw3EjI3socAMMNERGRITHcSMhOwXBDRERkaAw3Erodbk4k3JS4EiIiItPBcCMhb6fyRTS3xqZIXAkREZHpYLiR0H8fbg8AuJJZgM2nkyWuhoiIyDQw3EjIXWUF+1uXpqavjca1LC6kSUREdL8YbiQ2KsRT3E7MLpSwEiIiItPAcCOx94Z3ELez8kskrISIiMg0MNxIzEwuw2Ody1cJz8zXSFwNERFR08dw0wg421kCALIK2HNDRER0vxhuGoHbyzBk5LHnhoiI6H4x3DQCLVVWADigmIiIyBAYbhoBL0cbAMCxq9nYxgn9iIiI7gvDTSPg5Wgtbr//V7yElRARETV9DDeNgJvSStx2V1nV0JKIiIjuheGmETCTy/DO0ABxm4iIiOqP4aaR6OHnBIBz3RAREd0vhptGwuXW7eDpag10OkHiaoiIiJouhptGwsPBCtYWZtCU6XA5I1/qcoiIiJoshptGwtxMjs7eKgDA1DUnoWXvDRERUb0w3DQi3XwdAQCX0vPx58nrEldDRETUNDHcNCLBHipx+9DlLAkrISIiaroYbhqRhwJdxe0N0TdwLatAwmqIiIiaJoabRkRhboY3BrcT9/deyJCwGiIioqaJ4aaRySsuE7ff2xSPohKthNUQERE1PQw3jczobl56+4cuZ0pUCRERUdPEcNPItHOzRwcPpbgv8I5wIiKiOmG4aYRa3JqtGAB0TDdERER1wnDTCFUMNPmashpaEhER0d0YbhqhirMTq4tKJayEiIio6WG4aYTKKoabYvbcEBER1QXDTSNUcVXwvGL23BAREdVFowk3CxYsgEwmw8yZM2ts99tvvyEgIABWVlbo2LEjtm7dapwCjSiw5Z27pdLzNBJWQkRE1PQ0inBz/PhxLF++HJ06daqx3aFDhzBu3Dg8//zziI6OxsiRIzFy5EjExcUZqVLjePOR9vB0sAYAbDqVzJmKiYiI6kDycJOfn4/x48fj+++/h6OjY41tFy1ahEceeQRvvvkmAgMD8dFHHyEkJARLliwxUrXGobSywIpJPcT9hTvOSVgNERFR0yJ5uJk2bRrCw8MRFhZ2z7aHDx+u1G7IkCE4fPhwQ5UnGV9nG3HbpcK8N0RERFQzcyk/fN26dTh58iSOHz9eq/apqalwc3PTO+bm5obU1NRqX6PRaKDR3Bm3olar61eskVlZmGHqwDZYuucydJzHj4iIqNYk67lJSkrCjBkzsGbNGlhZWTXY50REREClUokPb2/vBvssQ+vuW36Zbu+FDFzOyJe4GiIioqZBsnBz4sQJpKenIyQkBObm5jA3N8fevXuxePFimJubQ6utvBq2u7s70tLS9I6lpaXB3d292s+ZNWsWcnNzxUdSUpLBv0tDcbK1FLe/3HlBwkqIiIiaDskuSw0aNAixsbF6xyZPnoyAgAC8/fbbMDMzq/Sa0NBQREZG6t0uvnPnToSGhlb7OQqFAgpF0xyz0lJlLW7fLCiRsBIiIqKmQ7JwY29vj+DgYL1jtra2cHZ2Fo9PnDgRnp6eiIiIAADMmDEDAwYMwBdffIHw8HCsW7cOUVFR+O6774xevzG4q6zwn7B2+N+/F3Ay8SYy8zV6i2oSERFRZZLfLVWTxMREpKSkiPt9+vTB2rVr8d1336Fz5874/fffsXHjxkohyZS8Nsgf7dzsUFyqw5ErWVKXQ0RE1OhJerfU3fbs2VPjPgCMGTMGY8aMMU5BjYBMJkN7dyUupOUjNbdY6nKIiIgavUbdc0Pl3OzLL0VtjU25R0siIiJiuGkCHG/dNXUyMQcJmQUSV0NERNS4Mdw0ARVnK+Z8N0RERDVjuGkCHulwZx6fm4WlElZCRETU+DHcNAHmZnI83tUTAJCVr7lHayIiouaN4aaJcL417uZKBsfcEBER1YThpolwvjV5369RSUhX85ZwIiKi6jDcNBGDAl3F7Z6fRELHpcKJiIiqxHDTRLRzs9fbVxdzYDEREVFVGG6aEL8Kt4Rn5nMhTSIioqow3DQhS54OEbezuUo4ERFRlRhumpBgTxVCfBwAANkFvCWciIioKgw3TYyTbfldUxl5DDdERERVYbhpYlxuLaI5d1M8Zm+IlbgaIiKixofhponxcbozqHjt0UQJKyEiImqcGG6amIqLaBIREVFlDDdNTKsWtnr7Wk7mR0REpIfhpokJbKnExyODxf08TuZHRESkh+GmCXqmty9sLc0AAK+vj+FSDERERBUw3DRRSmsLAEDkuXQcS8iWuBoiIqLGg+GmiSos0YrbBZoyCSshIiJqXBhumqherZzEbS7FQEREdAfDTRM1//GO4jYX0SQiIrqD4aaJcrFX4OX+rQEAn24/B0HgoGIiIiKA4aZJ83e1E7fPpeZJWAkREVHjwXDThI3s6gmFefkf4c4zaRJXQ0RE1Dgw3DRhFmZyRIwqH3vz0+EEXpoiIiICw02TF96pJczkMmTmlyBNrZG6HCIiIskx3DRxCnMzcTHNyxn5EldDREQkPYYbE+DvUj6w+MiVLIkrISIikh7DjQkI79QSAPBb1HWJKyEiIpIew40JGBToBgBIVRfjJmcrJiKiZo7hxgTYKczh5WgNgPPdEBERMdyYiLa3JvRLyCqQuBIiIiJpMdyYCM9bPTfJOUUSV0JERCQthhsT4eFQHm6+3nUJv5/gwGIiImq+GG5MhOetcAMAczfGSVgJERGRtBhuTERf/xbitqONhYSVEBERSYvhxkQ42ynwy4u9AQDWlmYSV0NERCQdhhsTorQ2BwBczihAfHKuxNUQERFJg+HGhCit7lyOCl98APO3nJGwGiIiImkw3JgQpbX+WJvv91+FIAgSVUNERCQNhhsTYqcwr3SsqFQrQSVERETSYbgxIWZyWaVjNwtLJaiEiIhIOgw3Jmbra/309nMKuZAmERE1Lww3JibIQ4ljsweJ++GLDyBNXSxhRURERMbFcGOCXJVWevt7z2dIVAkREZHxMdyYqLBAN3H7QlqehJUQEREZF8ONiYoY1RED27sAAOI4oR8RETUjDDcmysVegQ8e6wAAOHY1G+l5HHdDRETNA8ONCfN1tkV7N3voBCDuBntviIioeWC4MXH+rnYAgH0XMiWuhIiIyDgYbkxcaxdbAMCqQwko0JRJXA0REVHDY7gxcY928hC3UznfDRERNQMMNyauvbs9vBytAQDqIi7FQEREpq9e4SYpKQnXr18X948dO4aZM2fiu+++M1hhZDhKq/LVwtXFvCxFRESmr17h5umnn8bu3bsBAKmpqXj44Ydx7NgxzJkzBx9++KFBC6T7p7QuXy08lz03RETUDNQr3MTFxaFnz54AgPXr1yM4OBiHDh3CmjVrsGrVKkPWRwagsr7Vc8NwQ0REzUC9wk1paSkUCgUA4N9//8Vjjz0GAAgICEBKSorhqiODuH1Z6t2NcYjnbMVERGTi6hVuOnTogGXLlmH//v3YuXMnHnnkEQBAcnIynJ2dDVog3T/lrZ4bAFh9+JqElRARETW8eoWbTz/9FMuXL8fAgQMxbtw4dO7cGQDw119/iZerqPEY3vnO7eCJ2YUSVkJERNTwZIIgCPV5oVarhVqthqOjo3gsISEBNjY2cHV1NViBhqZWq6FSqZCbmwulUil1OUYTdyMXj359ANYWZjjw9oNwtlNIXRIREVGt1eX3u149N0VFRdBoNGKwuXbtGr766iucP3++UQeb5qyDhxIdPVUoKtVi6Z7LUpdDRETUYOoVbkaMGIGffvoJAJCTk4NevXrhiy++wMiRI7F06VKDFkiGIZPJ8N+H2wEA1h5LRG4h75wiIiLTVK9wc/LkSfTr1w8A8Pvvv8PNzQ3Xrl3DTz/9hMWLFxu0QDKcAe1c4KGyQmGJFu9uipO6HCIiogZRr3BTWFgIe3t7AMA///yDUaNGQS6Xo3fv3rh2jXfjNFZyuQzvDe8AAPg7JhkrDlyVuCIiIiLDq1e48ff3x8aNG5GUlIQdO3Zg8ODBAID09PRmNUi3KRrSwU3cPnHtpoSVEBERNYx6hZv33nsPb7zxBvz8/NCzZ0+EhoYCKO/F6dq1a63fZ+nSpejUqROUSiWUSiVCQ0Oxbdu2atuvWrUKMplM72FlZVWfr9BsyWQyfDq6IwDgZmGJxNUQEREZnnl9XvTEE0+gb9++SElJEee4AYBBgwbh8ccfr/X7eHl5YcGCBWjbti0EQcCPP/6IESNGIDo6Gh06dKjyNUqlEufPnxf3ZTJZfb5Cs+amLA+ENzmomIiITFC9wg0AuLu7w93dXVwd3MvLq84T+A0fPlxvf/78+Vi6dCmOHDlSbbiRyWRwd3evX9EEAHC0sQQAnE1Ro6hEC2tLM4krIiIiMpx6XZbS6XT48MMPoVKp4OvrC19fXzg4OOCjjz6CTqerVyFarRbr1q1DQUGBeJmrKvn5+fD19YW3tzdGjBiB+Pj4Gt9Xo9FArVbrPZq72+EGAN7+47SElRARERlevcLNnDlzsGTJEixYsADR0dGIjo7GJ598gq+//hpz586t03vFxsbCzs4OCoUCU6ZMwYYNGxAUFFRl2/bt22PFihXYtGkTfv75Z+h0OvTp00fsPapKREQEVCqV+PD29q5TfabIwfbOWlN/xSRjzVHe4UZERKajXssveHh4YNmyZeJq4Ldt2rQJr7zyCm7cuFHr9yopKUFiYiJyc3Px+++/44cffsDevXurDTgVlZaWIjAwEOPGjcNHH31UZRuNRgONRiPuq9VqeHt7N7vlFyoSBAGtZ29FxT/5hAXh0hVERER0Dw2+/EJ2djYCAgIqHQ8ICEB2dnad3svS0hL+/v7o1q0bIiIi0LlzZyxatKhWr7WwsEDXrl1x6dKlatsoFArxbqzbj+ZOJpNh+4z+ese0unotMUZERNTo1CvcdO7cGUuWLKl0fMmSJejUqdN9FaTT6fR6Wmqi1WoRGxuLli1b3tdnNkft3Ozw3AOtxP2MvNqdcyIiosauXndLffbZZwgPD8e///4rDv49fPgwkpKSsHXr1lq/z6xZszB06FD4+PggLy8Pa9euxZ49e7Bjxw4AwMSJE+Hp6YmIiAgAwIcffojevXvD398fOTk5WLhwIa5du4YXXnihPl+jWZPJZHhveBBWHCyfpbh3RCSi3g1DC64WTkRETVy9em4GDBiACxcu4PHHH0dOTg5ycnIwatQoxMfHY/Xq1bV+n/T0dEycOBHt27fHoEGDcPz4cezYsQMPP/wwACAxMREpKSli+5s3b+LFF19EYGAghg0bBrVajUOHDtVqfA7d28urT0hdAhER0X2r14Di6sTExCAkJARardZQb2lwdRmQ1Bz8efI6/rs+RtznwGIiImqMGnxAMZmOx7t6Sl0CERGRQTHcNHMymQzuyjvrc727MRYpuUUSVkRERHR/GG4I22f2E7d/PpKIuRvjJKyGiIjo/tTpbqlRo0bV+HxOTs791EIScbCxhJlcJs51E3sjV+KKiIiI6q9O4UalUt3z+YkTJ95XQSSNX1/qjSeWHQYAONnydnAiImq66hRuVq5c2VB1kMS6eDuI27ZcJZyIiJowjrkhAIC5mRy/vNgbAJBdWCJxNURERPXHcEMiF3tLAECGWgNBEFBSppO4IiIiorpjuCGRl6MNzOQy5GnKMOKbgwiNiERuYanUZREREdUJww2JrCzM4OdsAwA4fT0XWQUlOHg5U+KqiIiI6obhhvT0a+uit19c2niX0iAiIqoKww3pmT0sEF8+2VncT8ktlrAaIiKiumO4IT2W5nKMCvHCy/1bAwAuZ+RLXBEREVHdMNxQlTrfmvdmc0wK1MUcVExERE0Hww1VaWiwO5xsLVGi1eFSOntviIio6WC4oSrJZDK0c7MDACRkFkhcDRERUe0x3FC1WrWwBQCsj0qSuBIiIqLaY7ihao0K8QIAHLmSjXf+OC1xNURERLXDcEPV6uHnJG6vO54EQRAkrIaIiKh2GG6oRuN6+ojb6qIyCSshIiKqHYYbqtG74YHi9mvroqHVsfeGiIgaN4YbqpGtwhz+ruV3Te29kIHIs2kSV0RERFQzhhu6p9DWzuJ2Rr5GwkqIiIjujeGG7mlOhUtT6WqGGyIiatwYbuierCzM8PrD7QAAKblFEldDRERUM4YbqhVPR2sAwKX0fBSVaCWuhoiIqHoMN1QrnbxUAICTiTkY9MUe5BZyMU0iImqcGG6oVlq3sEMLOwUAIDm3GAu2n5O4IiIioqox3FCtyOUyrJrcA8M7ewAoX2+qpEwncVVERESVMdxQrQV7qrD4qS6wtTSDVicgIYurhRMRUePDcEN1IpPJ4O1kAwAIX7xf4mqIiIgqY7ihOnOxLx97U6rlUgxERNT4MNxQnX0xprO4rSnjbeFERNS4MNxQnd2+awoAhvxvH4pLGXCIiKjxYLihOpPLZeJ2QlYhPvg7XsJqiIiI9DHc0H07eS1H6hKIiIhEDDdULz9M7A4PlRUA4HxaHvKKOWMxERE1Dgw3VC9hQW74fWofcf/J5Uc49oaIiBoFhhuqN1f7OwOLz6aoMXDhHumKISIiuoXhhurN3EyON4e0F/dT1cUo1XJJBiIikhbDDd2XaQ/6Y97wIHE/TV0sYTVEREQMN2QAz/bxE7cf//YQx94QEZGkGG7ovslkd+a9ycjTYOQ3B7H/YoaEFRERUXPGcEMG8fHIYHH7XGoeJvzfMVy/WShhRURE1Fwx3JBBPNPbFzHvD9Y7tuc8e2+IiMj4GG7IYFTWFujgoRT3Y6/nSlgNERE1Vww3ZFCrn++F/z7cDgDwa1QStpxOkbgiIiJqbhhuyKCcbC0xKNBV3J+29qSE1RARUXPEcEMG5+9qp7ev0wkSVUJERM0Rww0ZnMLcDMsndBP3c4q4qCYRERkPww01iCEd3GFvZQ4AyC7QSFwNERE1Jww31GCcbS0BAFn5JRJXQkREzQnDDTUYp1vhZs3RRMQn87ZwIiIyDoYbajC+zrYAgL9ikjFiyUFcyciXuCIiImoOGG6owTjaWIrbZToB3+27ImE1RETUXDDcUIMZFeKpt7/ueBKSsrneFBERNSyGG2owwZ4q7PxPf8S8PxgP+DsDAP4+nSxxVUREZOoYbqhBtXWzh8raAo8EtwQAfLb9PLLyeWs4ERE1HIYbMoqHAlxhJpcBAF7/LQZlWp3EFRERkaliuCGj8HSwxpdPdgYA7DmfAf852/DDfg4wJiIiw2O4IaMZ3slDb//jLWclqoSIiEwZww0ZjVwug6eDtd6xQ5cyJaqGiIhMFcMNGdX6KaF6+0//cFSiSoiIyFQx3JBReTpYY+2LvaQug4iITBjDDRldiI+j3v4DC3YhOadIomqIiMjUMNyQ0VlZmKGjp0rcv5FThC93XpCwIiIiMiWShpulS5eiU6dOUCqVUCqVCA0NxbZt22p8zW+//YaAgABYWVmhY8eO2Lp1q5GqJUP6Y2ofPN71zvIMmZzYj4iIDETScOPl5YUFCxbgxIkTiIqKwkMPPYQRI0YgPj6+yvaHDh3CuHHj8PzzzyM6OhojR47EyJEjERcXZ+TK6X5Zmsv11p7acz4Dfu9swZTVJyAIgoSVERFRUycTGtkviZOTExYuXIjnn3++0nNjx45FQUEBNm/eLB7r3bs3unTpgmXLltXq/dVqNVQqFXJzc6FUKg1WN9XPZ9vP4ds9l/WOHZk1CO4qK4kqIiKixqguv9+NZsyNVqvFunXrUFBQgNDQ0CrbHD58GGFhYXrHhgwZgsOHD1f7vhqNBmq1Wu9BjcdbjwTAx8lG7xgvURER0f2QPNzExsbCzs4OCoUCU6ZMwYYNGxAUFFRl29TUVLi5uekdc3NzQ2pqarXvHxERAZVKJT68vb0NWj/dP28n/Yn9Hv36ABIyCySqhoiImjrJw0379u1x6tQpHD16FFOnTsWzzz6LM2fOGOz9Z82ahdzcXPGRlJRksPcmw5g1NBAWZjK9Y3M2xqK4VCtRRURE1JRJHm4sLS3h7++Pbt26ISIiAp07d8aiRYuqbOvu7o60tDS9Y2lpaXB3d6/2/RUKhXg31u0HNS7Bniqcfn+I3rGDl7IwYOFuXqIiIqI6kzzc3E2n00GjqfoHLTQ0FJGRkXrHdu7cWe0YHWo6rC3N0M1Xf3K/NLUGx69mS1QRERE1VeZSfvisWbMwdOhQ+Pj4IC8vD2vXrsWePXuwY8cOAMDEiRPh6emJiIgIAMCMGTMwYMAAfPHFFwgPD8e6desQFRWF7777TsqvQQbyvye7YMXBq3ihXyt8+c8F/Bl9A5cz8qUui4iImhhJw016ejomTpyIlJQUqFQqdOrUCTt27MDDDz8MAEhMTIRcfqdzqU+fPli7di3effddzJ49G23btsXGjRsRHBws1VcgA/JxtsG8xzoAANq42gEALqYz3BARUd00unluGhrnuWka9pxPx6SVxwEAT3TzwphuXujV2lniqoiISCpNcp4booq6+zmJ27+fuI7nVh1HgaZMwoqIiKipYLihRslOoX/FtKBEi1+OJUpUDRERNSUMN9Rk/LD/KtedIiKie2K4oUbr9qrhgS2VMJPLkKouxsnEm9DpGHCIiKh6DDfUaM0b3gGzhwVg5aQeCGxpDwAYvfQwvth5XuLKiIioMWO4oUZLZWOBl/q3gbvKCoHud0bGf7P7cg2vIiKi5o7hhpqE9u72evtPLjuMU0k50hRDRESNGsMNNQmhbfTnuDmWkI2R3xxEUnahRBUREVFjxXBDTUIHDxV2/qd/peOPfn1AgmqIiKgxY7ihJsP/1pIMFeUWleLl1VEoLtVKUBERETVGDDfUZMhksiqP74hPw/8duIpBX+zB3I1xRq6KiIgaG4YbalJaqqwAAJ4O1vB1thGPL9xxHpczCrD6yDVk5GmkKo+IiBoBhhtqUlZO7oGHAlyxfEI32FpWvaj9cI7DISJq1hhuqEkJcFdixaQeCPZU4eEgtyrbpKqLcT41z8iVERFRY8FwQ03WKw+2wduPBGBmWNtKzw35ah92nUuToCoiIpIaww01WQpzM0wd2AYPBbiKx4Ja3pnJ+LlVUVxok4ioGap60AJRE9Le3R7Bnko42ljC19kGZ1LU4nNxN9S4kpmPEB9HeDvZ1PAuRERkKmRCM/unrVqthkqlQm5uLpRK5b1fQE3K9rhUTPn5RKXjrVvYYtcbA41fEBERGURdfr95WYpMypAObljzQi/89FxPveNXMgskqoiIiIyNl6XIpMhkMjzg3wIAEOypRNwN9T1eQUREpoY9N2Sy3nkkUG//QhpvDyciag4YbshkPeDvjE9HdxT3B/9vH1Jzi5GYxZXEiYhMGcMNmSyZTIaxPXz0jvWOiET/hbtx+HKWRFUREVFDY7ghk/feo0GVjo37/giiE29KUA0RETU0hhsyec/1bYUtr/WtdHzc90ckqIaIiBoaww01Cx08VOjXtoXeseJSHRb9e1GiioiIqKEw3FCz8frg9pWO/e/fC3hu1XGsO5YoQUVERNQQGG6o2eji7YDZwwIqHd91Lh3v/BmLrbEpXIuKiMgEMNxQs1KqrT68vLLmJFrN2oq/YpKNWBERERkaZyimZqVAU3bPNq/9Eo3fopIwoJ0LBge5o6WDFSzM+O8AIqKmgn9jU7MyuIM7AMDG0gx/vtKn2nb7L2bi4y1n0X/hbny965KxyiMiIgPgquDU7JxPzUNLBysorSxw+HIWfjqcgLZu9lgcWf2dUwkLwo1YIRER3a0uv9+8LEXNTnt3e3E7tI0zQts4Q6cTEOyhRHyyGouqCDkFmjLYKvh/FyKipoCXpYgAyOUyDO7gjv883A6vPeRf6fnen0RCp2tWnZxERE0Www3RXWQyWaVjeZoyxFzPQWJWIf776ynEJ+fqPV9cqkVJmc5YJRIRUQ3Yz05US49/ewhyGaATgD+jbyB67sNwtLVEmVaHhz7fAzMzGfa+8SDk8srhiIiIjIc9N0Q1+GJMZ739ilemVhy8isKSMpxKykFybjGSsouQU1Rq5AqJiOhu7LkhusuTPbyxKPIiwgJdMSrEEwPbu+DQ5Sy8+ku0XrtNp5Lx+4nrSMktFo9lF2jgZGtp7JKJiKgChhuiu3g6WCN23mDYWppDJpPB2U6BocHuaOdmhwtp+WjVwhZXMwuQmF1Y6bWZ+SXwdwW+3HkB6qJSvD88qMoxPERE1HB4WYqoCvZWFnpjZ8zN5Fj3UihWTe6B36aEwr6a28K/33cFJWU6LI68iFWHEnAxPd9YJRMR0S0MN0S15GRriYHtXdHCToHHunhU2SbyXDpyikrE/Rs5RVyMk4jIyBhuiOrh9cHtEeLjgFEhnpWe++vUnYU3J688jmlrTxqzNCKiZo/LLxDdJ793ttyzTVigKyaG+qF/OxcjVEREZHrq8vvNnhsiI/j3bDomrjiG5JwiqUshIjJ5DDdE92nyA361bttnwS6cT81ruGKIiIjhhuh+vTM0AKuf71nr9m/9cRoR287i5dVRSMouxLbYFGi5bhURkcFwzA2RgRy9koU/Tl7Hqw+1xYboGxjZxROW5nI8/L+9yCsuw6iunvgz+kaVrx3TzQtt3ezwYHtXtHWzr7INEVFzVpffb4YbogaWla9B0s0idPF2wK/HE/H2H7E1tj/z4RDYWHJ+TSKiijigmKgRcbZToIu3AwBgRJfKt47f7WJaPrQ6AV9HXsQLP0Yhl+tVERHVCf95SGREVhZm92zz2Y5zOHHtJopLdQCAnvP/xYZXHkCQB3saiYhqgz03RI3MwUtZYrABAE2ZDv934KqEFRERNS0MN0RGtv7lUEwZ0AaPdHAXjx2dPQi9WztV+5pL6bx9nIiotnhZisjIerZyQs9WTvh8x3kgvvyYg40F8orL9Nq1drHFsme6YfD/9iHmei6W7LqIA5cy0drFDr1aOWHpnsu4cbMI7dzt4edsi9HdPKG0soCXozUcbCwl+GZERI0Dww2RRF4e0BpyGeCusobC3Ewv3PwxNRSu9lZwU1rBydYS2QUl+PyfCwCAI1eysfZootj2xLWbOHHtJv44eR0A4K60wpHZgwAA6epiPP3DUQwKcMWsYYFG/HZERNLhZSkiidhbWeC/g9vj6V4+AICgluUDhuUyoJuvE7ydbGBpLsdbQ9rX6X1T1cX4ft8VAMCn28/jUno+lu+7AkEQoCnTolSru8c7EBE1bey5IWokPhjRAY62lpjQ21fv+OMhnvj3bBr+PZte6/dauvcylNbmYm8OAKTkFmPMssNQWltg62t9IZPJDFY7EVFjwkn8iJqIvRcysPtcOlYdStA7vnHaAxj5zcF7vt7VXoH0PA0A4PS8wVBaWVTZTlOmxZPLj6B1C1v8b2yX+y2biMggOIkfkQka0M4F8x7rAKXVnQ7XY3MGiRME3svtYAMAcTdy8cuxRERsOwtBEBB7PRff7rkETZkWZ5LViEnKwYboG0jILDD01yAianC8LEXUxKyY1APvbozD+8M7wNXeCgAQ7KlE3A01AMBDZYXk3OIa3+Pp74+K28v3XhG3j1/NRp82LcT9gZ/vweZX+yLYU2Ww+nMKS3g3FxE1KPbcEDUx3f2csH1mf4S2cRaPfTehu7jt18IW617qDQBwtLGodc8OAOw+n4H5W8/qHXv06wMIjYjE3gsZ9ao3r7gU0Yk3IQgCVh68ii4f7sTm08n1ei8iotpguCEyAR4O1lg5qQd6tnJCxKiO6N3aGQkLwhH93mAEuN//KuMpucV4dsUxjF56CJtPJ6OwpAyFJWVYH5WEcd8dQU5hCXafS8fwrw8gPjlXfJ1OJyB88QE8/u0h7DyThg/+PgMAmLsxrsbPK9PqcCk9D81sSCARGQgHFBOZuOScIvRZsAsA4Otsg2tZhbV63WOdPfBXTN17WDp6qvD3q30BAAu2ncOyvZcBAH39W+DApUwAgI+TDfa99WC17/HGbzH4/cR1fDGmMx7wbwFnO0tYmN35t1hWvgbro67j0U4t4e1kU+caiajpqcvvN8MNUTOg0wk4dT0HQS2V0JTq8PLPUbAwk2P/xUyxze3JAm+b/qA/vtlzCXX9G8LRxgJ927ogJikHidnVB6nZwwLwQt/WkMsr35Lu984Wvf2X+rfG7AqTEH68+Qx+OHAVluZy/D29L9oboHeKiBo3hpsaMNwQ3aEuLoXCXI7knGJ4OVrj1+NJsFWYYeeZNLzzSCCuZOZj0srjDfb5C5/ohDKdAIW5HKNCvAAApVod2s7ZVqltwoJwcXvI//bhfNqd9bZ+mNgdYUFuVX6GpkyLxKxC+Lva3ffcPrHXc+Fir4C7yuq+3ocaXlGJFtaWZlKXQQZUl99v3i1F1IzdnuumVQtbAMAztyYQfLxredBwVSoa9PP3XczE37cuff13fQz6tW2Bo1eyq2ybU1iCaWtPolcrZ1zOyNd77sud5UtT9GrtBPu75u95fX0MNp9OwfIJ3TCkgzuKSrSIuZ6DHn5OMLur1+hCWh6mrD6BVwf5i+dAEARM/fkkoq5lIzO/vGerYtC6W1GJFpbm8krvTcbz1b8X8NW/F7Hupd7o3dr53i8gk8MBxURULSsLM6yc3EPct1MY9t9Df981pmf/xUyUVLM8xNPfH8XBS1n4cucFlOn0O5zPpKjxwk9ReGzJQZy4dhNJFS6HbT6dAgD4dvclAMC8v+Lx1HdHxLFAFc3ZEIsrmQX4z68xuJyRD51OwLK9V7A9PlUMNgCqHeisLi5Fj/n/Ytz3R6Ap09biDDSs1NxifLz5DK5lNa/5ir769yKA8j9rap4YboioRg+2dxW3zc1keH94kLj/Qt9WMDdSD8WZFPU921zNLMDopYfQ77PdmPdXPNLUd+b7ibmei2GL9uPXqCQAwMId5yEIAk4l5SC3qBQAxP8FgEFf7MXyfVfw6fZzlT6nsKTq4LL/QibyNWU4djUbIR/uRGJWIXQVgpggCEjNLa4UjiLPpmH/Rf1b7dXFpcjX6K8UX1fT157EDweu6s1rVJ3Ckvv7rLvla8pwKT3v3g1r8T6x13Pv3bAKci4x0mxJGm4iIiLQo0cP2Nvbw9XVFSNHjsT58+drfM2qVasgk8n0HlZWvP5N1JAGtHMBADz3QCs8G+qH7TP74dL8oXj30SDsfmMg+vq3wMpJPTA02B0A8OnojmjragcA6NPGGZ3vmmvn8ifD4Hafl7z8nGu+S2rVoYRK44XuDkjf7buCkd8cROcP/sGmUzdwIU3/ctf3+6+gKpn5Gly/WYj5W84gK18DrU7AplM39MJRQYkW/RfuRtiXe1FSVt4b9cfJG+gdEYlpa09i9oZY+L2zBR/8HY/nf4zChP87hus3CxF3Ixf5mjI89PlePP7NQWh19R8WGXXtJgDgRk4RrmYWYGtseS/WiWvZmLbmJG7kFAEAfjmWiOD3d2B7XEq9PwsoD2/PrzqOGeui8fg3BxH25T6cvp5T69dX1dv13MrjGL7kAHadSwNQPk1AbYeKyvnP92ZL0jE3e/fuxbRp09CjRw+UlZVh9uzZGDx4MM6cOQNbW9tqX6dUKvVCEBcAJGpYi5/qiiNXs/Bge1fI5TIEuN8ZzOftZIOfX+gFAOjd2hnTHsxHBw8lBrZ3xff7ruClAa3x4o9RYntnW0uYyWX4dnwIRi89DAD4cEQHxCTl6i30eVs3X0ecuPUjfVv/di4Y18MbU9ecrLHus/fo7YnYdqdXZsa6U5Wer3j3WEWfbT+Pyxn5OJeah2tZhQjyUIqXQu52JbMABy5lQAYZ3vgtBgCwNTZVfH7lwQRxu++nuwGU36mWma9BZr4GR65koZuvI3afS8eDAa6QyQCFed0Hyg5btB9FpVo837cV/u/AVQDA+bQ8LH6qK2b9GQsAmPLzSbjYKzC2uzdeH9wO0Uk58FBZw11lhaISLY5cyRInjyzQlGHqzydhJpdhzQu9IJfL8P5f8Yg8p7/A65bYFAS2VOLN32LQzc+p0sKwt/10OAEfbT6DVZN7QicIePWXaMweFohjCdnieerd2hkPf7kPAe72+L9JPfRer9MJle68q0vPTZlWB60g1OvcUuPTqO6WysjIgKurK/bu3Yv+/ftX2WbVqlWYOXMmcnJy6vUZvFuKyPjmbIjFmqOJAIB//tMf7dzskZhViP4Ly3/Mv5/YHWGBrtCU6VBYooUgCNh0Khm/Hk/Cj8/1RKlWh36flbft3doJq5/vBXO5DF/uvICvd11q8PqtLOQoLq16LFBDeyjAFX3aOOPjLeUzR1uaybF+Sig6e6mQptbgZOJNeDpYV+odA4A2s7fWu+dn2oNt8M3u8nFJS57uiulrowEAz4b64nJGgThnEQAcnT0IjjaWaPdu5bvcpgxoAydbC3yytTxIhndsifG9fcRlPnQ6AdFJORi99JD4GktzudjbdVt7N3u8OshfrGNIBzeEd/KAtYUZohNv4ucj1/DnK33g72ovTiXQ2dsBm6Y9oPc+648nIT45F+8P7yCGoTKtDo8s2g+dTsDWGf1gZVFzwNl/MQNbTqdg7qNBsL3HOLSTiTcxfc1JzA4PxKOdPGpsW1+HLmVi2b4r+HhEMHzu0aPZlDXZu6Vyc8uvqzo5OdXYLj8/H76+vtDpdAgJCcEnn3yCDh06VNlWo9FAo7mzYKBafe/r9kRkWG89EgALMzke7+qJdm7lc9K0sL+zvpTK2qL8ErOFmfjD8lzfVniubyuxzexhAVgceQkfPBYsTuj3+uD2GBXihWd+OIqMfA1CfBwwoJ2rOE5GaWWOaQ/66/XQ3K2bryNc7BTYHp9a5fNdvB2wcdoDWHs0EbM3xN7fiaiHXefSsa/C0hclWh3mbIjF2B7eeG/TnQGzW1/rhyW7L6JXK2eM6OKBi+n5MJPJoEX9ws3tYANADBQA8OPha5Xanr6eW+kOttvWRyXp9YBtiU3BltgU9PVvgSEd3DB3U+VBv3cHG6C8l6liHTvi07AjPk2vzX/Xx+Cbp0PEfbkMmPVnLHIKS/DN0yGQy2V464/TAABbhTleH9weWQUaZBeU4FJ6ef2RZ9MR3qllld/ltgn/dwwA4GxniVEhXpi57hTau9tj4ROdcCk9H34tbMX/Rl9dG43k3GJMXxuNvv4t8P5f8Rga7I5Hgmv+jOrEJ+dixYEE/HdwO3g6WAMAnv6hfEzVnI2xWDC6E/KKS/V6V4Hyc3ohLQ+tWtjCxtKsXlc88jVlyC8uq3EqhIw8DdLziuFirxDXvpNCo+m50el0eOyxx5CTk4MDBw5U2+7w4cO4ePEiOnXqhNzcXHz++efYt28f4uPj4eXlVan9vHnz8MEHH1Q6zp4bIuk99PkepOQWI+rdsHv+C7i2BEHAHydvoLuvI3ydbSCTyfDT4QRsjkkRL3FU9HQvH3w8Ihg7z6bh5dUnKj0/rKM7vh3fTXzvsd8dwbGr5e8zb3gQvt9/FSpri1oNeK5Ov7Yt9CZU7OrjgEKNVm8un7pwV1ohVV3z4qnNzUcjOmDnWf2g2NlLhZjruejZykn8M32+byvMfTRI77XHrmbjyJUsTHvQH2ZyWaVJJm9bPqEbXl59AmO7e2PqwDY4eDkTczZUvdTI/rcehJejNUq1AizNKw8OSsouxMId5/FCv1bwdbKFysYCZ5LVGLZ4PwAgtLUzfrm1htztenydbaAp1SFVXQw/ZxuMCvHCa4PaAii/c2zVoQQAwMguHvjqqa56n3c1swCfbjuHJ3t4IV+jxbBgd5jfCmiHLmXij5M3sCU2GcWlOhydPQhuysrB5UpGPl7/LQbRiTl4pIM7lk3oVuV3r68mOYnf1KlTsW3bNhw4cKDKkFKd0tJSBAYGYty4cfjoo48qPV9Vz423tzfDDVEjUFyqRYlWJ86309BOXMsWx/ncNmtoAF4e0AYAcOBiJmKu5+DJ7t7oMf9fAMAT3bzw+ZjOYvvJK49h9/nyH8jT8waLtauLS9Fp3j91rql/OxcseyYEH/x1Br9GJWHOsEC82L81gMozNd+v0NbOOHwlq9bt27nZwcHasspQaMp8nGzg4WCFp3v54rHOHuKfw9uPBOBmYQm+21f1QHMXewUy8sp/b9q72dcYTt2VVniyhze+3X0Jv00JRUdPFYrLdDh+NRsD2rngqe/vhGgAWP18T7y3KR5XM8tv67c0k+PC/KEAav7vpHdrJywd3w1dP9qpd/zuuZpGfHMQMUk54n54p5Y4k6zGlAGt8fYf+j2Wi8d1RVJ2oXjZuFULW5SU6fQuS47t7o1Pn+hUbV310eQuS02fPh2bN2/Gvn376hRsAMDCwgJdu3bFpUtVX3dXKBRQKBp2IjIiqp+Kl6GMoaoQ5VthjELfti3Qt20LvedzCkv19ivOw1Px/SpuO9taQmVjgeScIvRq5Yy9FzLw+sPtoC4uxciuntgelyqOFfrpuZ4AgA9HdsDLA1qjtYud+D7DOrrrDT6+X4M7uKFv2xZYeTABmfmaKtsEuNsjJbcYXbwd8N3Ebnjnj1ggwWAl1NroEK8qB5gbQ2J2IRKzC3HkSjZ2xN05/1VNC1BRxQs99+p1S1UXY3Fk+SD0x789BBtLM3GKgXnDg/SCDQBM/fmk3tQAJVodXl8fg6kD29T4OUeuZFcKNgCwOPIisvI1VV5mBIAtt+aHujvYAOX/KFm4o/ymngc/34OZYW2RkqPfU6iyMc4/WKojabgRBAGvvvoqNmzYgD179qBVq1b3ftFdtFotYmNjMWzYsAaokIhMib+rHcZ290Zcci7ik8svI3XzrXmMXycvld5+VeNBblv0VBcs2HYOS54Ogb+rHYpLtbBVmCPuRi56tXISxzlcqOKHT2FuphdsAODT0Z0wrqcPVhy4ihAfR3xxaybm+urZygkdPFR47oFWGLP8ENq42KGkTAc3pRX8Xe3w9a6L+HpcV7R1u7NWl4VZ5bEZVS3AOqqrJ/6MvlHtZ295rS/CF1c/5KCimWFtMf1BfxSVlhk03NXHltja3x6fnld1YKyNinMnzfv7TKXnq5rz6I+T1+sdAL+8j/+W3vr9tN7+qkMJlf4RoLSStu9E0k+fNm0a1q5di02bNsHe3h6pqeX/EatUKlhblw+UmjhxIjw9PREREQEA+PDDD9G7d2/4+/sjJycHCxcuxLVr1/DCCy9I9j2IqGmQyWT49IlO0OoELNl1CaFtnOFiX3XP7o6Z/bEjPhUv9NP/R9cD/i1wPOEm7Kv4y3tEF0+M6OIp7qusy//1evcSAI919sT51Hz0bOVYY732Vhbo19YF/dqWzzM0vLMH8orL8M6fpyGTAXE31Ojr3wKeDtbi5ITeTtZ455FATFtb+Tb5wFuDTK0tzbD51X6Vnn+mitu0rSv0rCmtzKEuLsMLfVuJA4HfDQ/EudQ8zA0PgpWlGdbeuivOwkyGH57tge/3XYG5mUz87Lt18XbAqQqXQza80gddfcrPy9QB/vUKN862lsgrLqt2tuuPRwbjp8MJleY1qujFfq3w/f6rNX5OVXd13e3yJ8Pw1HeHcTzhZo3tDKW1iy3WvNALoRG7jPJ5QOXeTeDOf/tSkTTcLF26FAAwcOBAveMrV67EpEmTAACJiYmQV5iJ6ebNm3jxxReRmpoKR0dHdOvWDYcOHUJQkP4AMCKi6pjJZZgR1rbGNu3d7atcbXzKgDZQWlngoQDXKl5V+89/Z2hAnV/nd2sNsC2vlQcTQRAgk8lws6AEJVodxnT3Em+xvpLRTuzp+eyJTujVyqnKFdjvZcrANoi5novxvXwwsL0rrmTko2crJxy9mo1L6fmYEOorzg3z3qNBeDjQDb1bO0MmK7/seHsCSADY++ZAfLT5LP49W36XU/92LvjpuZ5YtvcyFmw7h26+juhS4Zb2jl4qbHilDzadShYHwz4U4IojV7Lw5ZNd0NlbVelH/MV+rfD64PYwk8uQmlssTiFwW4C7PR7v6omHAlyxIz4Vqw9fw5Vb41i8HK1x/Wb5xIZje3jjp8PXoKkmvLRUWeHQOw+h1aytesd7+DnC28kGf568gWEd3WEml2H9y6GIuZ6Lkd8c1Gvb088JyyZ0w6w/T1e680uvXYUBz5tf7YtHv66+ByywpRItVdb45PGO+OrfCwjxcaz2TsCGpJQ43DSaAcXGwnluiKg50OkEtJ5d/sO7/60H4e1k+PlPboerusrI0+DvmGSM6+kjrtx9e5mKqgJYYUkZgt7bAQD4Y2ooOnk5iLdaf7b9HKwtzNDdzwknrmXjlYH+eu/xwIJd4kzMx+eEwcHGQnwtUL7QaeB72wHo37V25ZNhOJOiRr6mDC/9FAV1sf5loUl9/DDvsQ7iYF5HGwvsen0gHGzKpzXQ6oRKi6fuvZABHycbONlY4v8OXMHTvXzF26pv5BTh292XxPmgKgoLdBMD4aX5Q7ElNqXKSScB4Kke3lgw+s5A3tzCUoxaehB5xWV6l82WPdMN6qJSPNq5Jfacz8Ar95gQsyp/TX8AKw5cxcZTyZWeWzm5h97SLYbQ5AYUExGRYcnlMqx9oRcy8jUNEmyA+s8O72Kv0JvDCKg61NxmY2kOZ1tLZBWUoK2bvV44eeuROz1gt2dPruhm4Z05dqq6BGltaYblE7ohKbsQecVlYriRy2UI9iwfb3V63hAIgoBPtp7FxfR89PVvgXE9ffTep7BEC0fbO3M3VbUqfMVerP8Obq/3nKeDNeY/3hEnrt3EudQ7Y7K6+TpiSIc74cbcTI4RXTz1wk3v1k44cqW8Z6elylrvfVU2Ftg6o7yn72JaPrbEpmDKgDZ6l42GBrvj9ymhsDCTY0SF3qXQ1s5485H2mP1nrFiTlYUc43r64L1HgyCTyRDeyQNbYlMwOsQL3f2cxFm4m/VlKSIiajh9/Fvcu1ETsf/tB1FcWvdpA/xd7XD6ei5sLKu/K29Ih/I10Y4nZGNRZNXLaMhkMswJrzz84d3wQHy85Sz+N7ZLneqqzsywtpjyc3kvyrie3pg/siN0goDCEq3e2K0Vk7oj8mw63hseBIW5GQ5fzsLfp5Px0q1pBCq6fdkw2FMlBra7v1t3v/KB9Z+N7iROdOjrbFN+WWtmf1y/WYjcolJ08NB//cNBbjj74SMwN5MjXV2MAHd7uNgr0MFD2isjvCxFREQm62pmAf638wJeebBNpVl7q7L3QgZaOdvWaRmD3KJSg/ZUHLuaDT9nG7hWMVGeMSzdcxnro5Kw7qXeVU7WJ5UmOYmfsTDcEBERNT11+f3mgvBERERkUhhuiIiIyKQw3BAREZFJYbghIiIik8JwQ0RERCaF4YaIiIhMCsMNERERmRSGGyIiIjIpDDdERERkUhhuiIiIyKQw3BAREZFJYbghIiIik8JwQ0RERCaF4YaIiIhMirnUBRibIAgAypdOJyIioqbh9u/27d/xmjS7cJOXlwcA8Pb2lrgSIiIiqqu8vDyoVKoa28iE2kQgE6LT6ZCcnAx7e3vIZDKDvrdarYa3tzeSkpKgVCoN+t50B8+zcfA8Gw/PtXHwPBtHQ51nQRCQl5cHDw8PyOU1j6ppdj03crkcXl5eDfoZSqWS/8cxAp5n4+B5Nh6ea+PgeTaOhjjP9+qxuY0DiomIiMikMNwQERGRSWG4MSCFQoH3338fCoVC6lJMGs+zcfA8Gw/PtXHwPBtHYzjPzW5AMREREZk29twQERGRSWG4ISIiIpPCcENEREQmheGGiIiITArDjYF888038PPzg5WVFXr16oVjx45JXVKTEhERgR49esDe3h6urq4YOXIkzp8/r9emuLgY06ZNg7OzM+zs7DB69GikpaXptUlMTER4eDhsbGzg6uqKN998E2VlZcb8Kk3KggULIJPJMHPmTPEYz7Nh3LhxA8888wycnZ1hbW2Njh07IioqSnxeEAS89957aNmyJaytrREWFoaLFy/qvUd2djbGjx8PpVIJBwcHPP/888jPzzf2V2nUtFot5s6di1atWsHa2hpt2rTBRx99pLf+EM913e3btw/Dhw+Hh4cHZDIZNm7cqPe8oc7p6dOn0a9fP1hZWcHb2xufffaZYb6AQPdt3bp1gqWlpbBixQohPj5eePHFFwUHBwchLS1N6tKajCFDhggrV64U4uLihFOnTgnDhg0TfHx8hPz8fLHNlClTBG9vbyEyMlKIiooSevfuLfTp00d8vqysTAgODhbCwsKE6OhoYevWrUKLFi2EWbNmSfGVGr1jx44Jfn5+QqdOnYQZM2aIx3me7192drbg6+srTJo0STh69Khw5coVYceOHcKlS5fENgsWLBBUKpWwceNGISYmRnjssceEVq1aCUVFRWKbRx55ROjcubNw5MgRYf/+/YK/v78wbtw4Kb5SozV//nzB2dlZ2Lx5s3D16lXht99+E+zs7IRFixaJbXiu627r1q3CnDlzhD///FMAIGzYsEHveUOc09zcXMHNzU0YP368EBcXJ/zyyy+CtbW1sHz58vuun+HGAHr27ClMmzZN3NdqtYKHh4cQEREhYVVNW3p6ugBA2Lt3ryAIgpCTkyNYWFgIv/32m9jm7NmzAgDh8OHDgiCU/59RLpcLqampYpulS5cKSqVS0Gg0xv0CjVxeXp7Qtm1bYefOncKAAQPEcMPzbBhvv/220Ldv32qf1+l0gru7u7Bw4ULxWE5OjqBQKIRffvlFEARBOHPmjABAOH78uNhm27ZtgkwmE27cuNFwxTcx4eHhwnPPPad3bNSoUcL48eMFQeC5NoS7w42hzum3334rODo66v298fbbbwvt27e/75p5Weo+lZSU4MSJEwgLCxOPyeVyhIWF4fDhwxJW1rTl5uYCAJycnAAAJ06cQGlpqd55DggIgI+Pj3ieDx8+jI4dO8LNzU1sM2TIEKjVasTHxxux+sZv2rRpCA8P1zufAM+zofz111/o3r07xowZA1dXV3Tt2hXff/+9+PzVq1eRmpqqd55VKhV69eqld54dHBzQvXt3sU1YWBjkcjmOHj1qvC/TyPXp0weRkZG4cOECACAmJgYHDhzA0KFDAfBcNwRDndPDhw+jf//+sLS0FNsMGTIE58+fx82bN++rxma3cKahZWZmQqvV6v1FDwBubm44d+6cRFU1bTqdDjNnzsQDDzyA4OBgAEBqaiosLS3h4OCg19bNzQ2pqalim6r+HG4/R+XWrVuHkydP4vjx45We43k2jCtXrmDp0qX473//i9mzZ+P48eN47bXXYGlpiWeffVY8T1Wdx4rn2dXVVe95c3NzODk58TxX8M4770CtViMgIABmZmbQarWYP38+xo8fDwA81w3AUOc0NTUVrVq1qvQet59zdHSsd40MN9ToTJs2DXFxcThw4IDUpZicpKQkzJgxAzt37oSVlZXU5ZgsnU6H7t2745NPPgEAdO3aFXFxcVi2bBmeffZZiaszLevXr8eaNWuwdu1adOjQAadOncLMmTPh4eHBc92M8bLUfWrRogXMzMwq3U2SlpYGd3d3iapquqZPn47Nmzdj9+7d8PLyEo+7u7ujpKQEOTk5eu0rnmd3d/cq/xxuP0fll53S09MREhICc3NzmJubY+/evVi8eDHMzc3h5ubG82wALVu2RFBQkN6xwMBAJCYmArhznmr6e8Pd3R3p6el6z5eVlSE7O5vnuYI333wT77zzDp566il07NgREyZMwH/+8x9EREQA4LluCIY6pw35dwnDzX2ytLREt27dEBkZKR7T6XSIjIxEaGiohJU1LYIgYPr06diwYQN27dpVqauyW7dusLCw0DvP58+fR2JionieQ0NDERsbq/d/qJ07d0KpVFb6oWmuBg0ahNjYWJw6dUp8dO/eHePHjxe3eZ7v3wMPPFBpKoMLFy7A19cXANCqVSu4u7vrnWe1Wo2jR4/qneecnBycOHFCbLNr1y7odDr06tXLCN+iaSgsLIRcrv9TZmZmBp1OB4DnuiEY6pyGhoZi3759KC0tFdvs3LkT7du3v69LUgB4K7ghrFu3TlAoFMKqVauEM2fOCC+99JLg4OCgdzcJ1Wzq1KmCSqUS9uzZI6SkpIiPwsJCsc2UKVMEHx8fYdeuXUJUVJQQGhoqhIaGis/fvkV58ODBwqlTp4Tt27cLLi4uvEX5HireLSUIPM+GcOzYMcHc3FyYP3++cPHiRWHNmjWCjY2N8PPPP4ttFixYIDg4OAibNm0STp8+LYwYMaLKW2m7du0qHD16VDhw4IDQtm3bZn17clWeffZZwdPTU7wV/M8//xRatGghvPXWW2Ibnuu6y8vLE6Kjo4Xo6GgBgPDll18K0dHRwrVr1wRBMMw5zcnJEdzc3IQJEyYIcXFxwrp16wQbGxveCt6YfP3114KPj49gaWkp9OzZUzhy5IjUJTUpAKp8rFy5UmxTVFQkvPLKK4Kjo6NgY2MjPP7440JKSore+yQkJAhDhw4VrK2thRYtWgivv/66UFpaauRv07TcHW54ng3j77//FoKDgwWFQiEEBAQI3333nd7zOp1OmDt3ruDm5iYoFAph0KBBwvnz5/XaZGVlCePGjRPs7OwEpVIpTJ48WcjLyzPm12j01Gq1MGPGDMHHx0ewsrISWrduLcyZM0fv9mKe67rbvXt3lX8nP/vss4IgGO6cxsTECH379hUUCoXg6ekpLFiwwCD1ywShwjSORERERE0cx9wQERGRSWG4ISIiIpPCcENEREQmheGGiIiITArDDREREZkUhhsiIiIyKQw3REREZFIYboio2fHz88NXX30ldRlE1EAYboioQU2aNAkjR44EAAwcOBAzZ8402mevWrUKDg4OlY4fP34cL730ktHqICLjMpe6ACKiuiopKYGlpWW9X+/i4mLAaoiosWHPDREZxaRJk7B3714sWrQIMpkMMpkMCQkJAIC4uDgMHToUdnZ2cHNzw4QJE5CZmSm+duDAgZg+fTpmzpyJFi1aYMiQIQCAL7/8Eh07doStrS28vb3xyiuvID8/HwCwZ88eTJ48Gbm5ueLnzZs3D0Dly1KJiYkYMWIE7OzsoFQq8eSTTyItLU18ft68eejSpQtWr14NPz8/qFQqPPXUU8jLy2vYk0ZE9cJwQ0RGsWjRIoSGhuLFF19ESkoKUlJS4O3tjZycHDz00EPo2rUroqKisH37dqSlpeHJJ5/Ue/2PP/4IS0tLHDx4EMuWLQMAyOVyLF68GPHx8fjxxx+xa9cuvPXWWwCAPn364KuvvoJSqRQ/74033qhUl06nw4gRI5CdnY29e/di586duHLlCsaOHavX7vLly9i4cSM2b96MzZs3Y+/evViwYEEDnS0iuh+8LEVERqFSqWBpaQkbGxu4u7uLx5csWYKuXbvik08+EY+tWLEC3t7euHDhAtq1awcAaNu2LT777DO996w4fsfPzw8ff/wxpkyZgm+//RaWlpZQqVSQyWR6n3e3yMhIxMbG4urVq/D29gYA/PTTT+jQoQOOHz+OHj16ACgPQatWrYK9vT0AYMKECYiMjMT8+fPv78QQkcGx54aIJBUTE4Pdu3fDzs5OfAQEBAAo7y25rVu3bpVe+++//2LQoEHw9PSEvb09JkyYgKysLBQWFtb688+ePQtvb28x2ABAUFAQHBwccPbsWfGYn5+fGGwAoGXLlkhPT6/TdyUi42DPDRFJKj8/H8OHD8enn35a6bmWLVuK27a2tnrPJSQk4NFHH8XUqVMxf/58ODk54cCBA3j++edRUlICGxsbg9ZpYWGhty+TyaDT6Qz6GURkGAw3RGQ0lpaW0Gq1esdCQkLwxx9/wM/PD+bmtf8r6cSJE9DpdPjiiy8gl5d3Qq9fv/6en3e3wMBAJCUlISkpSey9OXPmDHJychAUFFTreoio8eBlKSIyGj8/Pxw9ehQJCQnIzMyETqfDtGnTkJ2djXHjxuH48eO4fPkyduzYgcmTJ9cYTPz9/VFaWoqvv/4aV65cwerVq8WBxhU/Lz8/H5GRkcjMzKzyclVYWBg6duyI8ePH4+TJkzh27BgmTpyIAQMGoHv37gY/B0TU8BhuiMho3njjDZiZmSEoKAguLi5ITEyEh4cHDh48CK1Wi8GDB6Njx46YOXMmHBwcxB6ZqnTu3BlffvklPv30UwQHB2PNmjWIiIjQa9OnTx9MmTIFY8eOhYuLS6UByUD55aVNmzbB0dER/fv3R1hYGFq3bo1ff/3V4N+fiIxDJgiCIHURRERERIbCnhsiIiIyKQw3REREZFIYboiIiMikMNwQERGRSWG4ISIiIpPCcENEREQmheGGiIiITArDDREREZkUhhsiIiIyKQw3REREZFIYboiIiMikMNwQERGRSfl/aF5qvVm49YMAAAAASUVORK5CYII=\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Tj28W2w_ziDA"
      },
      "source": [
        "**Answer**\n",
        "\n",
        "The given plot represents the training loss curve for the bigram model over 1000 iterations. The loss is the negative log-likelihood (NLL) of the training data under the model's learned probability distribution.\n",
        "\n",
        "$\\textbf{For Loss Curve:}$\n",
        "- Initially, the loss is high (around 4.6), which is expected since the model starts with random parameters and has not yet learned meaningful token transitions.\n",
        "- As training progresses, the loss rapidly decreases, indicating that the model is improving its ability to predict the next token.\n",
        "- After approximately 600 iterations, the loss stabilizes around 2.5, implying that the model has learned a reasonable probability distribution over bigrams in the dataset.\n",
        "\n",
        "\n",
        "$\\textbf{For Final Loss Value:}$\n",
        "- A final loss of around 2.5 suggests that the model has learned a probability distribution better than uniform guessing (loss = $\\log V $).\n",
        "- The fact that the loss does not reach zero means the model is not making perfect predictions, which is expected in language modeling due to inherent uncertainty and variability in real text.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nUP9q72s9jSC"
      },
      "source": [
        "Note that these models can take up a lot of memory on the GPU. As you go through this assignment, you may want to free the models after you train them using code along the lines of\n",
        "```\n",
        "model.to('cpu')\n",
        "torch.cuda.empty_cache()\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "bigram_model.to('cpu')\n",
        "torch.cuda.empty_cache()"
      ],
      "metadata": {
        "id": "Zj9YiTpmb-4u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "slaOmWgFLdMk"
      },
      "source": [
        "### 1.2: Token Embeddings: going from discrete tokens to continuous latent spaces\n",
        "\n",
        "In the look up table formulation of the bigram model, we are modelling the logits of the next token didstirbution independently for each token, even if two tokens are extremely similar to each other.\n",
        "One way arond this problem is to learn an embedding of the discrete tokens into $\\mathbb{R}^{D}$, and then to run multi-class logistic regression on top of this learned embedding.\n",
        "\n",
        "More precisely, if we have a vocabulary of tokens of size $V$ that we choose to embed in a Euclidean embedding space of dimension $D$, we can parameterize the distribution of the next token if the current token is $v$ according to\n",
        "\\begin{align*}\n",
        "  \\mathrm{Cat}\\Big( \\mathrm{softmax} (\\beta X_v) \\Big),\n",
        "\\end{align*}\n",
        "where $X_v \\in \\mathbb{R}^{D}$ is the learned embedding of token $v$ into $\\mathbb{R}^{D}$ and $\\beta \\in \\mathbb{R}^{V \\times D}$. Notice that if $X$ were a fixed design matrix this formulation would be equivalent to multi-class logistic regression. However, both $X$ and $\\beta$ are learnable parameters."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kX6BRU07O7Cr"
      },
      "source": [
        "#### Question 1.2.1: Implement BigramWithWordEmbeddingsLM\n",
        "\n",
        "Implement a bigram languge model that uses a linear readout from a low dimensional Euclidean embedding of each token to parameterize the logits of the next token distribution, instead of parameterizing the logits of the next token distribution directly. It should have almost the same implementation as `BigramLanguageModel` from Question 1.1.6, except `init` should also take in an `embed_size`, and the `forward` method will need to be modified."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "brU5zILoQASX"
      },
      "outputs": [],
      "source": [
        "class BigramWithWordEmbeddingsLM(nn.Module):\n",
        "\n",
        "    def __init__(self, vocab_size, embed_size=32):\n",
        "      \"\"\"\n",
        "      Args:\n",
        "        vocab_size: int, size of the vocabulary\n",
        "        embed_size: int, dimension of the word embedding (D)\n",
        "      \"\"\"\n",
        "      super().__init__()\n",
        "      #TODO, your code here\n",
        "      self.token_embedding_table = nn.Embedding(vocab_size, embed_size)\n",
        "      self.lm_head = nn.Linear(embed_size, vocab_size)\n",
        "\n",
        "    def forward(self, token_ids, targets=None):\n",
        "        \"\"\"\n",
        "        Args:\n",
        "          token_ids: (B, T) token ids that make up the context (batch has size B, each entry in the batch has length T)\n",
        "          targets: (B, T) token ids corresponding to the target of each context in token_ids\n",
        "\n",
        "        Returns:\n",
        "          logits: (B, T, V), logits[b,t, :] gives the length V vector of logits for the next token prediction in string b up to t tokens\n",
        "          loss: scalar, negative log likelihood of target given context\n",
        "        \"\"\"\n",
        "        # TODO, your code here\n",
        "\n",
        "        logits = self.token_embedding_table(token_ids)\n",
        "        logits = self.lm_head(logits)\n",
        "\n",
        "        if targets is None:\n",
        "            loss = None\n",
        "        else:\n",
        "          B, T, V = logits.shape\n",
        "          logits = logits.view(B*T, V)\n",
        "          targets = targets.view(B*T)\n",
        "          loss = F.cross_entropy(logits, targets)\n",
        "\n",
        "        return logits, loss\n",
        "\n",
        "    @torch.no_grad()\n",
        "    def generate(self, token_ids, max_new_tokens=CONTEXT_WINDOW_SIZE):\n",
        "        \"\"\"\n",
        "        Args:\n",
        "          token_ids: (B, T) tensor of token ids to provide as context\n",
        "          max_new_tokens: int, maximum number of new tokens to generate\n",
        "\n",
        "        Returns:\n",
        "          (B, T+max_new_tokens) tensor of context with new tokens appended\n",
        "        \"\"\"\n",
        "        #TODO\n",
        "        # your code below\n",
        "        B, T = token_ids.shape\n",
        "        new_token_sequences = torch.zeros((B, T+max_new_tokens), dtype=torch.long, device=token_ids.device)\n",
        "        new_token_sequences[:, :T] = token_ids\n",
        "        for t in range(max_new_tokens):\n",
        "            logits, loss = self(token_ids)\n",
        "            logits = logits[:, -1, :]\n",
        "            probs = F.softmax(logits, dim=-1)\n",
        "            new_tokens = torch.multinomial(probs, num_samples=1)\n",
        "            new_token_sequences[:, T + t] = new_tokens\n",
        "        return new_token_sequences\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5JJCQ3vWuX6y"
      },
      "source": [
        "#### Question 1.2.2: Training your bigram model with word embeddings\n",
        "\n",
        "Train your bigram model with word embeddings for `SMALL_ITERS` iterations. Plot and interpret the loss curve. How does the final loss compare to that of the bigram model without embeddings? Why do you think this is?\n",
        "\n",
        "Our train loss gets down to around 2.5 after 1000 iterations."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kZpsE59qug1B",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "80fcb7dd-e00a-4296-b181-37fece07bc1a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/1000 [00:00<?, ?it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "iteration 0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  1%|          | 8/1000 [00:01<02:16,  7.25it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "step 0: train loss 4.4024, val loss 4.3897\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 20%|█▉        | 197/1000 [00:03<00:08, 92.64it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "iteration 200\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 22%|██▏       | 217/1000 [00:05<00:24, 32.30it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "step 200: train loss 2.4754, val loss 2.4995\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 40%|███▉      | 397/1000 [00:07<00:06, 88.60it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "iteration 400\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 42%|████▏     | 416/1000 [00:08<00:18, 32.18it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "step 400: train loss 2.4645, val loss 2.4834\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 60%|█████▉    | 596/1000 [00:10<00:04, 92.22it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "iteration 600\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 62%|██████▏   | 616/1000 [00:11<00:11, 32.56it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "step 600: train loss 2.4606, val loss 2.4858\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 80%|████████  | 800/1000 [00:13<00:02, 68.19it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "iteration 800\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 81%|████████  | 807/1000 [00:14<00:12, 15.41it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "step 800: train loss 2.4626, val loss 2.4827\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 99%|█████████▉| 990/1000 [00:17<00:00, 94.70it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "iteration 999\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1000/1000 [00:18<00:00, 55.08it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "step 999: train loss 2.4613, val loss 2.4954\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "bigram_model_embed = BigramWithWordEmbeddingsLM(vocab_size)\n",
        "bm_e = bigram_model_embed.to(device)\n",
        "\n",
        "learning_rate = 1e-2\n",
        "optimizer = torch.optim.AdamW(bigram_model_embed.parameters(), lr=learning_rate)\n",
        "\n",
        "eval_interval = 200\n",
        "\n",
        "loss_list = []\n",
        "\n",
        "for it in tqdm(range(SMALL_ITERS)):\n",
        "\n",
        "    # every once in a while evaluate the loss on train and val sets\n",
        "    if it % eval_interval == 0 or it == SMALL_ITERS - 1:\n",
        "        print(f\"iteration {it}\")\n",
        "        losses = estimate_loss(bm_e, EVAL_ITERS, CONTEXT_WINDOW_SIZE, device)\n",
        "        print(f\"step {it}: train loss {losses['train']:.4f}, val loss {losses['val']:.4f}\")\n",
        "\n",
        "    # sample a batch of data\n",
        "    xb, yb = get_batch('train', CONTEXT_WINDOW_SIZE, device)\n",
        "\n",
        "    # evaluate the loss\n",
        "    logits, loss = bm_e(xb, yb)\n",
        "    loss_list.append(loss.detach().item())\n",
        "    optimizer.zero_grad(set_to_none=True)\n",
        "    loss.backward()\n",
        "    optimizer.step()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot and interpret the loss curve.\n",
        "plt.plot(loss_list)\n",
        "plt.xlabel('Iteration')\n",
        "plt.ylabel('Loss')\n",
        "plt.title('Loss Curve')\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 472
        },
        "id": "fpkiGkm99oE5",
        "outputId": "4dc22ebf-7bde-4cb1-ada0-2ed9c9ca99da"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAj8AAAHHCAYAAABQhTneAAAAOnRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjEwLjAsIGh0dHBzOi8vbWF0cGxvdGxpYi5vcmcvlHJYcgAAAAlwSFlzAAAPYQAAD2EBqD+naQAAYQ1JREFUeJzt3XlYVGXDBvB72IZ1BlDZUVBQXMAFU3FPSDQrKSs1EzXL3N70K7O0NC0NtOVN600t10qjrNQy10g0E1FcQctdQWURFIZ1gJnz/YFzYGQVYc4g9++65rrgnGfOPOewzD3PdmSCIAggIiIiaiJMpK4AERERkSEx/BAREVGTwvBDRERETQrDDxERETUpDD9ERETUpDD8EBERUZPC8ENERERNCsMPERERNSkMP0RERNSkMPwQERFRk8LwQ0QPZP369ZDJZIiPj5e6KrVy8uRJvPjii/D09IRcLoejoyNCQkKwbt06aDQaqatHRAZgJnUFiIgMZfXq1Zg8eTKcnZ0xduxY+Pr6IicnB9HR0Zg4cSJSUlIwd+5cqatJRA2M4YeImoTDhw9j8uTJCAoKwo4dO2BnZyfumzlzJuLj45GYmFgvr5WXlwcbG5t6ORYR1T92exGRQZw4cQJDhw6FQqGAra0tgoODcfjwYb0yxcXFWLhwIXx9fWFpaYlmzZqhb9++2Lt3r1gmNTUVEyZMgIeHB+RyOVxdXTF8+HBcvXq12tdfuHAhZDIZNm7cqBd8dLp3747x48cDAGJiYiCTyRATE6NX5urVq5DJZFi/fr24bfz48bC1tcWlS5fw+OOPw87ODmPGjMH06dNha2uL/Pz8Cq81evRouLi46HWz7dy5E/369YONjQ3s7OwwbNgwnDlzptpzIqK6YfghogZ35swZ9OvXD6dOncLs2bMxb948XLlyBQMHDkRcXJxYbsGCBVi4cCEeffRRfPHFF3jnnXfQsmVLHD9+XCwzYsQIbNmyBRMmTMCXX36J1157DTk5OUhKSqry9fPz8xEdHY3+/fujZcuW9X5+JSUlCA0NhZOTEz7++GOMGDECI0eORF5eHn7//fcKdfntt9/w7LPPwtTUFADw7bffYtiwYbC1tcWSJUswb948nD17Fn379q0x1BFRHQhERA9g3bp1AgDh6NGjVZYJCwsTLCwshEuXLonbbt68KdjZ2Qn9+/cXt3Xu3FkYNmxYlce5c+eOAED46KOP7quOp06dEgAIM2bMqFX5ffv2CQCEffv26W2/cuWKAEBYt26duG3cuHECAOHtt9/WK6vVagV3d3dhxIgRett//PFHAYBw4MABQRAEIScnR7C3txdeeeUVvXKpqamCUqmssJ2IHhxbfoioQWk0GuzZswdhYWFo3bq1uN3V1RUvvPACDh48CJVKBQCwt7fHmTNncOHChUqPZWVlBQsLC8TExODOnTu1roPu+JV1d9WXKVOm6H0vk8nw3HPPYceOHcjNzRW3//DDD3B3d0ffvn0BAHv37kVWVhZGjx6NjIwM8WFqaoqePXti3759DVZnoqaK4YeIGtStW7eQn5+Pdu3aVdjXvn17aLVaJCcnAwDef/99ZGVloW3btvD398ebb76J06dPi+XlcjmWLFmCnTt3wtnZGf3798fSpUuRmppabR0UCgUAICcnpx7PrIyZmRk8PDwqbB85ciQKCgrw66+/AgByc3OxY8cOPPfcc5DJZAAgBr1BgwahRYsWeo89e/YgPT29QepM1JQx/BCR0ejfvz8uXbqEtWvXolOnTli9ejW6deuG1atXi2VmzpyJ8+fPIyIiApaWlpg3bx7at2+PEydOVHlcHx8fmJmZISEhoVb10AWTe1W1DpBcLoeJScV/p7169YKXlxd+/PFHAMBvv/2GgoICjBw5Uiyj1WoBlI772bt3b4XHtm3balVnIqo9hh8ialAtWrSAtbU1zp07V2Hfv//+CxMTE3h6eorbHB0dMWHCBHz//fdITk5GQEAAFixYoPe8Nm3a4I033sCePXuQmJiIoqIifPLJJ1XWwdraGoMGDcKBAwfEVqbqODg4AACysrL0tl+7dq3G597r+eefx65du6BSqfDDDz/Ay8sLvXr10jsXAHByckJISEiFx8CBA+/7NYmoegw/RNSgTE1NMXjwYGzbtk1v5lJaWho2bdqEvn37it1SmZmZes+1tbWFj48P1Go1gNKZUoWFhXpl2rRpAzs7O7FMVd577z0IgoCxY8fqjcHROXbsGDZs2AAAaNWqFUxNTXHgwAG9Ml9++WXtTrqckSNHQq1WY8OGDdi1axeef/55vf2hoaFQKBT48MMPUVxcXOH5t27duu/XJKLqcZFDIqoXa9euxa5duypsnzFjBhYtWoS9e/eib9++mDp1KszMzLBq1Sqo1WosXbpULNuhQwcMHDgQgYGBcHR0RHx8PH766SdMnz4dAHD+/HkEBwfj+eefR4cOHWBmZoYtW7YgLS0No0aNqrZ+vXv3xv/+9z9MnToVfn5+eis8x8TE4Ndff8WiRYsAAEqlEs899xw+//xzyGQytGnTBtu3b6/T+Jtu3brBx8cH77zzDtRqtV6XF1A6HmnFihUYO3YsunXrhlGjRqFFixZISkrC77//jj59+uCLL76479clompIPd2MiBo33VT3qh7JycmCIAjC8ePHhdDQUMHW1lawtrYWHn30UeHQoUN6x1q0aJHQo0cPwd7eXrCyshL8/PyExYsXC0VFRYIgCEJGRoYwbdo0wc/PT7CxsRGUSqXQs2dP4ccff6x1fY8dOya88MILgpubm2Bubi44ODgIwcHBwoYNGwSNRiOWu3XrljBixAjB2tpacHBwEF599VUhMTGx0qnuNjY21b7mO++8IwAQfHx8qiyzb98+ITQ0VFAqlYKlpaXQpk0bYfz48UJ8fHytz42IakcmCIIgWfIiIiIiMjCO+SEiIqImheGHiIiImhSGHyIiImpSGH6IiIioSWH4ISIioiaF4YeIiIiaFC5yWAmtVoubN2/Czs6uynv8EBERkXERBAE5OTlwc3Or9H57Ogw/lbh586bevYaIiIio8UhOToaHh0eV+xl+KmFnZweg9OLp7jlERERExk2lUsHT01N8H68Kw08ldF1dCoWC4YeIiKiRqWnICgc8ExERUZPC8ENERERNCsMPERERNSkMP0RERNSkMPwQERFRk8LwQ0RERE0Kww8RERE1KQw/RERE1KQw/BAREVGTwvBDRERETQrDDxERETUpDD9ERETUpPDGpgaUnV8MVWExFJbmUFqbS10dIiKiJoktPwYUsfMf9Fu6D98evip1VYiIiJoshh8DMjOVAQCKNYLENSEiImq6GH4MyMyk9HIXa7QS14SIiKjpYvgxIAuz0stdomXLDxERkVQYfgzIzETX7cWWHyIiIqkw/BiQmendlh+O+SEiIpIMw48Bmd9t+SnRsuWHiIhIKgw/BqRr+eFsLyIiIukw/BiQuSnH/BAREUmN4ceAzDnmh4iISHIMPwZkxpYfIiIiyTH8GJC5Cdf5ISIikhrDjwGx5YeIiEh6DD8GxHV+iIiIpMfwY0DmXOGZiIhIcgw/BqSb7VXMMT9ERESSYfgxIN2YnxK2/BAREUmG4ceAuM4PERGR9Bh+DEi8qzvv7UVERCQZhh8D4mwvIiIi6TH8GJA5x/wQERFJzmjCT2RkJGQyGWbOnFllma+//hr9+vWDg4MDHBwcEBISgiNHjuiVGT9+PGQymd5jyJAhDVz72tGN+Sliyw8REZFkjCL8HD16FKtWrUJAQEC15WJiYjB69Gjs27cPsbGx8PT0xODBg3Hjxg29ckOGDEFKSor4+P777xuy+rUmtvxwzA8REZFkJA8/ubm5GDNmDL7++ms4ODhUW3bjxo2YOnUqunTpAj8/P6xevRparRbR0dF65eRyOVxcXMRHTcc1FDMTjvkhIiKSmuThZ9q0aRg2bBhCQkLu+7n5+fkoLi6Go6Oj3vaYmBg4OTmhXbt2mDJlCjIzM6s9jlqthkql0ns0BN7bi4iISHpmUr54VFQUjh8/jqNHj9bp+W+99Rbc3Nz0gtOQIUPwzDPPwNvbG5cuXcLcuXMxdOhQxMbGwtTUtNLjREREYOHChXWqw/0Q1/nhCs9ERESSkSz8JCcnY8aMGdi7dy8sLS3v+/mRkZGIiopCTEyM3vNHjRolfu3v74+AgAC0adMGMTExCA4OrvRYc+bMweuvvy5+r1Kp4Onped91qolunR+NVoBWK8Dk7vdERERkOJJ1ex07dgzp6eno1q0bzMzMYGZmhv3792P58uUwMzODRqOp8rkff/wxIiMjsWfPnhoHSbdu3RrNmzfHxYsXqywjl8uhUCj0Hg3B3KzscnOhQyIiImlI1vITHByMhIQEvW0TJkyAn58f3nrrrSq7qJYuXYrFixdj9+7d6N69e42vc/36dWRmZsLV1bVe6v0gzE3Kwk+JRoBc0k5HIiKipkmyt187Ozt06tRJb5uNjQ2aNWsmbg8PD4e7uzsiIiIAAEuWLMH8+fOxadMmeHl5ITU1FQBga2sLW1tb5ObmYuHChRgxYgRcXFxw6dIlzJ49Gz4+PggNDTXsCVZCN+AZ4IwvIiIiqUg+26s6SUlJSElJEb9fsWIFioqK8Oyzz8LV1VV8fPzxxwAAU1NTnD59Gk899RTatm2LiRMnIjAwEH/99RfkcrlUpyEyKzfGh91eRERE0jCqjpeYmJhqv7969Wq1z7eyssLu3bvrt1L1SCaTwcxEhhKtwJYfIiIiiRh1y8/DiGv9EBERSYvhx8B0a/0w/BAREUmD4cfAuNAhERGRtBh+DEw36JktP0RERNJg+DEwseWHA56JiIgkwfBjYLoBzyWc6k5ERCQJhh8DK+v2YssPERGRFBh+DIyzvYiIiKTF8GNgHPNDREQkLYYfA+Mih0RERNJi+DEw3Z3duc4PERGRNBh+DIwtP0RERNJi+DEwM475ISIikhTDj4FZsOWHiIhIUgw/BiZOdeeYHyIiIkkw/BiYrturuIQtP0RERFJg+DEwc3Z7ERERSYrhx8AsTDnVnYiISEoMPwamG/NTxG4vIiIiSTD8GBjX+SEiIpIWw4+BWfDGpkRERJJi+DGwsru6c8wPERGRFBh+DMycLT9ERESSYvgxMHMzjvkhIiKSEsOPgenu6s5uLyIiImkw/BiYbpHDIrb8EBERSYLhx8DMzXh7CyIiIikx/BiYOVd4JiIikhTDj4FxnR8iIiJpMfwYmG6FZ97egoiISBoMPwbGdX6IiIikxfBjYBZc4ZmIiEhSRhN+IiMjIZPJMHPmzGrLbd68GX5+frC0tIS/vz927Niht18QBMyfPx+urq6wsrJCSEgILly40IA1vz9s+SEiIpKWUYSfo0ePYtWqVQgICKi23KFDhzB69GhMnDgRJ06cQFhYGMLCwpCYmCiWWbp0KZYvX46VK1ciLi4ONjY2CA0NRWFhYUOfRq3wru5ERETSkjz85ObmYsyYMfj666/h4OBQbdlly5ZhyJAhePPNN9G+fXt88MEH6NatG7744gsApa0+n332Gd59910MHz4cAQEB+Oabb3Dz5k1s3brVAGdTM97YlIiISFqSh59p06Zh2LBhCAkJqbFsbGxshXKhoaGIjY0FAFy5cgWpqal6ZZRKJXr27CmWqYxarYZKpdJ7NBROdSciIpKWmZQvHhUVhePHj+Po0aO1Kp+amgpnZ2e9bc7OzkhNTRX367ZVVaYyERERWLhw4f1Uvc54Y1MiIiJpSdbyk5ycjBkzZmDjxo2wtLSUqhoAgDlz5iA7O1t8JCcnN9hrsduLiIhIWpK1/Bw7dgzp6eno1q2buE2j0eDAgQP44osvoFarYWpqqvccFxcXpKWl6W1LS0uDi4uLuF+3zdXVVa9Mly5dqqyLXC6HXC5/0FOqlbK7urPlh4iISAqStfwEBwcjISEBJ0+eFB/du3fHmDFjcPLkyQrBBwCCgoIQHR2tt23v3r0ICgoCAHh7e8PFxUWvjEqlQlxcnFhGauz2IiIikpZkLT92dnbo1KmT3jYbGxs0a9ZM3B4eHg53d3dEREQAAGbMmIEBAwbgk08+wbBhwxAVFYX4+Hh89dVXACCuE7Ro0SL4+vrC29sb8+bNg5ubG8LCwgx6flUp3+0lCAJkMpnENSIiImpaJB3wXJOkpCSYmJQ1TvXu3RubNm3Cu+++i7lz58LX1xdbt27VC1GzZ89GXl4eJk2ahKysLPTt2xe7du2SfFyRji78AKUByMKM4YeIiMiQZIIgcOTtPVQqFZRKJbKzs6FQKOr12AVFGrSfvwsAcPb9UFhbGHX+JCIiajRq+/4t+To/TY1uhWcAKC5h7iQiIjI0hh8DMzMpCz9FHPRMRERkcAw/BiaTybjKMxERkYQYfiRgzpubEhERSYbhRwJmXOWZiIhIMgw/EjBntxcREZFkGH4kYMFuLyIiIskw/EjA3IwtP0RERFJh+JGArturiOv8EBERGRzDjwR0a/2UaNnyQ0REZGgMPxKwYLcXERGRZBh+JMBuLyIiIukw/EiAixwSERFJh+FHAlznh4iISDoMPxLQhZ8SrvBMRERkcAw/EtB1e/Gu7kRERIbH8CMBdnsRERFJh+FHAhYMP0RERJJh+JGAmTjbi2N+iIiIDI3hRwLs9iIiIpIOw48EGH6IiIikw/AjgbLbW7Dbi4iIyNAYfiQgTnUvYcsPERGRoTH8SMDMhN1eREREUmH4kYCu24srPBMRERkew48EeGNTIiIi6TD8SEA324u3tyAiIjI8hh8JmHGqOxERkWQYfiRgwRWeiYiIJMPwIwEuckhERCQdhh8JMPwQERFJR9Lws2LFCgQEBEChUEChUCAoKAg7d+6ssvzAgQMhk8kqPIYNGyaWGT9+fIX9Q4YMMcTp1FpZ+GG3FxERkaGZSfniHh4eiIyMhK+vLwRBwIYNGzB8+HCcOHECHTt2rFD+l19+QVFRkfh9ZmYmOnfujOeee06v3JAhQ7Bu3Trxe7lc3nAnUQec6k5ERCQdScPPk08+qff94sWLsWLFChw+fLjS8OPo6Kj3fVRUFKytrSuEH7lcDhcXl/qvcD0Rp7rz9hZEREQGZzRjfjQaDaKiopCXl4egoKBaPWfNmjUYNWoUbGxs9LbHxMTAyckJ7dq1w5QpU5CZmdkQVa4zXfgp0bLbi4iIyNAkbfkBgISEBAQFBaGwsBC2trbYsmULOnToUOPzjhw5gsTERKxZs0Zv+5AhQ/DMM8/A29sbly5dwty5czF06FDExsbC1NS00mOp1Wqo1Wrxe5VK9WAnVQMLM3Z7ERERSUXy8NOuXTucPHkS2dnZ+OmnnzBu3Djs37+/xgC0Zs0a+Pv7o0ePHnrbR40aJX7t7++PgIAAtGnTBjExMQgODq70WBEREVi4cOGDn0wtiQOe2e1FRERkcJJ3e1lYWMDHxweBgYGIiIhA586dsWzZsmqfk5eXh6ioKEycOLHG47du3RrNmzfHxYsXqywzZ84cZGdni4/k5OT7Po/7oburexFnexERERmc5C0/99JqtXpdUJXZvHkz1Go1XnzxxRqPd/36dWRmZsLV1bXKMnK53KAzwtjtRUREJB1Jw8+cOXMwdOhQtGzZEjk5Odi0aRNiYmKwe/duAEB4eDjc3d0RERGh97w1a9YgLCwMzZo109uem5uLhQsXYsSIEXBxccGlS5cwe/Zs+Pj4IDQ01GDnVRNxwDPDDxERkcFJGn7S09MRHh6OlJQUKJVKBAQEYPfu3XjssccAAElJSTAx0e+ZO3fuHA4ePIg9e/ZUOJ6pqSlOnz6NDRs2ICsrC25ubhg8eDA++OADo1rrh4scEhERSUcmCALfge+hUqmgVCqRnZ0NhUJR78dPzylEj8XRAIArEY9DJpPV+2sQERE1NbV9/5Z8wHNTZGFadtm51g8REZFhMfxIwLxc+OGgZyIiIsNi+JGAfvhhyw8REZEhMfxIQHdjU4AtP0RERIbG8CMBmUwGMxOu9UNERCQFhh+JlN3igt1eREREhsTwIxFd11cRW36IiIgMiuFHIhZmd1d51jL8EBERGRLDj0R03V5FvLM7ERGRQTH8SER+t+VHzfBDRERkUAw/ErE0NwUAFBZrJK4JERFR08LwIxGx5aeYLT9ERESGxPAjEbmu5aeELT9ERESGxPAjkbJuL7b8EBERGRLDj0TKBjyz5YeIiMiQGH4kwpYfIiIiaTD8SMSSLT9ERESSYPiRiNy89NKz5YeIiMiwGH4kYmlW2u2l5jo/REREBsXwIxFdyw9XeCYiIjIshh+J6Fp+uMIzERGRYTH8SEQ324stP0RERIbF8CORsgHPbPkhIiIyJIYfibDbi4iISBoMPxLhgGciIiJpMPxIRM6WHyIiIkkw/EjEki0/REREkmD4kUjZvb3Y8kNERGRIDD8S0d3Vnbe3ICIiMiyGH4lwnR8iIiJpMPxIRNfyw3t7ERERGRbDj0TY8kNERCQNScPPihUrEBAQAIVCAYVCgaCgIOzcubPK8uvXr4dMJtN7WFpa6pURBAHz58+Hq6srrKysEBISggsXLjT0qdw3Xfgp0mih0QoS14aIiKjpkDT8eHh4IDIyEseOHUN8fDwGDRqE4cOH48yZM1U+R6FQICUlRXxcu3ZNb//SpUuxfPlyrFy5EnFxcbCxsUFoaCgKCwsb+nTui67bCwDUJez6IiIiMhQzKV/8ySef1Pt+8eLFWLFiBQ4fPoyOHTtW+hyZTAYXF5dK9wmCgM8++wzvvvsuhg8fDgD45ptv4OzsjK1bt2LUqFH1ewIPQNfyAwDqYi2sLSSsDBERURNiNGN+NBoNoqKikJeXh6CgoCrL5ebmolWrVvD09KzQSnTlyhWkpqYiJCRE3KZUKtGzZ0/ExsZWeUy1Wg2VSqX3aGimJjKYm8oAAAUc9ExERGQwkoefhIQE2NraQi6XY/LkydiyZQs6dOhQadl27dph7dq12LZtG7777jtotVr07t0b169fBwCkpqYCAJydnfWe5+zsLO6rTEREBJRKpfjw9PSsp7OrHhc6JCIiMjzJw0+7du1w8uRJxMXFYcqUKRg3bhzOnj1badmgoCCEh4ejS5cuGDBgAH755Re0aNECq1ateqA6zJkzB9nZ2eIjOTn5gY5XW2XhhzO+iIiIDEXSMT8AYGFhAR8fHwBAYGAgjh49imXLltUq0Jibm6Nr1664ePEiAIhjgdLS0uDq6iqWS0tLQ5cuXao8jlwuh1wuf4CzqBuru+GH3V5ERESGI3nLz720Wi3UanWtymo0GiQkJIhBx9vbGy4uLoiOjhbLqFQqxMXFVTuOSCq6m5uy24uIiMhw6tTyk5ycDJlMBg8PDwDAkSNHsGnTJnTo0AGTJk2q9XHmzJmDoUOHomXLlsjJycGmTZsQExOD3bt3AwDCw8Ph7u6OiIgIAMD777+PXr16wcfHB1lZWfjoo49w7do1vPzyywBKZ4LNnDkTixYtgq+vL7y9vTFv3jy4ubkhLCysLqfaoKw45oeIiMjg6hR+XnjhBUyaNAljx45FamoqHnvsMXTs2BEbN25Eamoq5s+fX6vjpKenIzw8HCkpKVAqlQgICMDu3bvx2GOPAQCSkpJgYlLWOHXnzh288sorSE1NhYODAwIDA3Ho0CG9AdKzZ89GXl4eJk2ahKysLPTt2xe7du2qsBiiMbBktxcREZHByQRBuO/lhR0cHHD48GG0a9cOy5cvxw8//IC///4be/bsweTJk3H58uWGqKvBqFQqKJVKZGdnQ6FQNNjrjFt7BPvP38LHz3XGs4EeDfY6RERETUFt37/rNOanuLhYHCD8xx9/4KmnngIA+Pn5ISUlpS6HbJI44JmIiMjw6hR+OnbsiJUrV+Kvv/7C3r17MWTIEADAzZs30axZs3qt4MPMyuLumJ8ihh8iIiJDqVP4WbJkCVatWoWBAwdi9OjR6Ny5MwDg119/RY8ePeq1gg8zzvYiIiIyvDoNeB44cCAyMjKgUqng4OAgbp80aRKsra3rrXIPOw54JiIiMrw6tfwUFBRArVaLwefatWv47LPPcO7cOTg5OdVrBR9mHPNDRERkeHUKP8OHD8c333wDAMjKykLPnj3xySefICwsDCtWrKjXCj7MeHsLIiIiw6tT+Dl+/Dj69esHAPjpp5/g7OyMa9eu4ZtvvsHy5cvrtYIPMy5ySEREZHh1Cj/5+fmws7MDAOzZswfPPPMMTExM0KtXL1y7dq1eK/gws7w726uAs72IiIgMpk7hx8fHB1u3bkVycjJ2796NwYMHAyhdsbkhFwV82Fia3Z3tVcLwQ0REZCh1Cj/z58/HrFmz4OXlhR49eog3Dd2zZw+6du1arxV8mFmx5YeIiMjg6jTV/dlnn0Xfvn2RkpIirvEDAMHBwXj66afrrXIPO0szjvkhIiIytDqFHwBwcXGBi4sLrl+/DgDw8PDgAof3SVzhmbO9iIiIDKZO3V5arRbvv/8+lEolWrVqhVatWsHe3h4ffPABtFq+kdcWFzkkIiIyvDq1/LzzzjtYs2YNIiMj0adPHwDAwYMHsWDBAhQWFmLx4sX1WsmHFW9vQUREZHh1Cj8bNmzA6tWrxbu5A0BAQADc3d0xdepUhp9a4grPREREhlenbq/bt2/Dz8+vwnY/Pz/cvn37gSvVVJSN+WH4ISIiMpQ6hZ/OnTvjiy++qLD9iy++QEBAwANXqqnQzfYq1ggo0XCsFBERkSHUqdtr6dKlGDZsGP744w9xjZ/Y2FgkJydjx44d9VrBh5mu5QcACku0sDWtUxYlIiKi+1Cnd9sBAwbg/PnzePrpp5GVlYWsrCw888wzOHPmDL799tv6ruNDS25Wdvm50CEREZFhyARBEOrrYKdOnUK3bt2g0TTuN3KVSgWlUons7OwGv12H37ydKCzW4q/Zj8LT0bpBX4uIiOhhVtv3b/azSIx3diciIjIshh+Jcbo7ERGRYTH8SMySNzclIiIyqPua7fXMM89Uuz8rK+tB6tIkiTc3LeFUdyIiIkO4r/CjVCpr3B8eHv5AFWpqrNjyQ0REZFD3FX7WrVvXUPVosjjgmYiIyLA45kdiupubcsAzERGRYTD8SMySLT9EREQGxfAjMU51JyIiMiyGH4mJLT8c8ExERGQQDD8S08324lR3IiIiw5A0/KxYsQIBAQFQKBRQKBQICgrCzp07qyz/9ddfo1+/fnBwcICDgwNCQkJw5MgRvTLjx4+HTCbTewwZMqShT6XOdC0/nOpORERkGJKGHw8PD0RGRuLYsWOIj4/HoEGDMHz4cJw5c6bS8jExMRg9ejT27duH2NhYeHp6YvDgwbhx44ZeuSFDhiAlJUV8fP/994Y4nTrhmB8iIiLDuq91furbk08+qff94sWLsWLFChw+fBgdO3asUH7jxo16369evRo///wzoqOj9RZXlMvlcHFxaZhK1zNOdSciIjIsoxnzo9FoEBUVhby8PAQFBdXqOfn5+SguLoajo6Pe9piYGDg5OaFdu3aYMmUKMjMzG6LK9ULX8qNm+CEiIjIISVt+ACAhIQFBQUEoLCyEra0ttmzZgg4dOtTquW+99Rbc3NwQEhIibhsyZAieeeYZeHt749KlS5g7dy6GDh2K2NhYmJqaVnoctVoNtVotfq9SqR7spO6DeHsLhh8iIiKDkDz8tGvXDidPnkR2djZ++uknjBs3Dvv3768xAEVGRiIqKgoxMTGwtLQUt48aNUr82t/fHwEBAWjTpg1iYmIQHBxc6bEiIiKwcOHC+jmh+yQ344BnIiIiQ5K828vCwgI+Pj4IDAxEREQEOnfujGXLllX7nI8//hiRkZHYs2cPAgICqi3bunVrNG/eHBcvXqyyzJw5c5CdnS0+kpOT63QudVHW8sOp7kRERIYgecvPvbRarV4X1L2WLl2KxYsXY/fu3ejevXuNx7t+/ToyMzPh6upaZRm5XA65XF6n+j4ojvkhIiIyLEnDz5w5czB06FC0bNkSOTk52LRpE2JiYrB7924AQHh4ONzd3REREQEAWLJkCebPn49NmzbBy8sLqampAABbW1vY2toiNzcXCxcuxIgRI+Di4oJLly5h9uzZ8PHxQWhoqGTnWR3dbK98dnsREREZhKThJz09HeHh4UhJSYFSqURAQAB2796Nxx57DACQlJQEE5OynrkVK1agqKgIzz77rN5x3nvvPSxYsACmpqY4ffo0NmzYgKysLLi5uWHw4MH44IMPJGvZqYmtvPRHkFNYLHFNiIiImgaZIAiC1JUwNiqVCkqlEtnZ2VAoFA36WtkFxei8cA8A4N8PhogrPhMREdH9qe37t+QDnps6haUZzE1lAIDbeUUS14aIiOjhx/AjMZlMBgdrCwAMP0RERIbA8GMEHG1Kw08mww8REVGDY/gxAs1sdS0/VU/xJyIiovrB8GMElFbmAABVQYnENSEiInr4MfwYAYWlLvxwujsREVFDY/gxAgpdyw/X+iEiImpwDD9GQNftlc2WHyIiogbH8GMEFJalqzxzzA8REVHDY/gxAuz2IiIiMhyGHyMgDnhm+CEiImpwDD9GwMqi9H5evLM7ERFRw2P4MQJWd29mqi7WSlwTIiKihx/DjxHQtfwUFLPlh4iIqKEx/BgBS7O74YfdXkRERA2O4ccIWFqU/hgKSzQQBEHi2hARET3cGH6MgG7MjyAA6hKO+yEiImpIDD9GwPJu+AGAQo77ISIialAMP0bA3NQEZiYyABz0TERE1NAYfoyEruurkNPdiYiIGhTDj5GwtOCMLyIiIkNg+DESupYfdnsRERE1LIYfI2FpXvqjUDP8EBERNSiGHyPBlh8iIiLDYPgxEpYMP0RERAbB8GMkxPDDAc9EREQNiuHHSIhT3bnCMxERUYNi+DESuju7/3X+lsQ1ISIiergx/BgJXbfXnrNpuJKRJ3FtiIiIHl4MP0ZCblb2ozh7UyVhTYiIiB5uDD9GokhTNtZHgCBhTYiIiB5uDD9GorDcLK/cwhIJa0JERPRwkzT8rFixAgEBAVAoFFAoFAgKCsLOnTurfc7mzZvh5+cHS0tL+Pv7Y8eOHXr7BUHA/Pnz4erqCisrK4SEhODChQsNeRr1ovz6PrfziySsCRER0cNN0vDj4eGByMhIHDt2DPHx8Rg0aBCGDx+OM2fOVFr+0KFDGD16NCZOnIgTJ04gLCwMYWFhSExMFMssXboUy5cvx8qVKxEXFwcbGxuEhoaisLDQUKdVJ/nlWn5u5zL8EBERNRSZIAhGNcDE0dERH330ESZOnFhh38iRI5GXl4ft27eL23r16oUuXbpg5cqVEAQBbm5ueOONNzBr1iwAQHZ2NpydnbF+/XqMGjWqVnVQqVRQKpXIzs6GQqGonxOrwYZDV/Her6Wh79lAD3z8XGeDvC4REdHDorbv30Yz5kej0SAqKgp5eXkICgqqtExsbCxCQkL0toWGhiI2NhYAcOXKFaSmpuqVUSqV6Nmzp1imMmq1GiqVSu9haGN6tkQPb0cAQH4Rx/wQERE1FMnDT0JCAmxtbSGXyzF58mRs2bIFHTp0qLRsamoqnJ2d9bY5OzsjNTVV3K/bVlWZykRERECpVIoPT0/PBzmlOjEzNcFzgR4A9LvAiIiIqH5JHn7atWuHkydPIi4uDlOmTMG4ceNw9uxZg9Zhzpw5yM7OFh/JyckGfX0dG7kZACBfzfBDRETUUMykroCFhQV8fHwAAIGBgTh69CiWLVuGVatWVSjr4uKCtLQ0vW1paWlwcXER9+u2ubq66pXp0qVLlXWQy+WQy+UPeioPTHeLizx2exERETUYyVt+7qXVaqFWqyvdFxQUhOjoaL1te/fuFccIeXt7w8XFRa+MSqVCXFxcleOIjImNRWkW5Z3diYiIGo6kLT9z5szB0KFD0bJlS+Tk5GDTpk2IiYnB7t27AQDh4eFwd3dHREQEAGDGjBkYMGAAPvnkEwwbNgxRUVGIj4/HV199BQCQyWSYOXMmFi1aBF9fX3h7e2PevHlwc3NDWFiYVKdZa9Zs+SEiImpwkoaf9PR0hIeHIyUlBUqlEgEBAdi9ezcee+wxAEBSUhJMTMoap3r37o1Nmzbh3Xffxdy5c+Hr64utW7eiU6dOYpnZs2cjLy8PkyZNQlZWFvr27Ytdu3bB0tLS4Od3vzjmh4iIqOEZ3To/xkCKdX4AIE1ViJ4fRsPURIaLi4dCJpMZ7LWJiIgau0a3zg+VdXtptALUJdoaShMREVFdMPwYEWuLsl7IXDXH/RARETUEhh8jYmoig93dcT+qgmKJa0NERPRwYvgxMgorcwCAqpAtP0RERA2B4cfI6MJPNlt+iIiIGgTDj5FRWrHbi4iIqCEx/BgZhSVbfoiIiBoSw4+RUYpjfhh+iIiIGgLDj5ERBzwXcMAzERFRQ2D4MTK6bq+V+y8hh60/RERE9Y7hx8joBjwDwCd7zktYEyIioocTw4+R0XV7AcCJ5CzpKkJERPSQYvgxMspy4cdWbiphTYiIiB5ODD9GRqEXfsyqKUlERER1wfBjZExNZOLXNgw/RERE9Y7hx8h4N7MRv5ZBVk1JIiIiqguGHyPjYGOBl/p4AwDSVIUS14aIiOjhw/BjhPxc7QAABy9m4FxqjsS1ISIiergw/BghK/OyWV7rD12RsCZEREQPH4YfI2RZLvw4WFtIWBMiIqKHD8OPEcovKruvV/l1f4iIiOjBMfwYoRZ2cvHrohKthDUhIiJ6+DD8GKGg1s1gblo6zT2vSCNxbYiIiB4uDD9GSCaTYfKANgCAgnJdYERERPTgGH6MlJVF6aBntvwQERHVL4YfI2V9d8ZXAcMPERFRvWL4MVLWd+/rlcduLyIionrF8GOkrO92e+Wr2fJDRERUnxh+jJS9Venihkeu3sb20zclrg0REdHDg+HHSDkrytb6mb7phIQ1ISIiergw/BgpJ4Wl1FUgIiJ6KDH8GCmFpZnUVSAiInooSRp+IiIi8Mgjj8DOzg5OTk4ICwvDuXPnqn3OwIEDIZPJKjyGDRsmlhk/fnyF/UOGDGno06lXMplM6ioQERE9lCQNP/v378e0adNw+PBh7N27F8XFxRg8eDDy8vKqfM4vv/yClJQU8ZGYmAhTU1M899xzeuWGDBmiV+77779v6NOpd5te6Sl+XaLhPb6IiIjqg6R9K7t27dL7fv369XBycsKxY8fQv3//Sp/j6Oio931UVBSsra0rhB+5XA4XF5f6rbCB9fAqO9dP957H7CF+EtaGiIjo4WBUY36ys7MBVAw41VmzZg1GjRoFGxsbve0xMTFwcnJCu3btMGXKFGRmZlZ5DLVaDZVKpfcwBmamZT+eL2Mu4bM/zktYGyIiooeD0YQfrVaLmTNnok+fPujUqVOtnnPkyBEkJibi5Zdf1ts+ZMgQfPPNN4iOjsaSJUuwf/9+DB06FBpN5QsGRkREQKlUig9PT88HPp+G8NkfF6SuAhERUaMnEwRBkLoSADBlyhTs3LkTBw8ehIeHR62e8+qrryI2NhanT5+uttzly5fRpk0b/PHHHwgODq6wX61WQ61Wi9+rVCp4enoiOzsbCoXi/k6knnm9/bve91cjh1VRkoiIqGlTqVRQKpU1vn8bRcvP9OnTsX37duzbt6/WwScvLw9RUVGYOHFijWVbt26N5s2b4+LFi5Xul8vlUCgUeg9jpdEaRVYlIiJqtCQNP4IgYPr06diyZQv+/PNPeHt71/q5mzdvhlqtxosvvlhj2evXryMzMxOurq4PUl2joC7hvb6IiIgehKThZ9q0afjuu++wadMm2NnZITU1FampqSgoKBDLhIeHY86cORWeu2bNGoSFhaFZs2Z623Nzc/Hmm2/i8OHDuHr1KqKjozF8+HD4+PggNDS0wc+poRUWc8o7ERHRg5A0/KxYsQLZ2dkYOHAgXF1dxccPP/wglklKSkJKSore886dO4eDBw9W2uVlamqK06dP46mnnkLbtm0xceJEBAYG4q+//oJcLq9Q3tgtG9VF73u2/BARET0YoxnwbExqO2DKULILitE38k/kqEuwb9ZAeDe3qflJRERETUyjGvBM1VNamUNuXvqjYssPERHRg2H4aSTkZqYAOOaHiIjoQTH8NBJys9IfVdj//sacXxLA3koiIqK6YfhpJC5nlN3s9fsjSThz0zhuwUFERNTYMPw0Utfv5EtdBSIiokaJ4aeRSskulLoKREREjRLDTyOVyvBDRERUJww/jcTWaX0wLqgVXgv2BcCWHyIiorpi+GkkunjaY+HwTvB1sgUA/HrqJv5N5aBnIiKi+8Xw08i4Ki3Fr2dGnZSuIkRERI0Uw08j41Iu/FzL5IwvIiKi+8Xw08g4K8rCT/lWICIiIqodhp9GxtzUBI+2awEAaG7b+O5ST0REJDWGn0bopb7eAABVYbHENSEiImp8GH4aIaWVOQAgu4Dhh4iI6H4x/DRCuvCTkl2IzFy1xLUhIiJqXBh+GqHyY30G//cASjRaCWtDRETUuDD8NEI2cjPx68y8IsScuyVhbYiIiBoXhp9GyrZcAHr5m3h2fxEREdUSw08j9cOrveDnYid+/9KGeAiCIGGNiIiIGgeGn0aqo5sSu2b2R3NbCwDAqeQsxF7OlLhWRERExo/hp5Hr6KYUv37h6zh2fxEREdWA4aeRu7ejK3DRH4i9lIn952/hl+PXJakTERGRMTOruQgZM6224jifdX9fwZ6zaQCAR7wc4elobehqERERGS22/DRymkrCjy74AMDXf12GukRjyCoREREZNYafRk5Twwyvb2KvYd3fV3H9Tj6mfHcMx67dNlDNiIiIjBO7vRq58tPbLc1NUFhccbXnyJ3/YldiKk4mZ2FnYirWju8OTwdr+DrbVShLRET0sGPLTyP37rAOMDWRYfqjPvjn/SFVljuZnCV+/dL6eDz23wMY/dVh5BeVGKCWRERExoPhp5Hr7GmPMwtDMSu0HWQyGV7u613r58ZezsTGw0kNWDsiIiLjw/DzELA0NxW/nvlYW4R1cav1c8/czMbuM6lYuf8SLqTlNET1iIiIjIpM4D0RKlCpVFAqlcjOzoZCoZC6OnWy9uAVvL/9LLp42ut1edXkSsTjkMlkDVcxIiKiBlLb929JW34iIiLwyCOPwM7ODk5OTggLC8O5c+eqfc769eshk8n0HpaWlnplBEHA/Pnz4erqCisrK4SEhODChQsNeSpGZ0IfL8TMGoj1Ex65r+f9djoFxRotrmTkiduy84vxw9EkqAqL77selU3FJyIikpKk4Wf//v2YNm0aDh8+jL1796K4uBiDBw9GXl5etc9TKBRISUkRH9euXdPbv3TpUixfvhwrV65EXFwcbGxsEBoaisLCwoY8HaMik8ng1dwG9tYWejdArclr35/AzB9O4tGPYzDkswM4n5aDmT+cwFs/J+C9bWfuqw6/nbqJTu/txt5y6w49iO+PJGHAR/tw+VZuvRyPSCo5hcX48WgysvKLpK4KUZNkVN1et27dgpOTE/bv34/+/ftXWmb9+vWYOXMmsrKyKt0vCALc3NzwxhtvYNasWQCA7OxsODs7Y/369Rg1alSN9XgYur3KS7yRjae//BvFmgf/UZ96bzCUVuZIvJGNBb+eQWArB7wZ2g5mphVztNfbv4tfn1s0BKv/uoInAlzRqplNja8jCAJWHbiMTm5K9PVtrne8fr7N8e3Eng98LkRSmb7pOLafTkEfn2bY+HIvqatD9NBoFN1e98rOzgYAODo6VlsuNzcXrVq1gqenJ4YPH44zZ8paJK5cuYLU1FSEhISI25RKJXr27InY2NiGqbiR6+SuxKn3BtfLsTov3INJ38Rj4oajiL92B6sOXMb6Q1dx7Npt7D9/q8rnLdl5Dh/tPodHP44BAFxMz0F2QdXdaDsTUxG581+8uCauwr6s/PvvfiMyJttPpwAA/r6YKXFNiJomowk/Wq0WM2fORJ8+fdCpU6cqy7Vr1w5r167Ftm3b8N1330Gr1aJ37964fr30Jp6pqakAAGdnZ73nOTs7i/vupVaroVKp9B4PGytzUzSzsQCASscBvdq/Nb54oWutjrXnbBrSVGV3jz90KRMjVsRi3NojaPvuTvybWvH6rf37CgBAK5TOMAv59ACe+PyvSo+/PPoCpm48XuXrJ9zIxs2sgir3F2u0SLyRjfPlZq9l5Rdh2sbj2Hcuvcbzq4sbWQU4du1OvR6zsFiDYk3FRSuNUYkR1/M/35/AsysO1bqOWq1Qr91Rx5PuYGdCCrRaAZ/9cb7aDwnGyIg6Bx7YrRw1buexq5GMKPxMmzYNiYmJiIqKqrZcUFAQwsPD0aVLFwwYMAC//PILWrRogVWrVtX5tSMiIqBUKsWHp6dnnY9lrGQyGba/1hcH3nwUA9s5IW5usLhvbK9WeH1wW7jZW9Xp2OVbcIpKtJi1+RR+jE+usvyMqJMAgOTbBfjpWNmd5zNy1Riz+jA+3Xter3xl/3zXHrwCjVZAwvVsHL6cKZbRaAW88PVhPPH5QQz+7wEcupgBAHjv1zP4PSEFE9YdrfF8/r6YgT6Rf+KVb+Lx993n16RP5J8YseIQzqXqLxcgCALWHryC307drPK5J5OzMGz5X/hwxz/itjx1Cfou2YeRqypvrcxTl1S4LinZBfcVQs6n5SAzV40Pd/yDlzccRYlGixKNFt8evoZL9zGu6laOGt0X/4G3fjpd6+fUpLKB8kUlWuxISEGuumxhzjUHr+D9385WCCvJt/PxbexV5BQW47dTNxF/7Q7+Sal8KYcf45MxM+oEikpKr92bP51G4KI/sP10xZ/ZsWu3MXJVLBJvZFdZd61WwMX0HPHn88yXhzBl43Es//MCPvvjAsatPVLzBaiDi+m5+Db2aqW/A8UaLQqLNYi9lIm3fjpdbatreYXFGgz+7wE8vzLW4CGoqESL9Jyqx2nmF5Xg9PWsSuuVnV9c4bl56hIM+ewAhi47UOXfyYMu+pqRq8buM6n3NdHjXGrOff291YZGKyDmXDqy2UpeJaO4vcX06dOxfft2HDhwAB4eHvf1XHNzc3Tt2hUXL14EALi4uAAA0tLS4OrqKpZLS0tDly5dKj3GnDlz8Prrr4vfq1SqhzIAuSrLwo2zwhID2rbAhbQcvD3UD3IzU7iV2/9EgCvc7K3wY3xyjd1M97Z4JN5QYXY1b4QX08v+0GdtPoXOHkpYmpti7paESrsBCoo1sLbQ/1Ut0QqYvy0RG+NKF2ls08IGe/5vAPaeTcXRq2X1mbghHgkLBuOvC2UhZvy6I/g6vDvMKxmnBACTvz2GHHUJbmQVYO/ZNFyNHKa3X6MVcPBiBrp42ENpba6370TSHTgr5Nh9JhWb4pJwNkUljrUKbu8knkdGrhrWFqb4+2ImXvkmHgBw5qYKrz/WFpbmpvjrwi1k5KqRkauGRivA1ESGrw9choWZCbp7OSDsf39jQh9vzH28PQBg37l0Mdj9PCUIga2q7zq+mpGHwf89oLft0KVMXMnIw3u/lnYjj+/tBTtLM8gAfBeXhC9Gd0Vvn+YVjrX497PIyi/GD/HJWPx0J5iayPSWSygs1sBEJoOFWen1vpKRh0/3nsfUgW3Q3rVin3zijWyMXBWLaYN8MHWgj7h91uZT+PVuiPxlam8s/v0f8XfPwswEbw/1gyAIEARgxIpDSM9R46fjN8TnF2srf8PT/a728WmO57p74ufjpYF8+qYTeCLADYIgiOfz0vp4ZBcUY/y6o5jQxwtnU0p/Zkorc9zKUeNCei4OX87EprgkvPdkB4x8pOz/yK7EyluegdKWw1s5anTxtK90f1GJFjmFxWhmK6/yGCGf7gdQ+rcxoY/+YqcjVhzCrRw1UrJLA4G13BTvPdmxymPpxJy7hQt3/17zizSwkdfuLeOfFBUKizVo42SL6ZtOYGgnF4zs7omfjl1HM1sLBLcva5lPyS7A4cuZeCLATfyb3HbyhvghKWbWQHg1t9H7OQDAhHVHEXflNv73QjcMCyj7X6/RCnjyi4PIyi/CX7MHiX+jZ26qkHm31efdrYl4sVcrdHJXis+Lu5yJkV8dxv+FtMWMEN9anee9nl8Zi8sZeVj8dCd09rCHj5Ot3jps98pTlyD0s9K/wwuLh1b5PwkAvj18De72lhjk51zp/jx1CTSCAIWlOTbHJ+PtXxLwiJcDNk/uXeUx01WFaG4rh4nJ/S1v8ubmUziXloMfXw2q9vzK02oFFJZU/F8uFUlrIQgC/vOf/2DLli2IiYmBt3ftVyfW0Wg0SEhIwOOPPw4A8Pb2houLC6Kjo8Wwo1KpEBcXhylTplR6DLlcDrm86n8qD6v1Ex5BiVYQ/+Ba2JVdg1f7t4G/hxLbT91EFhr200P0v+mI3PlvlfsTrmeL/4B1vj+SBHVJ2ZvZpVt5GPVVLJJu5+uVKyjWYPbPp/WaumPO3cLn0RcwfZAvdiSkIKhNMzgrLLH+7yv4+fgN5Kj1P/2VaLQwMzXBtcw8bD+dAjtLM8y/O/Otr09zzHuig1j27V8S8Oupmzh0qWKIm/tLAmaGtMXuM6mI2PkvbOVmeq0YALAi5hJMTWRYf+iquC2nsBgFxRosvtsy1MenGYo1Ar46cFkMP5+Vay1bc/AKung64J8UFW7nFcHB2gLJd/IR0t4ZFmYmuJlVgM3HKrbMpeeocbBcS1f5OgDAC6vjEDtnkF6IPnQpA1tPlrWQ+LyzEy/2aglHGzle6uOFNJUaL39TGsoinwmAV3MbTN14HP+kqHDg/C1xLNqB87eQpy7BwHZOmLrxOPKKNFi66xxaN7fFkE4uuHQrVww+QGlrSnk5d5dhmPTtMZy9qUJ6Tmm37Klya1xl5xfjm9ir6NbSASv2X0KeugRfh3cX99+ppKsrp7AYw5YfRLeW9pj6qI/YYpKRq8ZHu0uX5fj9dEqlP8uFv53Fyv2XxO//Ta16EdGQT/ajoFiD957sgB+OJiO7oBjTHvXBi71aAQDe3ZqAX47fwNfh3XHoUgZ8ne1w5MptzBvWAZl5avxvX9nrHLyQgbAu7pDJAHtri7stJPotVUmZ+n8n98pVl0BdrMHZm2XPu51XVGP4KSjSICW7AEOXlXZpj+7hiQPnb+HA+VuY80uCWE43cUKrFRAU8SeA0p/P+LuhTRd8gNLxf89398BTX/yNxzo4Y8FTpaEt7krpTZq/O3xNL/ycTL4j/h9IvJmNPncD+7ly3fFRR5MRdTRZ74PNvG2JAID//nEeDjbm8HCwqhA0dOunPRfogfeHd8Lqvy6ja0sH7EhMwdWMPFy+u0TIO1tKjzV1YBv8Z5AvrCwqDwjl/y+l56jhbm8FQRBwM7sQbkpLJN8uQHM7C6RmF2Le1tJjdvG0x9rxj8Dx7jCGE0l38G3sNfxyojToLx/dFR/vKf3dLP9B8F6HLmbghdVxeDbQA+883h4Od48HlLacAoCnozUEQUCRRgu5Wek5qAqLsflui/3xpDvo3aY5NFoB+UUlsLMs+zBYVKJFkUaLv87fwrLoCxAEIPlOPn6d3gfOCkvIzUzFD0RSkDT8TJs2DZs2bcK2bdtgZ2cnjslRKpWwsir9BxseHg53d3dEREQAAN5//3306tULPj4+yMrKwkcffYRr167h5ZdfBlDavTNz5kwsWrQIvr6+8Pb2xrx58+Dm5oawsDBJztNYyWQymJuWJX5TExm+Du+OO/lF8Pco/UT0iLcjtp28CTu5WYVQAAA/vhqE5+92zTwR4CoO5LwfX+67WO3+kV8drrCtfPDRqeoP/Zdyn/51lv95EbvOpOJ8Wi5aN7fBn7MGYsFvZyt9/uqDV9DRTYH3fj2Dy7f0l2E4eDEDY+8ZlF1Z8AGArSdv6gWFe98sAWBZdMX1qLLyi/W6YMq3jh2+nIlerZvpjcE6fT0bL284in3n9MeWDO/ihk+f74LekX9WWr9Zm0+ha0v7SvfpXEjLFcOPRitg/NqK3Yjf3b1lys/HruNGubFZY1bHwdHGQvyHn11QjM4L92Djyz0RfrcraGC7FnoBdvJ3xzAuqBU2xOovZ3GvlOxCHLlyu9plFTbGJeGPf/T3H716W/xaECp2sT75+UEk3c5H0u18RP9b9Xixyn6WAPR+LlVRl2hQUKwBUBqYdHStEwDwY3zpm82E9frX21ZuJrZQ6kT/m46uH+yFpbkJEhaEIjO3YqirqoVh3d9XkJpdiA2xVyvcJDnzbvjJU5fA09Fa3F5QpEFRiRZKa3PMiDqBPeXqUtWA7phz6RjexR2f/1n2t7/pSBJe6NmqwhuiRqtF4KI/AJQGcl340dEKArLzi7HqwCX4OtvqdfVsOpIEB2sLnL6ehXmVLNXx+LK/8Ov0PjAzNUH5H73uw82ViMdx5qYKS3b9ixnBvnh/e+nPZ/Ox62IAqM6XMZew6sBlfPNSD3RyV+KVb+JhZiLDqB4t0dbZVu81U7IK4G5vhe8OX8O8bWfwcl9vrD54BT28HDF3WHux3MnkLIz+6jBy1SV4qosbVsRc0nvN174/off97bwiMShN33QcmblF2PBSD/Fcfjp2Hb+evIlPR3ZGanYhurZ0wLMrD0EQUHrPyBQVov9NR4CHEh8+7a/XE5Bx93fr5Q2lrXA7XuuHSd/Gw0VphcxcNW5mFeDOPT0HIZ+WtnQFeCjx6/S+NV7DhiJp+FmxYgUAYODAgXrb161bh/HjxwMAkpKSYGJS9sdw584dvPLKK0hNTYWDgwMCAwNx6NAhdOhQ9ul79uzZyMvLw6RJk5CVlYW+ffti165dFRZDpIoe66D/See9JzvCVWmF57p7IPiT0mZ1MxMZhndxR+QIf5ibmoifngRB0As/k/q3RlGJVmxB6OPTrNJ/hqrCim8cTwS44kRSlt6bZ307n1bamnQ5Iw+Lf688+ACotlUKgNjK0FDe2Vp5dyAAjPrqMDq5K5CqKhvfcP1OAa7fqXjdtp28iXG9vap9rRNJWdXuzy4oxrytiejopkBwe2cUVTPGqLKf3b2DTbMLivHE5wfF72POVRwMXFPwAYA//03Hn9WEEwAVgg8A7Ewo64r6MT65Qni/Wq6FJKeS39P6sGRn1Qu7nr6eBe/mVS8NcW/rXHmFxVpM+e4YxgZ5Vdi360wqhn9xEP8d2QW2lmboE/lnjUth3M5T483Np3AhPRf927aArdwUPk522BR3DcUaAQuf6qgXfADg+p3KW5huZhVCqxXw3z/KWizPp+Vi4W9nMH2Qj17ZewPt7bwi/Hqy7ANN3JXb6Pz+HvH7J8q1Av1+OgW/V/OB7GyKCuFrj2CovysqO3tVYQnGrT2CzLwiva7z+6HRCpj902mM7+2FI3dbq3QfkH6YVLbMwY2sAqScuimGtNUHSyeJHLl6Gzfu+Xs+d3cyx73BpzLn03Jw+noWPtp9TvwZ/30xQ+/3uUijxfRNJyo894tyH0xLP1TF49UBrcVtybfzoS7RiB+05m1LxPm0XPF/a3VOX89GQZGmylaxhmZU6/wYi4dtnZ/6cio5C9H/pGHaIB+xCfReurV4Rj3iicgRAfg8+gI+udslc+jtQXjlm3icuVna/Px8dw/xE+295j/RAd/FXavQ0lIbi8I6YeFvZzC0k6teVwkR1V1nT3u9bsQH0dLRGl7NbXCgkplvJrLSWaHG4OcpQRix4sGXSHGykyO0owu+Pawf5GcNbouP95T+f3RRWOp9iCmvvasC/6TU3yzkXq0dcfjy7ZoLVuKFni2xKa5+boj9x+sD4ONkWy/H0qnt+zfDTyUYfuru99Mp2HTkGv77fBc4KSyx+q/LWPR76ViV8i1Et/OKkF1QjEF3W5N03O2t0MXTHp883xmPfhwjDtC8HxcWD4W6RAsbC1Ms+PVMrVoOGpqb0hI363AuDe3T5zsjV10iNvMbi1GPeGLqQB/0/2jfAx3nlX7e+Dc1p86f2u/1Uh9vbI5PrrQLmBqHz0d3RVZ+Ec6mqPD9kapnpTZmPk62ehNLDO2xDs61Wtl//YRHMLCdU72+dqNc5JAav2EBrtj4ci84KUq7GJ8N9EBzWws81bnsTvMymQzNbOXwbm4DPxc7WJqb4NUBrbFiTDf8NftR/G9MN1iam+KT5ztDbmaCUY94YueMfjCRAd1qGJMSO2cQzE1NYCs3g0wmQ4BHxfLdWznUeB6tq+lq+OS5zhjcofIZF1Xp37YF+vg0q3Rfc1s53GuxzMALPVvivSfLunfH9GxZ69e3qmJGxuP+rujpXXm9ylNY1txD3qu1Iy5/+Hi13TT3esSr4s9i48s9ETkiAC2bWWPpiIAK+78O7463hvjVeOxdM/vhnWEd8MbgdrWuT01s5aZQWOnP8LOzNMORd4KxOrw7xvZqhfOLhmKQn/4/9I+eDcDy0aXraNlYmGLO0Jrr31R0cq+fD5g/vhqEZaO6VFvGzESG/r4tMDbIC71a1/x7fz9q8zdcW8F+lQcCPxc7bP9PzeNk/nh9AJpXMzPwXiYy4I/X9e+q8GRnN9znJDAAgFcza3w1NhCfPNe5xrKVdc8bCsMPNSh7awvEzgmu9J+STCbDb//pixPzBmPO0PYY6u+qN+Wyd5vmiH83BB8+7Y/2rgqcmD8Ym17phS/HdAMAvDbIB093dcf7wzvi77cHYft/+urNRAKAxzo6w9HGAv18y6Zo12Zq5ubJQVX+8Y4I9MBX4d3xQVgnPNPNXW9ft5b2+OP1ARjepSzsOdnJ8WRnNwzv4n7voeDnYofDcwYh+o0BeKWfNyxMTfDGY21hbirDa8G+eLfcQMfmtnKMeqQlQto7Y8GTHbD4aX/8PKU3Vod3R3NbC4S01/+HWVNgiXzGH5bmpnqz/HbP7A8Ph7JruPf/+mPOUD98EKa/8Ghl/1i1WsDERIb55QIaUHEcmc5zgR5QWllU2N6n3HT6wR0rPvexDs6YMrANBrRtobe9V2tHWJmb4pmu7ri4eCj8XErfVDt7KCscQ+fV/q2x47V+kJcbZNvcVo5Nr/TE3McrBhRPR+sK4Wf7f/rCyc4SIR2c8UFYJ1iYmeDJzmXjTpaM8Mdz3T3xVGc3XI0chjPvD8GrA9pUWScANXYFlP8woTPqEU9xYGtl1ozrjue7V76USEtHa/HvSqeymTh2VfxOVXX/QOU916oyM4PbYskIf8wZ6ocNL/Woslz5DxwuiorjN7u3ckBoR5dqX2vb9D7i1Pc+lSzb8CCiJvXCtEfb4PSCwfh1eh+8/ljbSst1dFPg7XvCr3+5KfdOdnKsHBtY6XNzCkvQ1rl292osqWRph79mP1phW7eW9vh2Yk/4ONmJ9ZgR7ItFYZ3w+ehu6OFV+bIZ5f9PlPeonxNkMhme6qL/O/q4v/7PJrCVAzq4SdezYhwT7umhVt3aFeamJqgui5SfOqn7R/q4vyvi5gbDyU6ut+5HZZ+8FJbmOPT2IFiYmqD13B0AgKmPttGb0l2ZZrZyjAj0QFZBMXYmpKB/2xb4dO95vD+8bKbJ2F6t8GLPlujeyhH5RSWwt7bAY+2dobQ2x5IRAfB1skVoRxf43v1nJQgCWtjK9WbsrHwxEGamJjAzhdhKYWluikkDWovjqnTdhv19m8PKwhSrx5VNzw6824p1tH0IbmYX4o9/SmdyPd/dA1cy8sQZcCMC3fHd4SQMaNsCG17qgVx1CWzvTlt2tLHAS328IZMB7Vzs8FqwL2b/dBrPdHWHr7MdfJ3tKsxmeiLAtcJgW+3dHvTAVg5oYSfHrbsDwYP9nPD3xQzkF2nEsh+EdcLYXq2w5uAVvYHI9/5Dtbe2wIaXeogLA47sXrZuzppx3XEhPVecVv1SH28M8nOqcJ85mUyGD5/2x9wtCXrbLy4eKpb9flIvpGUXwtPRGh3dFJDJZOjsYY8Pd/wrvtbhy5l4uqs7vinXjfr56K6V3qvOvlyo825eeZDp4e0oDoAFAAdrc9zJL8aisE543N8VMefS8fqPpyo8b8247ghu74wXerbE1I3HcTuvCF7NrPFBWCfMHuKHiB3/YOQjnkhTqTFtU+lK6c90c0c/3xa4laOudJzdS328Sl9z1kA8vyoWbVrYIiNXLS4xsWSEP7p4OqCdix1eXB1X4e9nx2v98G9qDsLXHsHj/i54Y3A7aLQCzExl+OemCm/9fFpv8Hh5no7WCCkXbM4tGoKPdp3D1pM3xNlEQOmbqm5A9VtD28FZYQlBABb//g/G9W4FExMZLE1MsXZ8d5xMzsbySmZOdnQrCxnNbeVYPrprhdlR9+rsaY+iEi3+SVHB3d4Kj/u74Ou/rlR6Hm+GloaaAA97BHjY47VgX3x/JElvmv8XL3SDd3Mb3MwqEH+XOnsqkXB34UxLc1OYm5rgfy90E39+OjmFxbAwM8FXYwORfKcAz3X3gLmJCb4/kiTO3tIpvmdGbGcPJTwdrfHO4+3FZTMA4JepfcSvf3i1F27nFcHDoXQ237AAVwwLcMXNrIIKs0R/mdIbVzLyxNm4rwX7Ivl2PmYGl4Y+c1MTRL8xAAt+PYOgNs0wdaAP9p+/hXFrj6CntyM2vtyz0ntCGgrH/FSCY34eTtfv5CM9R41uLR2QriqEnaU5Xlh9GOdScxDc3llchbmZjQWOzXtM77mCIOD6nQJ4OFjpBa660A0K925ug32zBtZY/tKtXFzLzKtycTOd7PxicdbLhD5eCOvijnHrjuCNwe3wQo+WOHU9C22a21ZYmPFeWq2AhBvZaOdip9dKVv5GtQkLBsN/wR69570Z2g7THi2dqVOs0eLghQzEXs7E7NB2yL+70OGGQ1fR37eFuJRCUYkWC347g01xSVBYmmHLtD5o06JiWDh7UwWZDGjrbAfTcq2Dt/OK0O2DvQCAMwtDq12Hpnz9+7dtgW+qaWXQScrMh7mZTK9Fccp3x7Dz7oKFlz58XK8+OqevZ+GpL/4GUPXidemqQuxMTEVhsQb7z9/CyrGByM4vFn/HMnLV6H53irfOm6HtMHVgG/F3UBAEaIXSGUX3ttTobqcR6OUotpKpSzRYtP0fDGjbAj/GJyMtR43/C/FFP98W4nkUFmsgNzPB0t3nsCLmEkxkpeepe82iEi3+vpiBrSdvYNvdpRt04/m0WqHSBfOy8ovQ5f3S6fezBrdDdy9HXEzPRXpOod5CluXplkIASrurds3sLy7kuGpsYI2tPDsSUrDwtzP46NnOiL2cicEdnNG1ZcVu1rD//Y2TyVl4/bG28HOxw/7zt5BdUCzO/Lv04eMwkZVOCW/dwhYd3RT4+fh1JN8u0FvH6d7FUHVSswvRKyIaADC6R0tEPOMvXqsBH+9DRk4Rds3shwEfxQAoHR94aE7pCvwX03PFcwZKu7oXP+1f6eu8/fNpRB1NxvRHfTArtB3avrtTXLX8pT7emBXaVlxgML+oBLM2n8LgDi4I61qxRboym+KS9D5AXP7wcZiYyLArMQVtWtiKH/KkxgHPD4Dhp+ko1mhRVKLFlzEXxYXijswNFscsNYSDFzLwyd5zYndefdFqBYR9+Tf+SVFh1dhADPJzrrAq7oPQhQcLUxOcXzwUPxxNwls/J+DVAa3R1skOT3Z2k2TRsh0JKVBamdfYjfHd4WtYc/AKwoNa4YkAN73uvvtx5MptbIi9iikD2uitEHyvb2Ovwru5Lfr61q17RRAETPr2mDhwtGtLe2wp9ym9oakKi/G/Py/iue6elXbDrfv7irguUVVv/OVdupULQRDg41T7N8nk2/n4ZM85vNK/NTq6KdFv6Z9IzS7EX7MHwUVZP3+jt/OKcORKJoLbO4shNSW7AMGf7Edwe2d8Prrqex5O23gcvyeUhqTqrsHuM6k4fu0OZg/x0wvLt3LUKNJo4W5vhZc3HEX0v+lYM667+EFHEASMW3cUCdez8H+PtcWIbh5VBvwSjRZnU1To4KqAmakJvOf8Lq4jVJufT228uzVBXMervo5Z3xh+HgDDT9NzNSMPAz+OQa/WjoiaFCR1deqsIZeQb/vOThRptPBxssUfrw8AUPrPu64hgmpHFzr7+DTDxpd71VDacIpKtPjqwCX0b9ui0okFDSG7oBh56pI634fwfhQUaWBpblLth4fdZ1Lx6rfHat2KW51cdQkyctTwumfCQF0/wIxdE4e/LmSgpaM1DlQy1qcurmbkIfSzAwjr4o4lz1acjGAMGH4eAMNP05SRq4bC0lzSJdeN2enrWfjv3vN4a6ifOJiYGt7m+GR8se8iVod3N5quBSolCALir92Br5Mt7K2rHmwuhfScQmw4dBWjHmmptyL3g8ovKoGVuWm9tSjXN4afB8DwQ0RE1PhwnR8iIiKiSjD8EBERUZPC8ENERERNCsMPERERNSkMP0RERNSkMPwQERFRk8LwQ0RERE0Kww8RERE1KQw/RERE1KQw/BAREVGTwvBDRERETQrDDxERETUpDD9ERETUpDD8EBERUZNiJnUFjJEgCAAAlUolcU2IiIiotnTv27r38aow/FQiJycHAODp6SlxTYiIiOh+5eTkQKlUVrlfJtQUj5ogrVaLmzdvws7ODjKZrN6Oq1Kp4OnpieTkZCgUino7LlXEa20YvM6GwetsOLzWhtFQ11kQBOTk5MDNzQ0mJlWP7GHLTyVMTEzg4eHRYMdXKBT8ozIQXmvD4HU2DF5nw+G1NoyGuM7VtfjocMAzERERNSkMP0RERNSkMPwYkFwux3vvvQe5XC51VR56vNaGwetsGLzOhsNrbRhSX2cOeCYiIqImhS0/RERE1KQw/BAREVGTwvBDRERETQrDDxERETUpDD8G9L///Q9eXl6wtLREz549ceTIEamr1KhERETgkUcegZ2dHZycnBAWFoZz587plSksLMS0adPQrFkz2NraYsSIEUhLS9Mrk5SUhGHDhsHa2hpOTk548803UVJSYshTaVQiIyMhk8kwc+ZMcRuvc/24ceMGXnzxRTRr1gxWVlbw9/dHfHy8uF8QBMyfPx+urq6wsrJCSEgILly4oHeM27dvY8yYMVAoFLC3t8fEiRORm5tr6FMxWhqNBvPmzYO3tzesrKzQpk0bfPDBB3r3fuJ1rpsDBw7gySefhJubG2QyGbZu3aq3v76u6+nTp9GvXz9YWlrC09MTS5cuffDKC2QQUVFRgoWFhbB27VrhzJkzwiuvvCLY29sLaWlpUlet0QgNDRXWrVsnJCYmCidPnhQef/xxoWXLlkJubq5YZvLkyYKnp6cQHR0txMfHC7169RJ69+4t7i8pKRE6deokhISECCdOnBB27NghNG/eXJgzZ44Up2T0jhw5Inh5eQkBAQHCjBkzxO28zg/u9u3bQqtWrYTx48cLcXFxwuXLl4Xdu3cLFy9eFMtERkYKSqVS2Lp1q3Dq1CnhqaeeEry9vYWCggKxzJAhQ4TOnTsLhw8fFv766y/Bx8dHGD16tBSnZJQWL14sNGvWTNi+fbtw5coVYfPmzYKtra2wbNkysQyvc93s2LFDeOedd4RffvlFACBs2bJFb399XNfs7GzB2dlZGDNmjJCYmCh8//33gpWVlbBq1aoHqjvDj4H06NFDmDZtmvi9RqMR3NzchIiICAlr1bilp6cLAIT9+/cLgiAIWVlZgrm5ubB582axzD///CMAEGJjYwVBKP1jNTExEVJTU8UyK1asEBQKhaBWqw17AkYuJydH8PX1Ffbu3SsMGDBADD+8zvXjrbfeEvr27Vvlfq1WK7i4uAgfffSRuC0rK0uQy+XC999/LwiCIJw9e1YAIBw9elQss3PnTkEmkwk3btxouMo3IsOGDRNeeuklvW3PPPOMMGbMGEEQeJ3ry73hp76u65dffik4ODjo/d946623hHbt2j1QfdntZQBFRUU4duwYQkJCxG0mJiYICQlBbGyshDVr3LKzswEAjo6OAIBjx46huLhY7zr7+fmhZcuW4nWOjY2Fv78/nJ2dxTKhoaFQqVQ4c+aMAWtv/KZNm4Zhw4bpXU+A17m+/Prrr+jevTuee+45ODk5oWvXrvj666/F/VeuXEFqaqredVYqlejZs6fedba3t0f37t3FMiEhITAxMUFcXJzhTsaI9e7dG9HR0Th//jwA4NSpUzh48CCGDh0KgNe5odTXdY2NjUX//v1hYWEhlgkNDcW5c+dw586dOtePNzY1gIyMDGg0Gr03AgBwdnbGv//+K1GtGjetVouZM2eiT58+6NSpEwAgNTUVFhYWsLe31yvr7OyM1NRUsUxlPwfdPioVFRWF48eP4+jRoxX28TrXj8uXL2PFihV4/fXXMXfuXBw9ehSvvfYaLCwsMG7cOPE6VXYdy19nJycnvf1mZmZwdHTkdb7r7bffhkqlgp+fH0xNTaHRaLB48WKMGTMGAHidG0h9XdfU1FR4e3tXOIZun4ODQ53qx/BDjdK0adOQmJiIgwcPSl2Vh05ycjJmzJiBvXv3wtLSUurqPLS0Wi26d++ODz/8EADQtWtXJCYmYuXKlRg3bpzEtXt4/Pjjj9i4cSM2bdqEjh074uTJk5g5cybc3Nx4nZswdnsZQPPmzWFqalphNkxaWhpcXFwkqlXjNX36dGzfvh379u2Dh4eHuN3FxQVFRUXIysrSK1/+Oru4uFT6c9Dto9JurfT0dHTr1g1mZmYwMzPD/v37sXz5cpiZmcHZ2ZnXuR64urqiQ4cOetvat2+PpKQkAGXXqbr/Gy4uLkhPT9fbX1JSgtu3b/M63/Xmm2/i7bffxqhRo+Dv74+xY8fi//7v/xAREQGA17mh1Nd1baj/JQw/BmBhYYHAwEBER0eL27RaLaKjoxEUFCRhzRoXQRAwffp0bNmyBX/++WeFptDAwECYm5vrXedz584hKSlJvM5BQUFISEjQ+4Pbu3cvFApFhTeipio4OBgJCQk4efKk+OjevTvGjBkjfs3r/OD69OlTYamG8+fPo1WrVgAAb29vuLi46F1nlUqFuLg4veuclZWFY8eOiWX+/PNPaLVa9OzZ0wBnYfzy8/NhYqL/VmdqagqtVguA17mh1Nd1DQoKwoEDB1BcXCyW2bt3L9q1a1fnLi8AnOpuKFFRUYJcLhfWr18vnD17Vpg0aZJgb2+vNxuGqjdlyhRBqVQKMTExQkpKivjIz88Xy0yePFlo2bKl8Oeffwrx8fFCUFCQEBQUJO7XTcEePHiwcPLkSWHXrl1CixYtOAW7BuVnewkCr3N9OHLkiGBmZiYsXrxYuHDhgrBx40bB2tpa+O6778QykZGRgr29vbBt2zbh9OnTwvDhwyudKty1a1chLi5OOHjwoODr69vkp2CXN27cOMHd3V2c6v7LL78IzZs3F2bPni2W4XWum5ycHOHEiRPCiRMnBADCp59+Kpw4cUK4du2aIAj1c12zsrIEZ2dnYezYsUJiYqIQFRUlWFtbc6p7Y/L5558LLVu2FCwsLIQePXoIhw8flrpKjQqASh/r1q0TyxQUFAhTp04VHBwcBGtra+Hpp58WUlJS9I5z9epVYejQoYKVlZXQvHlz4Y033hCKi4sNfDaNy73hh9e5fvz2229Cp06dBLlcLvj5+QlfffWV3n6tVivMmzdPcHZ2FuRyuRAcHCycO3dOr0xmZqYwevRowdbWVlAoFMKECROEnJwcQ56GUVOpVMKMGTOEli1bCpaWlkLr1q2Fd955R2/qNK9z3ezbt6/S/8njxo0TBKH+ruupU6eEvn37CnK5XHB3dxciIyMfuO4yQSi3zCURERHRQ45jfoiIiKhJYfghIiKiJoXhh4iIiJoUhh8iIiJqUhh+iIiIqElh+CEiIqImheGHiIiImhSGHyKiSnh5eeGzzz6TuhpE1AAYfohIcuPHj0dYWBgAYODAgZg5c6bBXnv9+vWwt7evsP3o0aOYNGmSwepBRIZjJnUFiIgaQlFRESwsLOr8/BYtWtRjbYjImLDlh4iMxvjx47F//34sW7YMMpkMMpkMV69eBQAkJiZi6NChsLW1hbOzM8aOHYuMjAzxuQMHDsT06dMxc+ZMNG/eHKGhoQCATz/9FP7+/rCxsYGnpyemTp2K3NxcAEBMTAwmTJiA7Oxs8fUWLFgAoGK3V1JSEoYPHw5bW1soFAo8//zzSEtLE/cvWLAAXbp0wbfffgsvLy8olUqMGjUKOTk5DXvRiOi+MfwQkdFYtmwZgoKC8MorryAlJQUpKSnw9PREVlYWBg0ahK5duyI+Ph67du1CWloann/+eb3nb9iwARYWFvj777+xcuVKAICJiQmWL1+OM2fOYMOGDfjzzz8xe/ZsAEDv3r3x2WefQaFQiK83a9asCvXSarUYPnw4bt++jf3792Pv3r24fPkyRo4cqVfu0qVL2Lp1K7Zv347t27dj//79iIyMbKCrRUR1xW4vIjIaSqUSFhYWsLa2houLi7j9iy++QNeuXfHhhx+K29auXQtPT0+cP38ebdu2BQD4+vpi6dKlescsP37Iy8sLixYtwuTJk/Hll1/CwsICSqUSMplM7/XuFR0djYSEBFy5cgWenp4AgG+++QYdO3bE0aNH8cgjjwAoDUnr16+HnZ0dAGDs2LGIjo7G4sWLH+zCEFG9YssPERm9U6dOYd++fbC1tRUffn5+AEpbW3QCAwMrPPePP/5AcHAw3N3dYWdnh7FjxyIzMxP5+fm1fv1//vkHnp6eYvABgA4dOsDe3h7//POPuM3Ly0sMPgDg6uqK9PT0+zpXImp4bPkhIqOXm5uLJ598EkuWLKmwz9XVVfzaxsZGb9/Vq1fxxBNPYMqUKVi8eDEcHR1x8OBBTJw4EUVFRbC2tq7Xepqbm+t9L5PJoNVq6/U1iOjBMfwQkVGxsLCARqPR29atWzf8/PPP8PLygplZ7f9tHTt2DFqtFp988glMTEobun/88ccaX+9e7du3R3JyMpKTk8XWn7NnzyIrKwsdOnSodX2IyDiw24uIjIqXlxfi4uJw9epVZGRkQKvVYtq0abh9+zZGjx6No0eP4tKlS9i9ezcmTJhQbXDx8fFBcXExPv/8c1y+fBnffvutOBC6/Ovl5uYiOjoaGRkZlXaHhYSEwN/fH2PGjMHx48dx5MgRhIeHY8CAAejevXu9XwMialgMP0RkVGbNmgVTU1N06NABLVq0QFJSEtzc3PD3339Do9Fg8ODB8Pf3x8yZM2Fvby+26FSmc+fO+PTTT7FkyRJ06tQJGzduREREhF6Z3r17Y/LkyRg5ciRatGhRYcA0UNp9tW3bNjg4OKB///4ICQlB69at8cMPP9T7+RNRw5MJgiBIXQkiIiIiQ2HLDxERETUpDD9ERETUpDD8EBERUZPC8ENERERNCsMPERERNSkMP0RERNSkMPwQERFRk8LwQ0RERE0Kww8RERE1KQw/RERE1KQw/BAREVGTwvBDRERETcr/A9yjZHeKtsFKAAAAAElFTkSuQmCC\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WBgcFIj5u2Ml"
      },
      "source": [
        "---\n",
        "\n",
        "# Answer\n",
        "\n",
        "As we can see in this plot, the loss converges to around 2.5 much faster when compares to the bigram model without embeddings (only takes around 200 iterations).\n",
        "\n",
        "That is because our embedding modelling maps the tokens to a lower dimension space and the linear model can generalize the information of the tokens, so it can capture the information in similar tokens easily. The bigram model working on the next token's logits of each token, in this case the dimension will be high which will take a lot more time than our embedding modelling. Moreover, in bigram model is doing optimization is discrete space while the embedding modelling is working on continuous latent spaces, this continuous space makes the gradient-decent based optimization more efficient.\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "bigram_model_embed.to('cpu')\n",
        "torch.cuda.empty_cache()"
      ],
      "metadata": {
        "id": "nqq7GN10cLZt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ypOE6LnnGdyu"
      },
      "source": [
        "### 1.3: Attention: Relaxing Markovian assumptions to transmit information across the sequence length\n",
        "\n",
        "A major problem with the bigram models of Sections 1.1 and 1.2 was that they were Markovian: the distribution of the next token was determined entirely by the current token! The attention mechanism provides a way to extract information between the previous tokens in the context to provide a better parameterization for the distribution of the next token."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F-XHeM1VRO6H"
      },
      "source": [
        "#### Question 1.3.1: Averaging over word embeddings\n",
        "\n",
        "One simple way to pool information would simply be to average the embeddings!\n",
        "\n",
        "Your TODO: Add comments to the the code snippet below. Write a description here explaining why the code is mathematically equivalent to averaging the embeddings of the previous tokens and the current token."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S-8W0Xx_zsst"
      },
      "source": [
        "### Answer：\n",
        "The attention matrix $\\boldsymbol{A}$ (all description below used 0-indexed) is computed from a strictly lower triangular mask:\n",
        "$$\n",
        "A_{i j}=\\frac{\\mathbb{I}(j \\leq i)}{i+1}\n",
        "$$\n",
        "where $\\mathbb{I}(j \\leq i)$ is an indicator function that is 1 if $j \\leq i$ and 0 otherwise. Applying softmax ensure that each row sums to 1 .\n",
        "\n",
        "The average embeddings are computed as:\n",
        "$$\n",
        "\\text { avg_embeddings }=A X\n",
        "$$\n",
        "which results in:\n",
        "$$\n",
        "\\text { avg_embeddings }[t]=\\frac{1}{t+1} \\sum_{i=0}^{t-1} X[i]\n",
        "$$\n",
        "\n",
        "This formula shows that each embedding at time $t$ is the arithmetic mean of all embeddings from (0-indexed) $t=0$ to $t-1$, proving that the implementation is mathematically equivalent to averaging the embeddings of previous and current tokens.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gCaS07DtGgCr",
        "outputId": "e0b16e9a-503a-4fda-b862-240163d36273",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([4, 8, 2])\n",
            "tensor([[-0.0812, -1.8482],\n",
            "        [ 0.9644, -1.0071],\n",
            "        [ 1.0212, -0.2257],\n",
            "        [-1.6282,  0.3827],\n",
            "        [ 0.1593, -0.5935],\n",
            "        [-0.0302, -0.5043],\n",
            "        [ 0.4907, -1.5719],\n",
            "        [-1.1143,  1.1583]])\n",
            "\n",
            "tensor([[-0.0812, -1.8482],\n",
            "        [ 0.4416, -1.4276],\n",
            "        [ 0.6348, -1.0270],\n",
            "        [ 0.0691, -0.6746],\n",
            "        [ 0.0871, -0.6583],\n",
            "        [ 0.0676, -0.6327],\n",
            "        [ 0.1280, -0.7668],\n",
            "        [-0.0273, -0.5262]])\n"
          ]
        }
      ],
      "source": [
        "# average word embedding via matrix multiply and softmax\n",
        "small_batch_size = 4              # B\n",
        "small_context_window_size = 8     # T\n",
        "small_embed_size = 2              # D\n",
        "\n",
        "# make \"synthetic\" word embeddings (for illustration purposes only)\n",
        "X = torch.randn(small_batch_size, small_context_window_size, small_embed_size)\n",
        "\n",
        "# TODO: comment the code below\n",
        "print(X.shape)\n",
        "tril = torch.tril(torch.ones(small_context_window_size, small_context_window_size))\n",
        "attn_weights = torch.zeros((small_context_window_size, small_context_window_size))\n",
        "attn_weights = attn_weights.masked_fill(tril == 0, float('-inf'))\n",
        "attn_weights = F.softmax(attn_weights, dim=-1)\n",
        "avg_embeddings = attn_weights @ X\n",
        "print(X[0])\n",
        "print(\"\")\n",
        "print(avg_embeddings[0])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oIDlnRDGXaie"
      },
      "source": [
        "#### 1.3.2: Single-headed scaled $(Q,K,V)$-attention\n",
        "\n",
        "A more sophisticated approach than simply averaging over previous word embeddings is single-headed (Query, Key, Value) scaled attention.\n",
        "That is, we now summarize the information contained in a length $T$ sequence of tokens that have been embeded into $X \\in \\mathbb{R}^{T \\times D}$ according to\n",
        "\\begin{equation}\n",
        "   \\mathrm{SoftmaxAcrossRows} \\Bigg( \\frac{\\mathrm{CausalMask}\\Big(X U_q^\\top U_k X^\\top \\Big)}{\\sqrt{K}} \\Bigg) \\Big( X V^\\top \\Big),\n",
        "\\end{equation}\n",
        "where $U_q, U_k \\in \\mathbb{R}^{K \\times D}$, $V \\in \\mathbb{R}^{D \\times D}$, and $K$ is the \"head size\".\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E84BzzxPdwUd"
      },
      "source": [
        "##### Question 1.3.2.1\n",
        "\n",
        "In the limiting case where $U_q$ and $U_k$ are all zeros, and $V = I_{D}$, what does $(U_q, U_k, V)$ attention simplify to?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AmFw8z5Dz3T6"
      },
      "source": [
        "**Answer**:\n",
        "It simplifies to uniform averaging."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jeKfSrREhgdH"
      },
      "source": [
        "##### Question 1.3.2.2: Implement single-headed scaled $(U_q,U_k,V)$-attention.\n",
        "\n",
        "Complete the below code so the `forward` method returns single-headed scaled $(U_q,U_k,V)$-attention."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "O_eBPiT-Yy0q"
      },
      "outputs": [],
      "source": [
        "class Head(nn.Module):\n",
        "    \"\"\" one head of self-attention \"\"\"\n",
        "\n",
        "    def __init__(self, head_size, context_window_size, embed_size=384):\n",
        "        \"\"\"\n",
        "        Args:\n",
        "          head_size: int, size of the head embedding dimension (K)\n",
        "          context_window_size: int, number of tokens considered in the past for attention (T)\n",
        "          embed_size: int, size of the token embedding dimension (D)\n",
        "        \"\"\"\n",
        "        super().__init__()\n",
        "        self.head_size = head_size\n",
        "        self.key = nn.Linear(embed_size, head_size, bias=False)\n",
        "        self.query = nn.Linear(embed_size, head_size, bias=False)\n",
        "        self.value = nn.Linear(embed_size, embed_size, bias=False)\n",
        "\n",
        "        # not a param of the model, so registered as a buffer\n",
        "        self.register_buffer('tril', torch.tril(\n",
        "            torch.ones(context_window_size, context_window_size)))\n",
        "\n",
        "    def forward(self, x):\n",
        "        \"\"\"\n",
        "        Args:\n",
        "          x: (B,T,D) tensor of token embeddings\n",
        "\n",
        "        Returns:\n",
        "          (B,T,D) tensor of attention-weighted token embeddings\n",
        "        \"\"\"\n",
        "        # TODO: your code here\n",
        "        B,T,D = x.shape\n",
        "        k = self.key(x)\n",
        "        q = self.query(x)\n",
        "        v = self.value(x)\n",
        "        wei = q @ k.transpose(-2,-1) * self.head_size**-0.5\n",
        "        tril = torch.tril(torch.ones(T, T, device=x.device))\n",
        "        wei = wei.masked_fill(tril == 0, float('-inf'))\n",
        "        wei = F.softmax(wei, dim=-1)  ## wei.shape:\n",
        "        out = wei @ v\n",
        "        return out"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3RqGrCB21qUV"
      },
      "source": [
        "##### Question 1.3.2.3: Implement a single-headed attention language model\n",
        "\n",
        "Complete the code below. Note that because the transformer has no idea where tokens are occuring in space, we have also added in position embeddings."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "REr3aWnS1xJL"
      },
      "outputs": [],
      "source": [
        "class SingleHeadedAttentionLM(nn.Module):\n",
        "\n",
        "    def __init__(self, vocab_size, context_window_size, head_size, embed_size=384):\n",
        "      \"\"\"\n",
        "      Args:\n",
        "        vocab_size: int, size of the vocabulary (V)\n",
        "        context_window_size: int, number of tokens considered in the past for attention (T)\n",
        "        head_size: int, size of the head embedding dimension (K)\n",
        "        embed_size: int, size of the token embedding dimension (D)\n",
        "      \"\"\"\n",
        "      super().__init__()\n",
        "      self.token_embedding_table = nn.Embedding(vocab_size, embed_size)\n",
        "      self.position_embedding_table = nn.Embedding(context_window_size, embed_size)\n",
        "      self.context_window_size = context_window_size\n",
        "\n",
        "      # TODO: your code below\n",
        "      self.atten_head = Head(head_size, context_window_size)\n",
        "      self.lm_head = nn.Linear(embed_size, vocab_size)\n",
        "\n",
        "    def forward(self, token_ids, targets=None):\n",
        "        \"\"\"\n",
        "        Args:\n",
        "          token_ids: (B, T) token ids that make up the context (batch has size B, each entry\n",
        "                     in the batch has length T)\n",
        "          targets: (B, T) token ids corresponding to the target of each context in token_ids\n",
        "\n",
        "        Returns:\n",
        "          logits: (B, T, V) logits[b,t] gives the length V vector of logits for the next token\n",
        "                   prediction in string b up to t tokens\n",
        "          loss: scalar, negative log likelihood of target given context\n",
        "        \"\"\"\n",
        "        B, T = token_ids.shape # (batch size, length)\n",
        "        tok_emb = self.token_embedding_table(token_ids) # (B,T,D)\n",
        "        pos_emb = self.position_embedding_table(torch.arange(T, device=device)) # (T,D)\n",
        "        x = tok_emb + pos_emb # (B,T,D)\n",
        "        x = self.atten_head(x) # (B,T,D)\n",
        "        logits = self.lm_head(x) # (B,T,V)\n",
        "\n",
        "        # TODO: your code here\n",
        "        B, T, V = logits.shape\n",
        "        logits = logits.view(B*T, V)\n",
        "        if targets is None:\n",
        "            loss = None\n",
        "        else:\n",
        "            targets = targets.view(B*T)\n",
        "            loss = -torch.mean(torch.log(F.softmax(logits, dim=1)[torch.arange(B*T), targets]))\n",
        "        return logits, loss\n",
        "\n",
        "    @torch.no_grad()\n",
        "    def generate(self, token_ids, max_new_tokens):\n",
        "        \"\"\"\n",
        "        Args:\n",
        "          token_ids: (B, T) tensor of token ids to provide as context\n",
        "          max_new_tokens: int, maximum number of new tokens to generate\n",
        "\n",
        "        Returns:\n",
        "          (B, T+max_new_tokens) tensor of context with new tokens appended\n",
        "        \"\"\"\n",
        "        #TODO\n",
        "        # your code below\n",
        "        B, T = token_ids.shape\n",
        "        new_token_sequences = torch.zeros((B, T+max_new_tokens), dtype=torch.long, device=token_ids.device)\n",
        "        new_token_sequences[:, :T] = token_ids\n",
        "        return new_token_sequences"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "End-pUCa4RXe"
      },
      "source": [
        "Train your new `SingleHeadedAttentionLM` for `SMALL_ITERS` training iterations and plot the loss curve.\n",
        "The `head_size` shouldn't matter too much, we just use the `embedding_size`.\n",
        "Do you seen an improvement compared to your `BigramLanguageModel`? Discuss.\n",
        "\n",
        "Note: you may want to modify the learning rate. Training for `SMALL_ITERS` with a learning rate of `6e-4`, we can get to a train loss of around 2.3."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "070G_l0E0uG9",
        "outputId": "387d2da0-c6fa-46f9-922a-fc01c23b467f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/1000 [00:00<?, ?it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "iteration 0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  1%|          | 11/1000 [00:01<01:26, 11.42it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "step 0: train loss 4.1596, val loss 4.1590\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 19%|█▉        | 193/1000 [00:03<00:09, 89.36it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "iteration 200\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 21%|██        | 210/1000 [00:04<00:27, 29.01it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "step 200: train loss 2.5859, val loss 2.5918\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 39%|███▉      | 392/1000 [00:06<00:06, 87.84it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "iteration 400\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 41%|████      | 411/1000 [00:07<00:19, 30.35it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "step 400: train loss 2.4923, val loss 2.5154\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 60%|█████▉    | 599/1000 [00:09<00:04, 86.95it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "iteration 600\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 62%|██████▏   | 617/1000 [00:11<00:12, 30.32it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "step 600: train loss 2.3949, val loss 2.4291\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 80%|███████▉  | 799/1000 [00:13<00:02, 86.91it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "iteration 800\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 81%|████████  | 808/1000 [00:14<00:08, 22.88it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "step 800: train loss 2.3497, val loss 2.3980\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|█████████▉| 997/1000 [00:16<00:00, 86.98it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "iteration 999\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r100%|██████████| 1000/1000 [00:17<00:00, 57.47it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "step 999: train loss 2.3299, val loss 2.3743\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "embed_size = 384\n",
        "sha_model = SingleHeadedAttentionLM(vocab_size, CONTEXT_WINDOW_SIZE, embed_size, embed_size)\n",
        "sham = sha_model.to(device)\n",
        "learning_rate = 6e-4\n",
        "optimizer = torch.optim.AdamW(sha_model.parameters(), lr=learning_rate)\n",
        "\n",
        "eval_interval = 200\n",
        "\n",
        "loss_list = []\n",
        "\n",
        "for it in tqdm(range(SMALL_ITERS)):\n",
        "\n",
        "    # every once in a while evaluate the loss on train and val sets\n",
        "    if it % eval_interval == 0 or it == SMALL_ITERS - 1:\n",
        "        print(f\"iteration {it}\")\n",
        "        losses = estimate_loss(sham, EVAL_ITERS, CONTEXT_WINDOW_SIZE, device)\n",
        "        print(\n",
        "            f\"step {it}: train loss {losses['train']:.4f}, val loss {losses['val']:.4f}\"\n",
        "        )\n",
        "\n",
        "    # sample a batch of data\n",
        "    xb, yb = get_batch(\"train\", CONTEXT_WINDOW_SIZE, device)\n",
        "\n",
        "    # evaluate the loss\n",
        "    logits, loss = sham(xb, yb)\n",
        "    loss_list.append(loss.detach().item())\n",
        "    optimizer.zero_grad(set_to_none=True)\n",
        "    loss.backward()\n",
        "    optimizer.step()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## plot the loss_curve\n",
        "plt.plot(loss_list)\n",
        "plt.xlabel('Iteration')\n",
        "plt.ylabel('Loss')\n",
        "plt.title('Loss Curve')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "TaLaA0Eoc5Vm",
        "outputId": "c1853a0c-9993-47a2-c5b4-b85a38119654",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 472
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u05NFXpo0wWs"
      },
      "source": [
        "---\n",
        "\n",
        "# Answer\n",
        "\n",
        "As we can see in this plot, the loss converges to around 2.3, which is quite lower  compareing to the bigram model with embeddings. That is because the besides the current state, the infomation of previous states can help predict next tokens.\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sha_model.to('cpu')\n",
        "torch.cuda.empty_cache()"
      ],
      "metadata": {
        "id": "T1jVwxZlfVZv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7wjXYf-S4Lus"
      },
      "source": [
        "#### 1.3.3: Multi-headed attention"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZIObjMO0Ikp5"
      },
      "source": [
        "##### Question 1.3.3.1: Implement multi-headed attention"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "6vb8NU_s6Vfg"
      },
      "outputs": [],
      "source": [
        "\n",
        "class MultiHeadAttention(nn.Module):\n",
        "    def __init__(self, context_window_size, num_heads, embed_size):\n",
        "        super().__init__()\n",
        "        self.num_heads = num_heads\n",
        "        self.head_size = embed_size // num_heads  # 确保总维度匹配\n",
        "\n",
        "        self.heads = nn.ModuleList(\n",
        "            [Head(self.head_size, context_window_size, embed_size) for _ in range(num_heads)]\n",
        "        )\n",
        "        self.proj = nn.Linear(embed_size * num_heads, embed_size)  # 确保总维度匹配\n",
        "        self.dropout = nn.Dropout(0.1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = torch.cat([h(x) for h in self.heads], dim=-1)  # 拼接 heads\n",
        "\n",
        "        out = self.dropout(self.proj(out))  # 投影回 embed_size\n",
        "        return out\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aFCBRay3IuR3"
      },
      "source": [
        "##### Question 1.3.3.2: Implement a multi-headed attention LM\n",
        "\n",
        "Fill in the code below to create a language model that outputs its logits for next token prediction using multi-headed attention. Train your model for `SMALL_ITERS` training iterations. Compare the results with the single-headed attention model. Do you see an improvement?\n",
        "\n",
        "We get to a train loss of around 2 after 1000 iterations, which takes around 1.5 minutes on a T4 GPU."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "LvWHwcCzI1yr"
      },
      "outputs": [],
      "source": [
        "class MultiHeadedAttentionLM(nn.Module):\n",
        "\n",
        "    def __init__(self, vocab_size, context_window_size, embed_size=384, num_heads=6):\n",
        "      super().__init__()\n",
        "      self.head_size = embed_size // num_heads\n",
        "      self.context_window_size = context_window_size\n",
        "      # TODO: your code below\n",
        "      self.token_embedding_table = nn.Embedding(vocab_size, embed_size)\n",
        "      self.position_embedding_table = nn.Embedding(context_window_size, embed_size)\n",
        "      self.atten_heads = MultiHeadAttention(context_window_size, num_heads, embed_size)\n",
        "      self.lm_head = nn.Linear(embed_size, vocab_size)\n",
        "\n",
        "\n",
        "    def forward(self, token_ids, targets=None):\n",
        "        \"\"\"\n",
        "        Args:\n",
        "          token_ids: (B, T) token ids that make up the context (batch has size B, each entry in the\n",
        "                     batch has length T)\n",
        "          targets: (B, T) token ids corresponding to the target of each context in token_ids\n",
        "\n",
        "        Returns:\n",
        "          logits: (B, T, V), logits[b,t] gives the length V vector of logits for the next token\n",
        "                  prediction in string b up to t tokens\n",
        "          loss: scalar, negative log likelihood of target given context\n",
        "        \"\"\"\n",
        "        # TODO: your code below\n",
        "        B, T = token_ids.shape\n",
        "        tok_emb = self.token_embedding_table(token_ids)\n",
        "        pos_emb = self.position_embedding_table(torch.arange(T, device=device))\n",
        "        x = tok_emb + pos_emb\n",
        "        x = self.atten_heads(x)\n",
        "        logits = self.lm_head(x)\n",
        "        if targets is None:\n",
        "            loss = None\n",
        "        else:\n",
        "            logits = logits.view(B*T, -1)\n",
        "            targets = targets.view(B*T)\n",
        "            loss = -torch.mean(torch.log(F.softmax(logits, dim=1)[torch.arange(B*T), targets]))\n",
        "\n",
        "        return logits, loss\n",
        "\n",
        "    @torch.no_grad()\n",
        "    def generate(self, token_ids, max_new_tokens):\n",
        "        \"\"\"\n",
        "        Args:\n",
        "          token_ids: (B, T) tensor of token ids to provide as context\n",
        "          max_new_tokens: int, maximum number of new tokens to generate\n",
        "\n",
        "        Returns:\n",
        "          (B, T+max_new_tokens) tensor of context with new tokens appended\n",
        "        \"\"\"\n",
        "        # TODO: your code below\n",
        "        B, T = token_ids.shape\n",
        "        new_token_sequences = torch.zeros((B, T+max_new_tokens), dtype=torch.long, device=token_ids.device)\n",
        "        new_token_sequences[:, :T] = token_ids\n",
        "        return new_token_sequences"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hM9gOuPAMNcC",
        "outputId": "dc4da010-09ef-4901-b844-335f9148279f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/1000 [00:00<?, ?it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "iteration 0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 4/1000 [00:03<11:03,  1.50it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "step 0: train loss 4.1767, val loss 4.1758\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 20%|█▉        | 199/1000 [00:12<00:38, 20.73it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "iteration 200\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 20%|██        | 202/1000 [00:16<05:04,  2.62it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "step 200: train loss 2.4461, val loss 2.4720\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 40%|████      | 400/1000 [00:25<00:28, 20.97it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "iteration 400\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 40%|████      | 403/1000 [00:29<03:44,  2.66it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "step 400: train loss 2.1822, val loss 2.2393\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 60%|█████▉    | 598/1000 [00:38<00:18, 21.53it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "iteration 600\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 60%|██████    | 604/1000 [00:41<01:47,  3.67it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "step 600: train loss 2.0670, val loss 2.1585\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 80%|███████▉  | 799/1000 [00:50<00:09, 21.72it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "iteration 800\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 80%|████████  | 802/1000 [00:54<01:12,  2.73it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "step 800: train loss 1.9857, val loss 2.1090\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|█████████▉| 997/1000 [01:03<00:00, 21.73it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "iteration 999\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1000/1000 [01:06<00:00, 15.03it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "step 999: train loss 1.9391, val loss 2.0787\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "# Initialize model\n",
        "model = MultiHeadedAttentionLM(vocab_size, CONTEXT_WINDOW_SIZE)\n",
        "m = model.to(device)\n",
        "\n",
        "# create a PyTorch optimizer\n",
        "learning_rate = 6e-4\n",
        "optimizer = torch.optim.AdamW(model.parameters(), lr=learning_rate)\n",
        "\n",
        "eval_interval = 200\n",
        "\n",
        "loss_list = []\n",
        "\n",
        "for it in tqdm(range(SMALL_ITERS)):\n",
        "\n",
        "    # every once in a while evaluate the loss on train and val sets\n",
        "    if it % eval_interval == 0 or it == SMALL_ITERS - 1:\n",
        "        print(f\"iteration {it}\")\n",
        "        losses = estimate_loss(m, EVAL_ITERS, CONTEXT_WINDOW_SIZE, device)\n",
        "        print(f\"step {it}: train loss {losses['train']:.4f}, val loss {losses['val']:.4f}\")\n",
        "\n",
        "    # sample a batch of data\n",
        "    xb, yb = get_batch('train', CONTEXT_WINDOW_SIZE, device)\n",
        "\n",
        "    # evaluate the loss\n",
        "    logits, loss = m(xb, yb)\n",
        "    loss_list.append(loss.detach().item())\n",
        "    optimizer.zero_grad(set_to_none=True)\n",
        "    loss.backward()\n",
        "    optimizer.step()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## plot the loss curve\n",
        "plt.plot(loss_list)\n",
        "plt.xlabel('Iteration')\n",
        "plt.ylabel('Loss')\n",
        "plt.title('Loss Curve')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "il2mU02_glRK",
        "outputId": "c682c9bd-9559-4268-a22a-8308c8b980b8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 472
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAjcAAAHHCAYAAABDUnkqAAAAOnRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjEwLjAsIGh0dHBzOi8vbWF0cGxvdGxpYi5vcmcvlHJYcgAAAAlwSFlzAAAPYQAAD2EBqD+naQAAWilJREFUeJzt3Xdc1PXjB/DXMe6YdwyZgqCC4N4D90ocv9IyNTPX1yzXN2lYmQ03ltU3y7LMHJW7cmSOEHdOEBVw5gKVISJ7331+fyAH5x0IeHcfOF7Px4NH3Ofz/nzufZ/Se/WeEkEQBBARERGZCDOxK0BERESkTww3REREZFIYboiIiMikMNwQERGRSWG4ISIiIpPCcENEREQmheGGiIiITArDDREREZkUhhsiIiIyKQw3REREZFIYboioQmvXroVEIkFERITYVamUc+fO4ZVXXoG3tzdkMhmcnJzQv39/rFmzBkqlUuzqEZERWIhdASIifVm1ahWmTJkCNzc3jB07Fv7+/sjMzER4eDgmTZqEhIQEfPDBB2JXk4gMjOGGiEzCyZMnMWXKFAQFBWH37t2wt7dXnwsJCUFERARiYmL08l7Z2dmwtbXVy72ISP/YLUVEehEVFYVBgwZBLpfDzs4O/fr1w8mTJzXKFBYWYt68efD394eVlRWcnZ3RvXt3hIWFqcskJiZi4sSJ8PLygkwmg4eHB4YOHYpbt25V+P7z5s2DRCLB+vXrNYJNiQ4dOmDChAkAgEOHDkEikeDQoUMaZW7dugWJRIK1a9eqj02YMAF2dna4fv06Bg8eDHt7e4wZMwYzZsyAnZ0dcnJytN5r9OjRcHd31+gG27NnD3r06AFbW1vY29tjyJAhiI2NrfAzEVH1MNwQ0VOLjY1Fjx49cP78ebz77rv46KOPcPPmTfTu3RunTp1Sl5s7dy7mzZuHPn36YPny5ZgzZw4aNGiAs2fPqssMHz4c27Ztw8SJE/Hdd9/hjTfeQGZmJuLi4sp9/5ycHISHh6Nnz55o0KCB3j9fUVERgoOD4erqis8//xzDhw/HqFGjkJ2djb/++kurLn/++SdefPFFmJubAwB++eUXDBkyBHZ2dvj000/x0Ucf4eLFi+jevfsTQxsRVYNARFSBNWvWCACEM2fOlFtm2LBhglQqFa5fv64+du/ePcHe3l7o2bOn+ljr1q2FIUOGlHufhw8fCgCEpUuXVqmO58+fFwAIM2fOrFT5gwcPCgCEgwcPahy/efOmAEBYs2aN+tj48eMFAML777+vUValUgn169cXhg8frnF8y5YtAgDhyJEjgiAIQmZmpuDg4CBMnjxZo1xiYqKgUCi0jhPR02PLDRE9FaVSib///hvDhg1Do0aN1Mc9PDzw8ssv49ixY8jIyAAAODg4IDY2FteuXdN5L2tra0ilUhw6dAgPHz6sdB1K7q+rO0pfpk6dqvFaIpFgxIgR2L17N7KystTHN2/ejPr166N79+4AgLCwMKSlpWH06NFISUlR/5ibm6Nz5844ePCgwepMVFcx3BDRU7l//z5ycnIQEBCgda5p06ZQqVSIj48HAMyfPx9paWlo0qQJWrZsiVmzZuHChQvq8jKZDJ9++in27NkDNzc39OzZE5999hkSExMrrINcLgcAZGZm6vGTlbKwsICXl5fW8VGjRiE3Nxc7d+4EAGRlZWH37t0YMWIEJBIJAKiDXN++feHi4qLx8/fffyM5OdkgdSaqyxhuiMhoevbsievXr2P16tVo0aIFVq1ahXbt2mHVqlXqMiEhIbh69SpCQ0NhZWWFjz76CE2bNkVUVFS59/Xz84OFhQWio6MrVY+S4PG48tbBkclkMDPT/uuyS5cu8PX1xZYtWwAAf/75J3JzczFq1Ch1GZVKBaB43E1YWJjWz44dOypVZyKqPIYbInoqLi4usLGxwZUrV7TOXb58GWZmZvD29lYfc3JywsSJE7Fx40bEx8ejVatWmDt3rsZ1jRs3xttvv42///4bMTExKCgowBdffFFuHWxsbNC3b18cOXJE3UpUEUdHRwBAWlqaxvHbt28/8drHjRw5Env37kVGRgY2b94MX19fdOnSReOzAICrqyv69++v9dO7d+8qvycRVYzhhoieirm5OQYMGIAdO3ZozPxJSkrChg0b0L17d3W30YMHDzSutbOzg5+fH/Lz8wEUzzTKy8vTKNO4cWPY29ury5Tnk08+gSAIGDt2rMYYmBKRkZFYt24dAMDHxwfm5uY4cuSIRpnvvvuuch+6jFGjRiE/Px/r1q3D3r17MXLkSI3zwcHBkMvlWLx4MQoLC7Wuv3//fpXfk4gqxkX8iKhSVq9ejb1792odnzlzJhYuXIiwsDB0794d06ZNg4WFBX744Qfk5+fjs88+U5dt1qwZevfujfbt28PJyQkRERH47bffMGPGDADA1atX0a9fP4wcORLNmjWDhYUFtm3bhqSkJLz00ksV1q9r16749ttvMW3aNAQGBmqsUHzo0CHs3LkTCxcuBAAoFAqMGDEC33zzDSQSCRo3boxdu3ZVa/xLu3bt4Ofnhzlz5iA/P1+jSwooHg+0YsUKjB07Fu3atcNLL70EFxcXxMXF4a+//kK3bt2wfPnyKr8vEVVA7OlaRFSzlUwFL+8nPj5eEARBOHv2rBAcHCzY2dkJNjY2Qp8+fYTjx49r3GvhwoVCp06dBAcHB8Ha2loIDAwUFi1aJBQUFAiCIAgpKSnC9OnThcDAQMHW1lZQKBRC586dhS1btlS6vpGRkcLLL78seHp6CpaWloKjo6PQr18/Yd26dYJSqVSXu3//vjB8+HDBxsZGcHR0FF5//XUhJiZG51RwW1vbCt9zzpw5AgDBz8+v3DIHDx4UgoODBYVCIVhZWQmNGzcWJkyYIERERFT6sxFR5UgEQRBES1ZEREREesYxN0RERGRSGG6IiIjIpDDcEBERkUlhuCEiIiKTwnBDREREJoXhhoiIiExKnVvET6VS4d69e7C3ty93fxkiIiKqWQRBQGZmJjw9PXXu9VZWnQs39+7d09jnhoiIiGqP+Ph4eHl5VVimzoUbe3t7AMUPp2S/GyIiIqrZMjIy4O3trf4er0idCzclXVFyuZzhhoiIqJapzJASDigmIiIik8JwQ0RERCaF4YaIiIhMCsMNERERmRSGGyIiIjIpDDdERERkUhhuiIiIyKQw3BAREZFJYbghIiIik8JwQ0RERCaF4YaIiIhMCsMNERERmZQ6t3GmoeQUFCE1uwBSCzO42luJXR0iIqI6iy03ehJ2MQndPz2INzefE7sqREREdRrDjZ6YPdqCXaUSuSJERER1HMONnqjDjSCIXBMiIqK6jeFGT8yKsw2YbYiIiMTFcKMnjxpu2HJDREQkMoYbPZE8SjeMNkREROJiuNETjrkhIiKqGRhu9MRM3S0lbj2IiIjqOoYbPSlpuRHYckNERCQqhhs94YBiIiKimoHhRk+4iB8REVHNwHCjJxxQTEREVDMw3OgJF/EjIiKqGRhu9ETClhsiIqIageFGT8w4oJiIiKhGYLjREzOzkqngIleEiIiojmO40RO23BAREdUMDDd6UjrmRuSKEBER1XEMN3rCqeBEREQ1A8ONnnAqOBERUc3AcKMnbLkhIiKqGRhu9IR7SxEREdUMDDd6YsYBxURERDVCjQk3S5YsgUQiQUhISIXltm7disDAQFhZWaFly5bYvXu3cSr4BCXhRmDLDRERkahqRLg5c+YMfvjhB7Rq1arCcsePH8fo0aMxadIkREVFYdiwYRg2bBhiYmKMVNPylXZLiVsPIiKiuk70cJOVlYUxY8bgxx9/hKOjY4Vlly1bhoEDB2LWrFlo2rQpFixYgHbt2mH58uVGqm35SmdLMd0QERGJSfRwM336dAwZMgT9+/d/YtkTJ05olQsODsaJEyfKvSY/Px8ZGRkaP4bARfyIiIhqBgsx33zTpk04e/Yszpw5U6nyiYmJcHNz0zjm5uaGxMTEcq8JDQ3FvHnznqqelcGp4ERERDWDaC038fHxmDlzJtavXw8rKyuDvc/s2bORnp6u/omPjzfI+3ARPyIioppBtJabyMhIJCcno127dupjSqUSR44cwfLly5Gfnw9zc3ONa9zd3ZGUlKRxLCkpCe7u7uW+j0wmg0wm02/ldWDLDRERUc0gWstNv379EB0djXPnzql/OnTogDFjxuDcuXNawQYAgoKCEB4ernEsLCwMQUFBxqp2ubiIHxERUc0gWsuNvb09WrRooXHM1tYWzs7O6uPjxo1D/fr1ERoaCgCYOXMmevXqhS+++AJDhgzBpk2bEBERgZUrVxq9/o/jIn5EREQ1g+izpSoSFxeHhIQE9euuXbtiw4YNWLlyJVq3bo3ffvsN27dv1wpJYuAifkRERDWDRKhj38YZGRlQKBRIT0+HXC7X232TM/LQaXE4zM0kuL54sN7uS0RERFX7/q7RLTe1iYQDiomIiGoEhhs9KTsVvI41hhEREdUoDDd6UjLmBuBaN0RERGJiuNGTsuGGXVNERETiYbjRE0mZJ8np4EREROJhuNETttwQERHVDAw3emJWmm045oaIiEhEDDd6wpYbIiKimoHhRk/KZBuGGyIiIhEx3OiJBGVbbkSsCBERUR3HcKMnmmNumG6IiIjEwnCjJ1zEj4iIqGZguNETjrkhIiKqGRhu9EQikagDDsfcEBERiYfhRo9KuqY45oaIiEg8DDd6ZMaWGyIiItEx3OiR5FHLDcfcEBERiYfhRo9KW24YboiIiMTCcKNHpWNuRK4IERFRHcZwo0dm7JYiIiISHcONHnEqOBERkfgYbvSILTdERETiY7jRo5IBxVznhoiISDwMN3pU2nIjckWIiIjqMIYbPeI6N0REROJjuNEj9To3KnHrQUREVJcx3OgRBxQTERGJj+FGj7hCMRERkfgYbvTI7FG6UXJEMRERkWgYbvTI3IzdUkRERGJjuNEjc04FJyIiEh3DjR6VbL/AbikiIiLxMNzokbpbiuGGiIhINAw3elQyFVzJMTdERESiYbjRI3POliIiIhIdw40elYQbNtwQERGJh+FGj0r2lmLLDRERkXgYbvTIvGS2FJtuiIiIRMNwo0ecLUVERCQ+hhs94mwpIiIi8THc6FHp9gsiV4SIiKgOY7jRo5KWG3ZLERERiYfhRo+4KzgREZH4GG70iLOliIiIxMdwo0ecLUVERCQ+hhs94mwpIiIi8THc6JF6QDGzDRERkWgYbvSI3VJERETiY7jRI86WIiIiEh/DjR6VzJZSccwNERGRaBhu9IgtN0REROJjuNEjDigmIiISH8ONHpmrww3TDRERkVgYbvSI3VJERETiY7jRI/NHT5PhhoiISDwMN3rEbikiIiLxMdzoUUm3FMMNERGReBhu9Ei9t5RK5IoQERHVYQw3emTOlhsiIiLRMdzoUWnLDcMNERGRWBhu9IizpYiIiMTHcKNHJbOlBHZLERERiUbUcLNixQq0atUKcrkccrkcQUFB2LNnT7nl165dC4lEovFjZWVlxBpXTFLSLcVwQ0REJBoLMd/cy8sLS5Ysgb+/PwRBwLp16zB06FBERUWhefPmOq+Ry+W4cuWK+nVJoKgJzM04W4qIiEhsooabZ599VuP1okWLsGLFCpw8ebLccCORSODu7m6M6lWZerYUx9wQERGJpsaMuVEqldi0aROys7MRFBRUbrmsrCz4+PjA29sbQ4cORWxsrBFrWTEzdksRERGJTtSWGwCIjo5GUFAQ8vLyYGdnh23btqFZs2Y6ywYEBGD16tVo1aoV0tPT8fnnn6Nr166IjY2Fl5eXzmvy8/ORn5+vfp2RkWGQzwGUzpbiOjdERETiEb3lJiAgAOfOncOpU6cwdepUjB8/HhcvXtRZNigoCOPGjUObNm3Qq1cv/PHHH3BxccEPP/xQ7v1DQ0OhUCjUP97e3ob6KFznhoiIqAYQPdxIpVL4+fmhffv2CA0NRevWrbFs2bJKXWtpaYm2bdvi33//LbfM7NmzkZ6erv6Jj4/XV9W1SC2KH2chRxQTERGJRvRw8ziVSqXRjVQRpVKJ6OhoeHh4lFtGJpOpp5qX/BiK9FG/VEERww0REZFYRB1zM3v2bAwaNAgNGjRAZmYmNmzYgEOHDmHfvn0AgHHjxqF+/foIDQ0FAMyfPx9dunSBn58f0tLSsHTpUty+fRuvvvqqmB9DzbIk3CjZLUVERCQWUcNNcnIyxo0bh4SEBCgUCrRq1Qr79u3DM888AwCIi4uDmVlp49LDhw8xefJkJCYmwtHREe3bt8fx48fLHYBsbCXdUgVFSpFrQkREVHdJhDq2V0BGRgYUCgXS09P13kW1NyYRU36NRHsfR/w+tate701ERFSXVeX7u8aNuanNZBxQTEREJDqGGz2y5IBiIiIi0THc6JF6zA1bboiIiETDcKNHlubFi/ix5YaIiEg8DDd6xEX8iIiIxMdwo0dcxI+IiEh8DDd6VNpyU6dm1xMREdUoDDd6xNlSRERE4mO40aPS7RdUqGNrIxIREdUYDDd6VNItBbBrioiISCwMN3pUMqAY4IwpIiIisTDc6FHZlhuOuyEiIhIHw40emZtJYG72aCE/ttwQERGJguFGz6wetd7kFSpFrgkREVHdxHCjZ1aW5gCAvEK23BAREYmB4UbPSsJNLltuiIiIRMFwo2cyS3ZLERERiYnhRs+sLEq6pRhuiIiIxMBwo2fWUo65ISIiEhPDjZ5ZPeqWyi9iyw0REZEYGG70rKRbKreA4YaIiEgMDDd6VjoVnOGGiIhIDAw3eqaeLcXtF4iIiETBcKNnbLkhIiISF8ONnllzET8iIiJRMdzomYu9DACQmJ4nck2IiIjqJoYbPfN1tgEA3HqQI3JNiIiI6iaGGz3zcbYFANxKyRa5JkRERHUTw42eucmtAADpuYVQqgSRa0NERFT3MNzomdSi9JEWcDo4ERGR0THc6JmM4YaIiEhUDDd6ZmEmgURS/Dv3lyIiIjI+hhs9k0gkkJqXbJ7JlhsiIiJjY7gxgJKuqQIlww0REZGxMdwYgPTRzuD5hQw3RERExsZwYwBsuSEiIhIPw40BlISbfO4vRUREZHQMNwYgZcsNERGRaBhuDKC05YbhhoiIyNgYbgyALTdERETiYbgxANmj2VJcoZiIiMj4GG4MoKTlhisUExERGR/DjQGop4Kz5YaIiMjoGG4MoLTlhuGGiIjI2BhuDEDGcENERCQahhsDYMsNERGReBhuDEBqztlSREREYmG4MQCZJQcUExERiYXhxgCk5pwKTkREJBaGGwNgyw0REZF4qhVu4uPjcefOHfXr06dPIyQkBCtXrtRbxWqz0pYbhhsiIiJjq1a4efnll3Hw4EEAQGJiIp555hmcPn0ac+bMwfz58/VawdpIZskBxURERGKpVriJiYlBp06dAABbtmxBixYtcPz4caxfvx5r167VZ/1qJRnH3BAREYmmWuGmsLAQMpkMALB//34899xzAIDAwEAkJCTor3a1FHcFJyIiEk+1wk3z5s3x/fff4+jRowgLC8PAgQMBAPfu3YOzs7NeK1gbcW8pIiIi8VQr3Hz66af44Ycf0Lt3b4wePRqtW7cGAOzcuVPdXVWXcYViIiIi8VhU56LevXsjJSUFGRkZcHR0VB9/7bXXYGNjo7fK1VYyCw4oJiIiEku1Wm5yc3ORn5+vDja3b9/GV199hStXrsDV1VWvFayN2HJDREQknmqFm6FDh+Lnn38GAKSlpaFz58744osvMGzYMKxYsUKvFayNOOaGiIhIPNUKN2fPnkWPHj0AAL/99hvc3Nxw+/Zt/Pzzz/j666/1WsHayFZW3NuXkVsock2IiIjqnmqFm5ycHNjb2wMA/v77b7zwwgswMzNDly5dcPv2bb1WsDZyV1gBADLzi5CVXyRybYiIiOqWaoUbPz8/bN++HfHx8di3bx8GDBgAAEhOToZcLtdrBWsjO5kF7B+13iSm54lcGyIiorqlWuHm448/xjvvvANfX1906tQJQUFBAIpbcdq2bavXCtZWHg7FrTcMN0RERMZVrXDz4osvIi4uDhEREdi3b5/6eL9+/fC///2v0vdZsWIFWrVqBblcDrlcjqCgIOzZs6fCa7Zu3YrAwEBYWVmhZcuW2L17d3U+gsG5K6wBAAnpuSLXhIiIqG6pVrgBAHd3d7Rt2xb37t1T7xDeqVMnBAYGVvoeXl5eWLJkCSIjIxEREYG+ffti6NChiI2N1Vn++PHjGD16NCZNmoSoqCgMGzYMw4YNQ0xMTHU/hsF4yItbbhLYckNERGRU1Qo3KpUK8+fPh0KhgI+PD3x8fODg4IAFCxZApar89Odnn30WgwcPhr+/P5o0aYJFixbBzs4OJ0+e1Fl+2bJlGDhwIGbNmoWmTZtiwYIFaNeuHZYvX16dj2FQJYOKGW6IiIiMq1orFM+ZMwc//fQTlixZgm7dugEAjh07hrlz5yIvLw+LFi2q8j2VSiW2bt2K7Oxs9Riex504cQJvvfWWxrHg4GBs37693Pvm5+cjPz9f/TojI6PKdasOT/WYG3ZLERERGVO1ws26deuwatUq9W7gANCqVSvUr18f06ZNq1K4iY6ORlBQEPLy8mBnZ4dt27ahWbNmOssmJibCzc1N45ibmxsSExPLvX9oaCjmzZtX6froi+ujbqmkjPwnlCQiIiJ9qla3VGpqqs6xNYGBgUhNTa3SvQICAnDu3DmcOnUKU6dOxfjx43Hx4sXqVEun2bNnIz09Xf0THx+vt3tXRGFtCQDIzOdCfkRERMZUrXDTunVrneNcli9fjlatWlXpXlKpFH5+fmjfvj1CQ0PRunVrLFu2TGdZd3d3JCUlaRxLSkqCu7t7ufeXyWTq2VglP8YgtyoONxm5XMSPiIjImKrVLfXZZ59hyJAh2L9/v3p8zIkTJxAfH//UU7NVKpXGGJmygoKCEB4ejpCQEPWxsLCwcsfoiEluXfxoM/MKIQgCJBKJyDUiIiKqG6rVctOrVy9cvXoVzz//PNLS0pCWloYXXngBsbGx+OWXXyp9n9mzZ+PIkSO4desWoqOjMXv2bBw6dAhjxowBAIwbNw6zZ89Wl585cyb27t2LL774ApcvX8bcuXMRERGBGTNmVOdjGFRJy41KALILlCLXhoiIqO6oVssNAHh6emoNHD5//jx++uknrFy5slL3SE5Oxrhx45CQkACFQoFWrVph3759eOaZZwAAcXFxMDMrzV9du3bFhg0b8OGHH+KDDz6Av78/tm/fjhYtWlT3YxiMzMIMUnMzFChVyMgthJ2s2o+aiIiIqkDUb9yffvqpwvOHDh3SOjZixAiMGDHCQDXSH4lEArm1BVKyCpCRVwhPWItdJSIiojqh2isU05PZc1AxERGR0THcGJDcqnRQMRERERlHlbqlXnjhhQrPp6WlPU1dTI780Vo3GQw3RERERlOlcKNQKJ54fty4cU9VIVNi/6jlht1SRERExlOlcLNmzRpD1cMklUwHZ7cUERGR8XDMjQGVdkux5YaIiMhYGG4MyF5W0i3FlhsiIiJjYbgxIA4oJiIiMj6GGwMq2Rk8LYfhhoiIyFgYbgzIyVYKAEjNLhC5JkRERHUHw40BlYSbBww3RERERsNwY0D17GQAiltuVCpB5NoQERHVDQw3BuRoWzzmRqkSkJKdL3JtiIiI6gaGGwOSWZjD7tF08E6LwqFk6w0REZHBMdwYmCCUBpoHbL0hIiIyOIYbAysq01qTV6ASsSZERER1A8ONgb3Qrr769+wCbsNARERkaAw3BjZ7cFP179n5DDdERESGxnBjYHIrSzTzkAMAsguUIteGiIjI9DHcGIGtzBwAkMOWGyIiIoNjuDECG2nxdHC23BARERkew40RWJoXP+Z3tp7HnYc5IteGiIjItDHcGMGpGw/Uv4dfShaxJkRERKaP4cYIxnTxUf+exXE3REREBsVwYwQz+vqhvoM1AIYbIiIiQ2O4MQI7mYV6MT/OmCIiIjIshhsjsX20gWZWPmdMERERGRLDjZHYSovXuuEqxURERIbFcGMkJS033F+KiIjIsBhujKS0W4rhhoiIyJAYbozE7lG4iYpLw++Rd0SuDRERkeliuDESRxup+ve3t55HfhEHFhMRERkCw42R+LvZabyOvP1QpJoQERGZNoYbI7E0N4O3k7X69dXETBFrQ0REZLoYboxo6+td0aK+HAAw98+LuJ+ZL3KNiIiITA/DjRG5K6wwPshX/fq/G8+KVxkiIiITxXBjZPXsZerfT95IFbEmREREponhxsjq2cqeXIiIiIiqjeHGyOrZSzVe/3ziFqeFExER6RHDjZE5P9Zy8/GOWKw6elOk2hAREZkehhsjk1poP/JTNzn2hoiISF8YbkTw66TOGq+l5mZ4kJWPVUdv4EEWp4cTERE9DQuxK1AXya01H/v+S0kY/HUakjLyEX03HcteaitSzYiIiGo/ttyIwEZqrnUsKaO4xWbHuXu4msTVi4mIiKqL4UYE1tKKG8w++CPaSDUhIiIyPQw3IrC21G65KSsrv8hINSEiIjI9DDcicLKV4r2BgfBQWOk8r6vbioiIiCqH4UYkU3s3xpjODXSeOxuXhmscd0NERFQtDDcispWVjr2xl2mOw3nx+xPGrg4REZFJYLgR0aiO3ugd4IKFw1ogel4w3n6mifpcem4hBEEQsXZERES1E9e5EZGN1AJrJ3ZSv27t7aBxPjEjDx4KayPXioiIqHZjy00N4ibXHGB8MyVbpJoQERHVXgw3NUiAuz2+f6UdFNaWAICkjDwAgEolYM62aDz/3T/IyCsUs4pEREQ1nkSoYwM7MjIyoFAokJ6eDrlcLnZ1dHpryzn8cfauznOzggMwrXdjSCQSI9eKiIhIPFX5/mbLTQ0k07FzeIml+67gl5O3jVgbIiKi2oXhpgZyspVWeP7jHbFIycrH7D+icfLGAwBAboEShUoVcgq4ujEREdVt7JaqgTLzCjH/z4vYGnlHfWxa78b47tB1neXD3+6F4SuOIy2nEDZScxx8p7fW4GQiIqLajN1StZy9lSWWjmiNHv71AAB9A13x7sBAdGnkpLP8W5vPIS2neKBxToESm8/EG62uRERENQ3DTQ227KW2CH2hJZa91AYAsHBYC53lzt9J13hdpFSVe8+CovLP1bFGPCIiMlEMNzWYk60Uozs1gL1V8dTwyi7o9/WBf/HqugjcS8vVOJ6Qnov2C8Iw+49orWsOXklGkw/3YMc53bO0iIiIaguGm1rEVmaBb19uB39XuyeW3X8pCe9sPQ+geJ2ciWtOIyj0ADLzi7DxdBx2nLuL9NzSNXMmrjmDQqWAkM3nDFV9IiIio+D2C7XMkFYeeKaZG5p8uOeJZY9ff4BVR29g14UEnItP0zg3c9M5AMCP4zrA2tJcfbxkAUEiIqLaiuGmFpLqWAenSyMnnLyRqnV84V+XKrzX5J8jNF47MNwQEVEtJ2q3VGhoKDp27Ah7e3u4urpi2LBhuHLlSoXXrF27FhKJROPHyqruTnue2M0Xv0zqhLUTO+H4+33x95s9n+p+tx7kaIzVuZuWq94GokipwsHLycgrVAIAEtPz8NrPEfjn35Snek8iIiJ9ErXl5vDhw5g+fTo6duyIoqIifPDBBxgwYAAuXrwIW1vbcq+Ty+UaIagub0XQw78eevi7AAA8HazVweNpdF1yAC93boDZgwIxeNlRpOcWwsux+N4pWQUAgF5NXCAAOHL1Pv6+mIRbS4Y89fsSERHpg6jhZu/evRqv165dC1dXV0RGRqJnz/JbICQSCdzd3Q1dvRrtyKw+uJiQgT4BrhrHrSzNsfTFVpj12wUAwIW5A3DjfjbmbItG7L0MjbKNXGxx477uncc3nIrD8X9T1IOO7zzUnHl1+Op9rWuKlCoUKFXIzCvC+fg0+LnaoZFL6eBnQRDww5EbaFVfga5+9ar+oYmIiCqhRo25SU8vXq/FyUn3YnUlsrKy4OPjA5VKhXbt2mHx4sVo3ry5zrL5+fnIz89Xv87IyNBZrrZp4GyDBs42Os91alj6/ORWlmjj7YAvR7ZB8FdH1MfbeDugcyMn/HD4RrnvcetBTqXr02b+3/B2tMHVpEzkl1lL59qiQbA0L+79XLDrElb/c7P43mVaeuJTc+BiL4NVmYHNRERE1VVjpoKrVCqEhISgW7duaNFC92J1ABAQEIDVq1djx44d+PXXX6FSqdC1a1fcuXNHZ/nQ0FAoFAr1j7e3t6E+Qo3h42yLVeM6YPv0bupjAe72mNyjIeo7WOPDIU3x47gOeC84EL9PDYKrvQwAsPj5luWugvwkaTmFiL6brhFsAMB/zh4s2XMZ99Jy1cEGALLzixCfmoNJa8+gx2cH1QObwy8l4fnv/sH1+1nVqgcREVGN2Vtq6tSp2LNnD44dOwYvL69KX1dYWIimTZti9OjRWLBggdZ5XS033t7eNXpvKWO7cT8Ltx/koE+gK5QqAT8du4HtUfdgKzNHYxc7bHq0nUP/pq7Yfym5Wu/xy6ROGPvTafXrP2d0x9T1kRrdXZN7NMSPR4sDUDMPOXbP7PEUn4qIiExJVfaWqhHhZsaMGdixYweOHDmChg0bVvn6ESNGwMLCAhs3bnxi2dqwcWZN88+/KXC1l8HfzR6CIGDpvitwsZfhYXYBXOVW+HB7TJXv+eGQpk+cpr7/rV5IzS7AyB9OwMHGEn/O6I76DtYI2XwOtjILhL7QsrofiYiIapmqfH+LOuZGEAT897//xbZt23Do0KFqBRulUono6GgMHjzYADUkAOhWZvCvRCLBuwMD1a+LlCrsunAPuQVKbHytC4Z9+w+uJpV2KfVs4oIjOgYfPynYAED/Lw+rf0/LKcR7v1/ArOAA7Dx/DwAgszBD+OUkbJ/WDc52smp9NiIiMj2ittxMmzYNGzZswI4dOxAQEKA+rlAoYG1dvI/SuHHjUL9+fYSGhgIA5s+fjy5dusDPzw9paWlYunQptm/fjsjISDRr1uyJ78mWG8PKyCtEq7l/q1+/2r0hVh0rHWtTz06qnk4OAFaWZsgrLH8zz8p4s38TzOzv/1T3ICKimq0q39+iDihesWIF0tPT0bt3b3h4eKh/Nm/erC4TFxeHhIQE9euHDx9i8uTJaNq0KQYPHoyMjAwcP368UsGGDE9uZYkFj3YvXzCsBfzdSqeCS83N8NP4jhrlnW2fvsXlYU4BtkTE62WNHyIiqv1qxJgbY2LLjXGkZhfAyVaKY9dS8MpPpwAA/xvVGs+39cLYn07h6LXiVY03v9YFo388CZUe/ivs4V8Pv0zq/PQ3IiKiGqfWjLkh0+VkKwUAeDiUbo3hYF18bNlLbTHvz1iMC/JBex8nhL3VC9F30uHtZIPhK45X+z1LAhNQPJ5rwa5LaFjPBmODfKt9TyIiqn0YbsigPBSl4cbcrHibDCdbKZa91FZ9vLGLHRq72OFuWq7W9boMbeOJHefu6TyXnJmH+5n5GPL1MfWxV7r4aG3REbr7EmLvZWDNxI648zAXznZSyK24aSgRkSlguCGDspGW/ifmU86KyiXqO1jj69FtsT3qLiJvP1Rv/VDiwyFN0auJC/zd7FGoVGF3dKLWPTotCofcSvM/6ym/RuK1no3R3scReYVKvP/7BWx/FI42nIrDJztj0cDJBkfe7VPdj0lERDUIx9yQwV1JzMT9zHx096/8flJ5hUoEfqS591jZLRtSsvLReXE4lFUYrPN6r0bwdrTRWJentZcC5++ka92fiIhqllozW4rqhgB3+yoFG6B4DZsSL3dugN1vaK5WXM9Ohp0zuj1+WYV+OHxDa/PQsmvyEBGRaWC4oRpJIpEgwM0eAPBucACaeWqn9OaeClxeMBBtGzjovEe/QFetYxl5ml1duWWmj9exRkwiIpPFbimqsfIKlcgvUkFhXfFAX0EQ0HD2bq3jNxYPRkp2PkZ8fwK3K7HD+e43eugMUUREJD52S5FJsLI0f2KwAaA1Ewoo3pjTzEwCV3srje0jKjL466O4mZJd5XoSEVHNwnBDJif87V5o6aVQv36vzF5YJZ5t7anz2j6fH8KBy0nYHnUXVxIzDVZHIiIyHIYbMin1HazR2MVO45jC2hLnPxmA/3Qr3ZjV0ab8FqH/rI1AyOZzCP7qCA5cTsKOc3cBAJ/tvYw+nx/Cw+yCcq8lIiLxMdyQSXizfxMAQOgLLXWeV1hb4uNnm2F8kA8kEmB0pwaVuu9/1kZg5qZzSM7Iw3eHruNmSjbWHr+F0zdT2bJDRFRDcRE/Mgkz+/tjUo+GsJNV/J/0x882x7sDA2Ers4DU3AwFysrtSJ5dUDqr6nJiBpaFXwPAtXGIiGoittyQyXhSsAGKt4CwfVRu/eTO6OTrVKl7p2bnq3/fF5uk/j07v6iKtSQiIkNjuKE6q6OvE7ZMCVK/lpqX/8chPlX3vlcpWfk6jxMRkXgYbqjO2xfSEx/9XzOc/fiZcsuEbD6n8/j9TIYbIqKahuGG6rwAd3tM6l48XuevN7pjXJAPLMy0187R5c7D0hadkvUwY+6mY2+M9qaeRERkHAw3RGU091Rg/tAWmNyzkc7zS19spfF61m/nkZpdgN8i76DZx/tw5Op9/N83xzDl10icj08zQo2JiOhxnC1FpMP0Pn5IyynAxtPx6mMz+vihjbeDRrlCpYCXVp7ArZQcFChVGLf6tPrchbvpaP1YeSIiMjy23BDpYCezQOgLreAut1Ifeyc4AM52Mq2yV5OyYG+l/f8JeWWmjxMRkfGw5YaoAo/PhnIoZ6+rBzpWLf7x6A3cSMlGG28FRnUsXjSwoKh4XR2pBf+/gojIUBhuiCrgYi9DQnoezB8NMDYzk6BzQyecupn6xGuTM/Ox8XQcNp4Gwi4m49/kTDzMKYSXozV+n9oVVpbmhq4+EVGdxP99JKrA96+0R6eGTvh9alf1sXX/6YTvxrSDh8Kqgis17b+UhFsPcpCeW4jYexnYE5NgiOoSEREAiVAyf7WOyMjIgEKhQHp6OuRyudjVoVosJSsflxMysXj3JVxMyKjSte8ODICDtRRJGXl4sb0X5NaWUJTT5UVERFX7/mbLDVE11bOTobt/PbzSxUfrnPkT1slJyynEB9uisSz8Gnp8dhADvzpiqGoSEdU5HHND9JRGdfRGKy8FnGyl6LrkAADAx8kGN1Kyy71m5ZEbGq8T0vOgUgkwq+TigUREVD623BA9JXMzCVrUV8DTwVp9zLeebZXv80fUXcSn5iAtpwCCIOB+Zj7K6zXOK1Ri8LKjCNkUVe16ExGZKrbcEOlRD/96OHotBe8MCEDXxs5Y+NelSl/7ztbzAIq7u55t7YE1/9zCyA5eWPJCK60WnYsJGeqf8V190baBo14/BxFRbcYBxUR6VFCkQmp2AdwfzaTyff8vAMWBpbo7iNtKzbHw+RZ4vq0XAODHIzewaHdpaPrk2WaY2K1hudcLggCJhN1dRFS7cUAxkUikFmbqYAMA341ph76Brtj9RnesndgRi59vWeV7Zhco8ebm8ygoUiEhPVcj2ADA3TKbdz5u7T830WHhflxOrNpsLiKi2ozhhsiABrf0wOoJHeEqt0LvAFe83LlBte814ocTOHj5vtbxOxWEm7l/XsSD7AJ8uC2m2u9LRFTbMNwQGdnOGd2qdd35+DSci3+odfzWg2xExT3EmVvlr5occfshPt17GRfvZUClqlM90URUB3HMDZEIkjLyMH/XRfQLdEWXRs6IikvDJztjkJKlvUdVVWx6rQs6N3RSj7EpGfNT1uCW7vj25XYch0NEtQrH3BDVcG5yK3z7cju80M4Lng7WGNLKAxEfPoP+TV3VZab3aVzl+7608iQOXbmP/CIlMvMKdZbZHZ2I9afiAABKtuIQkQniVHCiGuSljg1wNi4NH/1fU7TycsC3B69rlZncoyHGBfli5/l72B51F9eSszTOT1x7Bs62UjzMKb8VaOm+K/B1tsUrP50CABx6p3e11uYhIqqJ2HJDVIP0b+aGyA/74/m2XvBUWGud7xPggjlDmsHbyQbT+/hpzMwq60F2ASpqlClUqjBj41n162nrz+osl1eoxPaou3hQzWnsRERiYLghqmFKxsJYS81R38Ea5mYSbJvWFW8/0wTfjmlX7nXD2nhW+j0KilTIyitSv76YkIFdF+7hblouXll1ChPXnIYgCPji7ysI2XwOk3+OqP4HIiIyMnZLEdVg4W/3Ql6hEg420ieuQhzgLgdwT+u4q70Mn77YChPXnFEfK9LRrDNjg+ZWDg+yC7DpdDwA4Gxcmsa5UzceYNHuS1gwtAVaezuoj6tUAlYdu4H2Pk5o7/PkVZNj7qZj/q6LeH9QINpxlWUi0hO23BDVYFaW5nCwkZZ7vuxcRzuZuc4yRSoBfQJcsTekR5Xe+15aLnIKlTrPfbIzFhfupGPot/9oHP/zwj0s3n0Zw1ccr9R7jF99GqdvpmLE9yeqVDciooow3BDVYqoy6UZqofuPc2GRCgDgWEFI0mX/xaRyZ1OZl9nr6sb90gHNF+9proR8Nu4hQjZFISkjT+d9HmQXD3quzKwtQRA49oeIKoXdUkS1mMLaUv27rq4mAChQFocbN7kV/jeqNW7cz8Y3B/4FAHwwOBBZeUX4+tHrsnQdK2EnK/2ro+8Xh9G/qRtc5TLkFZS29JTdAyu3UIkfxnao8LM8zC7Ah9tjMLKjN3o1cdE6/8nOWPx84jY2Tu6CoMbOFd6LiOo2hhuiWuyDwU1x60EOJnbzRV6ZLqSwN3si/HIyluy5jM9HtFYfL9l8s0sjZ0TceohXuzeCmZmkwiBT1rWkTExYcwZ30zS3fNh/KUmrbNk9sP59NF09M68QR6+loG+gK6wsNbvR2i4IAwD8FZ2Am6GD8e3Bf9HcU4E+gcVr//x84jYA4H9hVxHUOKhS9SWiuonhhqgW83aywZ6ZxWNpriVlAgAszSXwd7OHv5s9RnbwhpOtdndUN7966OZXT/16bBcf/HLydoXvNf/Pi1j9z81q1VNmYQ6VSsC09Wdx9FoK3OQydG1cr9zyfnP2qLuqlr7YSmP/LDsrzb+2lCoB4ZeS0M7HEfXsZNWqHxGZFm6/QGRCLt7LgKtcVuUveUEQMGldBA5cTgZQPK18+7l7mD+0OT7eEVvudV+Pbos3NkaVe74sbydrxKeWv8lnZQ1t44llL7VVv1519AYW/nUJPs42ODyrz1Pfn4hqpqp8f7PlhsiENPOsXmCXSCRY8kJLzNt1EWO7+KCZpxxjuvigo68Tdl1IwOmbujflbFSFVY31EWwAwLzMnlgJ6blY+Fdx99ftBzkVXjdr63mci0/DtundNMYMEZHp4Z9wIgIAuD7a76pER18nAMC3L7fD679EaK1188mzzcpdIdmQ0nMLcS4+DQt2XVR3xVUkv0iJjafisDXyDgDg6NX7GNTSw9DVJCIRMdwQUYVc7GVY/2oXTFhzGs085ZjauzEycovg52qHwkczsco6+E5vTF9/FhcTMnTc7emFX05GWm4hIm8/1Do3euVJFCpV+Gl8RyhsimeSvbXlPP66kKAuUzL9/Emy84vw+i+ReKaZG8Z39dVL3YnIODjmhoieiu/7f2m8vrVkCADg+8PXkZVXhEYutnhry/kn3kduZYGMMltCPA2phRmea+2J+g7WWBZ+TeOcq70MZhIJvh/bHm3KrK78uJKxPEDpZ9JFEAScufUQTdzsKlxwUZ8EQVBv00FUV1Tl+5uL+BGR3nw9unSg75RejfFOcIDONWtKONhYYv7Q5pBIgO/GtEdjF/3sTF5QpMJvkXe0gg0AJGfmIzEjD8O+/QdDvj6KlHIWBsysZNDafykZI384geeW/4OcgiKNKfmGsHTfZXRaHI741IrHGBHVZQw3RPRUfhjbHlN6Nca/iwbhudbam3fqmooOAPOea47db/TA2C4+uLZwELr718OaCZ3U5wPd7bWu6Rvoij9ndNdb3WPvZWDNY9Pbf4u8g35fHMLx6ynqYxUFlr0xiQCAuNQc9Fp6CD0+OwhVJVZcrq5vD17H/cx8fLAt2mDvQVTbMdwQ0VMJbu6O9wcFwsJc918nEokEL3duAFd7zenpozs1gKeDNSQSifpaD4fSAcrNPRVa90rNLkBLLwX2hfTUW/2/PXgdnRfvx/F/U6BSCXhn63lcv5+NM7dKx/T8evI2tkTEa117OTEDD3NKx/Dcz8zH/cx8bDgdp7NlZXd0An48ckMv9Y56bIA3EZViuCEig1v8fEuc+qAfIj7srz6may8sS3Mz7A3pgT9ndIe9lfZ8h5IupAB3e3w6vGWV62FWzjCVpIx8vLzqFLafu6vz/MK/LuHd3y4gNbtA3eUVczcdA786ql4bqKwPt8egx2cHkVtmO4qSRQwX7b6Eq49meRUpVcgpKMKf5++pW4cEQUBBkfZA7cdl5RfpHFRNRJwtRURGIpFIUM9OhiOz+sC2nB3MASDQvXig4OaIOK1zZdenGdWxAU7dTMUfZ3UHksdtmNwZ7/52QWO148c9aeDzjftZeLEKO5ifvPEAfQJdoVQJSEgvfd/MvCIs3HURq47dhIfCCgnpeejhXw+/TOqMV9dFIPpuOg680xt2MgucuvEA0XfTMal7Q61BxMNXHK9wsDNRXcWWGyIyqgbONnCuxArKZWeZ/zKpE1p5KTT2yQKApS+21mgNKs/A5u7o2rgefJxtqlzfshbsulil8j8cuY5P915Gi0/2YUvEHfXxnIIirDpWPNYnIb14x/Sj14q7xcIvJyM5Mx/Hrt0HAIxaeRIL/7qEsItJ0DW59cb9LHx78F9cTjTM1Hui2ojhhohqpGdbFS+019jFFj38XbBzRne0qK85DsfcTKK11cT26d207lWy0WcDp6qFG/ljXWPn76RX6fqTN1Kx4tB15BYq8XWZmVvlzcQ68ijQAIC5meZfzzvO3cPZOO1uqL5fHMbSfVcw8KujVaobkSljuCGiGqmrXz3s+m93nWHlcR8Oaar+3dlWqjVDy/rRDuQlXV66vNm/icbrbn7O2Px6EKTlDJR+Gg/KmX6+JzpR/XvRYwsk/hWdgOErKu4SUxpwlhZRbcJwQ0Q1Vov6CthbWT6x3LggXwDFO6K7ymU48HYv/P1mT/z8n05o4+2Auc81BwC80K4+vJ2sdd5jSCsP7A3pge9faY+boYOx/tUuaOohR+z8YK2yP43vUP0PBeBGSrbO41eTS7eTyMgrxLaoOzrLlefxrild3VhKlYD8Iu2p7anZBfg7NlErVIkpr1BZo+pDtQdXKCYik3A/Mx9KlfDE/a7yCpUI/Giv1vFTH/SDm1z3tWVXYR7S0gPvBAegz+eHKnyfoEbOWP9qZ2yLuou3tz55hWZ96d/UFZ+PaI0vw67i4JVk7JzeHQ42lvgrOgGB7nL8d2MULiVkYOeMbmjl5aC+Lvh/R3AlKRPznmteI7abyC1Qov3CMHg72mDfm/qb+k+1F3cFJ6I6x8X+yYOUAcDKUnumVsN6tnCpxCBnAPhiZGvkl5mqHeBmD1e5DMkZ+bhSZiPPHk3qwcxMgjYNHCp1X33ZfykZv568jZ9P3AYAvPpzBLo0csK3B69rlHtu+T+4GTpYPQOrpO57YhIQl5qD+5n5+OzFVrCyNMfhq/dx434WJnZrqJc6Vmb7iPN30pBToMSVpExuN0FVxnBDRHXOb1OC8Fd0At56pgkszc0gNTeDWXmL4ABY9lIbvLXlPL4c2RpWluawsjTHuCAfZOUVYfELLWFlaY7kzDz8cuI2ujauh2vJmRjV0RsA0NjFDivHtsdrv0Rq3XftxI6YsOaM3j9fUkbpmJ7I2w/LXQ8nt1AJG6mFxorKJ2+k4uSNVADAzvP3sGFyZ4xffRpA8fpCXRvXe6q6zdwUhWtJWdg+vZvOtY5KlK1TfpFKZyglKg/DDRHVOR18ndDB16nS5Ye2qY/g5u4aX7Dzh7bQKONqb4W3BwQAAIIaO2ucG9DcXed9A93l6NrYGcevP6h0XSpjs47VlHXp98VhjO/qi0EtdNcPAF7+8ZT690sJmXC2lcHR1hKu9rq78ARBQFpOIRzLDOreGhGPPy8k4MjV0tlgEbdS0dWv/KBUVCbc5BUqGW6oSjigmIioEp72y/XgO72xalwH9CyzkairvQzrX+2MqwsHoW+gKwBgRh8/9fkOPo7q35u42VX6vSqzwjFQvMbOkj2XsetCQqXKL9h1EcFfHcErq05pDFa+/SAbvZYexMoj1/HdoetouyAMf8cWz/y6lpSJWb9d0Ag2AFDexK57abnIL1Jq7OeVq+fNSGdtPY/JP0c89eyyVUdvYM62aJ0DtwEg8nbxUgCG3GuMdGPLDRGRETSsZ4uG9WwhtTDDvbRc/F8rD3VXmNRCgtUTOgIongK+LzYR+UUqrP1PJ3x38F/0CXTF0WspuJqkvcu5Pizdd6VK5a8mZaHT4nAcntUbf8cmIWTzOQDA4t2X1WXe+/0CBjR3x7n4NJ33eGfreYwN8sH0MmHufHwahn77DwY2d0dwCzf18bzC4rAmCAL+F3YVV5Oy8N6gQDSsV/Vd5AuVKmyNLJ6Fdvx6Cvxc7fDW5vOY2M233BY2XQRBwMK/LgEAnmvtic6NnLXKlEzdd7WXYXh7ryrXlapP1Jab0NBQdOzYEfb29nB1dcWwYcNw5cqT/5Bt3boVgYGBsLKyQsuWLbF7924j1JaI6On1bOKC/W/1Qshj6+qUsDA3w5//7Y6/3+wJO5kF3h0YiI6+TqjvoLsbyNlWih3Tu0FqboYgHV+whnI/Mx/zdl5UB5vHlWyGGnNX98KHiRl5WLrvikbryad7i8PR3thEZJVZ6HDGhrO4nJiBs3EP8fWBf7E3NvGJs9XKk1Nmv6+ouDS8/3s0Ttx4oHNMVEXScwvVvz/ILqigJDQGmutDzN103HmovTErlRI13Bw+fBjTp0/HyZMnERYWhsLCQgwYMADZ2brXgACA48ePY/To0Zg0aRKioqIwbNgwDBs2DDExMUasORGR4ZQMWi7LTqZ7vZ+fJ3VCa28HXJg7AO8NCtRbHWYFBzyxzONje8ru/XU/Mx9jfzqFdY9mbZXnXlouBEHAh9ujNcYeZeWXhpDYexkY+NVRHLtW+bFJKpWAP87eQdjFJJy5lao+XnYz04c5BbiYULVtK07deICIW6nqQdYAkJRRvIVGfGoOTt9M1bqmou6vP87ewaS1Z5CVr3vV6sfFp+bg/745hu6fHqxSvesaUbul9u7VXGti7dq1cHV1RWRkJHr21L2uwbJlyzBw4EDMmjULALBgwQKEhYVh+fLl+P777w1eZyIiMbTzcQAASCRAyRCP0Bdaorln8ZYUVpbm8HO1g6W5BIXKqo/xaOBkg7jU4taAYW080dTDXn2uvoO1eguLijz+BX30WsoTr4lLzcGVxEz8elJzo1RdM7zCLydpvB66/Bh6NXHBWwO0g9j2c3c1NkI9M6c/XOxlyCkoreOxaym4n6l7tWhdkjPzMGrlSa3jtx8UP7fnvzuOlKx8/D41CO19SgesVxRuSuoYsikKuYVKvDcwUGP9ocfF3qvaFiDVUahUYd3xW+jh74IAd3udZZIz8zB65UmM7OCN13s1NnidqqpGDShOTy/+l+bkVP4shhMnTqB/f82N8oKDg3HiROV36iUiqm08FNYIe7MnTs7upz7m76o5yNhOZoFTH/TH71O7wsJMgmdbe2Leo9WZn+TLkaWbkno72cDLsXQfrn/e74t+jwY869sbG6Pw6s8RWsf3X0rSOpaWU6jx+vyddHx94F/cuJ+lPvZvchZm/xGNrRGaqzuXtBCV7Za6lpylUUYQBOyJTsC1pExk5hViy5l4xNxNx4ZTcShUqnC3nB3lS1qGUh5tq7HhVLzGIOLsMqHv4JVkfB1+TWsQ8v5Lyfjn3wcYU2Z2mi5lc1LJewiCgORHrUdVEX4pCaduaLeGrTt+Cwv/uoTgr46Ue+33h27g+v1shO65XG4ZMdWYAcUqlQohISHo1q0bWrRoUW65xMREuLm5aRxzc3NDYmKizvL5+fnIzy9N5hkZ3DmXiGonf7fi/4veOaMbbqZk65zO7vRob62oj5+BncwCEokEaTmF+N/+qxXeu5ln6YqvNlILNHGzx/evtIfno7E+rwT5IPxycrXqPaGrL9Yev6Xz3JPGq5SVVM4XeMjmc+gb6IpBLTwwbX0krt/XHtow9Nt/0C/QtcJWhmXh1/DV/msIdLeHj7MN9sWWBqwPtkVj2UttdF4Xey8DK4+ULpL4+9k7yCuzxcXWyDto6aXAwBbumPhoXaMe/vXQtoGj1r0yK+ieKlKqMH3DWfXrvKLidYoW/XUJq47dxDej22JAczfILMqf2RdzNx0Rt1IxoLk7Jq0rDpWH3umN6/ez0K9p8XdrVFxaudeXKFDqdwabvtWYcDN9+nTExMTg2LFjer1vaGgo5s2bp9d7EhGJqZWXQ4VdFwA09uSa2d8fozt545OdsdgTU/o/gi+0rY8/ou4CKA40s4IDsC3qLoa3rw8AGFhm/Zuy42m+Ht0WTdzsKr0T+bOtPXWGm0B3e1xOrPxg2/xyprhfuJOOC3fS8dX+imeThV9OrjCg/f0ozFxOzNRZr5mbzpV7bdmZYgDw12PT6z/eEQtn29JVsDPzisqdsr87OgHBzd1h/tjCkrsuJKBsg09OgRIX72Vg1bGbAID/boyChZkEb/Tzxxv9/HXe+/++Kf6OvVlmf7P/++YYsvKL8NP4DsUBpxKLQVuY1aiOHy01onYzZszArl27cPDgQXh5VTxdzt3dHUlJms2VSUlJcHfXPYVv9uzZSE9PV//Ex1ducSsiIlPiKrfCilfa46fxHeBoY4nVEzpg9uCmGNDMDWsnFk9Dn97HD/vf6qVzgb6yu6P3auKCQHc5Tszuq/O9Xu3eEPUdSjcobe/jiJ//0wmNXDSnbpdtLdLFwebJm6bqk62samsZTe1dtbEmqdmlvQjjVp9Gkw/36Cw3bf1ZbDpTOgZJEAQsP3BNa2baor8u4cXvNYdkFKkEfBlWcSsdAESXmcVWMlZqw6k4nZuq6mJpXpqACmvg5qaittwIgoD//ve/2LZtGw4dOoSGDZ+8b0lQUBDCw8MREhKiPhYWFoagoCCd5WUyGWSyyu0ZQ0Rk6vo1dcPZj55R79W0clzldjgv24pgKy0OAR6K0gDTzEOOv97ojlsPcuDrbIM3n2mCRbsv4fm2xa1APZu4YOvrQej9+SFk5hVhwdDmGttE6LJ9Wjd8EXYVf56/V6XPWF2Pj+l5ErmOHetlFmawsjTXmCoOAB4Kqyp1we2NScSYzj7YeDoOX4Zd1TnwedujVrfqKDv2qET45WQEfLi3wm0xSpiXabnJyC2EcyX3ZjMWUVtupk+fjl9//RUbNmyAvb09EhMTkZiYiNzc0kFb48aNw+zZs9WvZ86cib179+KLL77A5cuXMXfuXERERGDGjBlifAQiolqnOptQNvWQI6iRM4a18VSvYQMAbvLiL7X+TV0hkUjQsJ4tJBIJbGUWWPx8S3QsMy7I2U6G6LnBuDg/GGODfOFRzto9FmYSvN6zEXzr2eKb0W0R9dEz+OzFVjrL/jiuAw7P6l3lz6PL/azKz5wCALm1dvuAtdRc5/GE9LwndpuVVfRoxtt3h/6t0oyuyqqoO7Bsd9mm03F4mF2A2X9cwN4yXZplV5BOyy2EIAhYfewmIm5pT4UXg6gtNytWrAAA9O7dW+P4mjVrMGHCBABAXFwczMokxK5du2LDhg348MMP8cEHH8Df3x/bt2+vcBAyERE9HXMzCTa+1kXr+LZp3XDk6n08365+pe9lIy3+6mmtY9zQuv90QtsGDrAvM8bH0VYKP1fd208806x4EGzvABccunJf67ybXPbEFqIS5bXcNPWQ45KO9XCcbKRax9JyCuHlaI14PHnqfEWuJWfhzK1U3ClnhlZ1VKf76P0/ovH+H9EAgI2n4/F6z0YY2dFbYwbY8X9TkJSRh/m7LgIAri4cVKnWH0MSvVvqSQ4dOqR1bMSIERgxYoQBakRERFXh6WCNlzo1qNa1LeorMLydF34/Wzxte3KPhuhVZu+tspzLbMRpIzXX6lZZ/HxLDF9xHAnpeZjepzG+PVg8e+m7Me3w2s+RVeoSepyfq53OcNOjnLqW7a6q7BpBj0vJyseoH06gEl+TOp25lYo3NkahuacCnRo6YnBLD0z99eyTL3yCH47cwMErybiaVDqN/qMdsXAq8+/n9M1UdPd/ut3jn1aNmS1FRER1z9znmqnDTRM33QvGAdAY5OztaKO1pYGngzVOPFoDSKUSYGluhjbeDmjv44TIj57B1aRMDPhf8botL7b3wm+RmuvgVKSBk7XWMStLM40ZZGVZl1ld2reeTbXCDVD+5qKVMeLRQOOE9Dzsv5SkNZvraZQNNiVSy4THmw+yGW6IiKjuspWWfg35OJe/Eaa11Bz73+oJM4kE7/1+ocJ7mplJtPbuqig4PYmng3a42ThZu4uusYstXunigxtl1tnxVGhfa+o+2h4DFzspBrbwEK0ODDdERCQaMzMJxnRugPuZ+Wjvo72oXVl+rsUBxVr6dF9dzzRzQ+eGTvj87yuVGo/j52KHv9/siYT0PPRq4gJBENSDslt7O+B8fBqea+2Jr0e3BVDccvTLyeI9tcpbm+dxU3o1xveHrz+5IIp3IT918wEmdmuIJXpaIdjRxhJzn2te4Vo+VbHz/D1Rw02NWOeGiIjqrkXPt8TKcR20Fq0rz3sDAyCRAK/1bFSl9wl/uxf+N6o1BjRzw4gO3tj0WvESIsPbeeHk7H7o1cQF7wzQ3q29sasdmrjZq8cDlZ1t9tP4DlgwtDkWPl86qcWszOewsjRD33K2rnh/UCD6N3XFp8Nb4v3HNj0d0MxN5zUAML6rL0590B+vdPFRH3OXW5W72emRWX3g5VhxC1KfAFcMbaM9KNzeqnpBMtC94jWMDI0tN0REVKs091Qgdl6wxtiWymjsYofGLqWzrhrWs8Wl+QNhZWkGiUSCdf/pBKB4wcPIWw+RlV8EubUF6lWwhks9OxnGBvlqHf9seCusO3ELb/Tzh9zaEq3m/q1VZnKPRphSZjuIkoHSfQJc8MXI1vj1ZByea+OJbksO6HxvmzKff/PrXeDjbIul+65olGlRX44GzjY49l5fbD4Th/d+j9Y4/1rPRkjKyMMn5exBNu+55hobkD6uo68jztx6iI6+jvhmdDt0CQ0HAI1FHMXAcENERLWOzVN2TZWwlmoHpJEdvDGyg/dT3XdkR2+M7Kh9D2tLcwQ3d8PLnX20Wqq2vB6Edcdv4Z3gANhbWepcAbmDjyNaexXvBG9mJsHKse2RU6Asd7xS2dlWI9oXb8GRV1jaVfZie69yxyNtnRKEjr5O8HG2gaONFLcf5MDH2QZ9vzisLvPlyDY4dCUZg1p6oJ6dDENaeeDs7Yfo19QwG61WFsMNERGRkTjbSfHVS211nmtRX4GlI1rrPFfit6ldNV4PaK659dB3Y9rhzsMc9eyosuHGzEyCqI8G4JsD1/DdoeLxPe4K3Qsp9g5wUS/A2N6n+J+NHrV6/bevH7458C+A4pWXy7ZcfftyuwrrbywMN0REREZiUclxRdU1uGXxIN7ypn5bS83x7sBAPN+2PvKLVFpbSHz/Sjv8ePQmFgwtf2FcN3lpICq7WnVNUjNrRUREZEJe71U8+Pmj/2tW5Wtf6dIAUgsz/FjJfcDKKm8zUH83e7Sor9A6PrCFB36f2hXeTjbl3rNsuKmpJEJllgk2IRkZGVAoFEhPT4dcLu5obiIiqhsEQUB6biEcdGzZUJlrM/OLdG7UWZ7fIu/gmwPXsGpcB/g/xRo/uqhUApb+fQWtvRRGne5dle9vhhsiIiKq8ary/c1uKSIiIjIpDDdERERkUhhuiIiIyKQw3BAREZFJYbghIiIik8JwQ0RERCaF4YaIiIhMCsMNERERmRSGGyIiIjIpDDdERERkUhhuiIiIyKQw3BAREZFJYbghIiIik8JwQ0RERCbFQuwKGJsgCACKt04nIiKi2qHke7vke7widS7cZGZmAgC8vb1FrgkRERFVVWZmJhQKRYVlJEJlIpAJUalUuHfvHuzt7SGRSPR674yMDHh7eyM+Ph5yuVyv96ZSfM7GwedsPHzWxsHnbByGes6CICAzMxOenp4wM6t4VE2da7kxMzODl5eXQd9DLpfzD44R8DkbB5+z8fBZGwefs3EY4jk/qcWmBAcUExERkUlhuCEiIiKTwnCjRzKZDJ988glkMpnYVTFpfM7GwedsPHzWxsHnbBw14TnXuQHFREREZNrYckNEREQmheGGiIiITArDDREREZkUhhsiIiIyKQw3evLtt9/C19cXVlZW6Ny5M06fPi12lWqV0NBQdOzYEfb29nB1dcWwYcNw5coVjTJ5eXmYPn06nJ2dYWdnh+HDhyMpKUmjTFxcHIYMGQIbGxu4urpi1qxZKCoqMuZHqVWWLFkCiUSCkJAQ9TE+Z/24e/cuXnnlFTg7O8Pa2hotW7ZERESE+rwgCPj444/h4eEBa2tr9O/fH9euXdO4R2pqKsaMGQO5XA4HBwdMmjQJWVlZxv4oNZpSqcRHH32Ehg0bwtraGo0bN8aCBQs09h/is666I0eO4Nlnn4WnpyckEgm2b9+ucV5fz/TChQvo0aMHrKys4O3tjc8++0w/H0Cgp7Zp0yZBKpUKq1evFmJjY4XJkycLDg4OQlJSkthVqzWCg4OFNWvWCDExMcK5c+eEwYMHCw0aNBCysrLUZaZMmSJ4e3sL4eHhQkREhNClSxeha9eu6vNFRUVCixYthP79+wtRUVHC7t27hXr16gmzZ88W4yPVeKdPnxZ8fX2FVq1aCTNnzlQf53N+eqmpqYKPj48wYcIE4dSpU8KNGzeEffv2Cf/++6+6zJIlSwSFQiFs375dOH/+vPDcc88JDRs2FHJzc9VlBg4cKLRu3Vo4efKkcPToUcHPz08YPXq0GB+pxlq0aJHg7Ows7Nq1S7h586awdetWwc7OTli2bJm6DJ911e3evVuYM2eO8McffwgAhG3btmmc18czTU9PF9zc3IQxY8YIMTExwsaNGwVra2vhhx9+eOr6M9zoQadOnYTp06erXyuVSsHT01MIDQ0VsVa1W3JysgBAOHz4sCAIgpCWliZYWloKW7duVZe5dOmSAEA4ceKEIAjFfxjNzMyExMREdZkVK1YIcrlcyM/PN+4HqOEyMzMFf39/ISwsTOjVq5c63PA568d7770ndO/evdzzKpVKcHd3F5YuXao+lpaWJshkMmHjxo2CIAjCxYsXBQDCmTNn1GX27NkjSCQS4e7du4arfC0zZMgQ4T//+Y/GsRdeeEEYM2aMIAh81vrweLjR1zP97rvvBEdHR42/N9577z0hICDgqevMbqmnVFBQgMjISPTv3199zMzMDP3798eJEydErFntlp6eDgBwcnICAERGRqKwsFDjOQcGBqJBgwbq53zixAm0bNkSbm5u6jLBwcHIyMhAbGysEWtf802fPh1DhgzReJ4An7O+7Ny5Ex06dMCIESPg6uqKtm3b4scff1Sfv3nzJhITEzWes0KhQOfOnTWes4ODAzp06KAu079/f5iZmeHUqVPG+zA1XNeuXREeHo6rV68CAM6fP49jx45h0KBBAPisDUFfz/TEiRPo2bMnpFKpukxwcDCuXLmChw8fPlUd69zGmfqWkpICpVKp8Rc9ALi5ueHy5csi1ap2U6lUCAkJQbdu3dCiRQsAQGJiIqRSKRwcHDTKurm5ITExUV1G17+HknNUbNOmTTh79izOnDmjdY7PWT9u3LiBFStW4K233sIHH3yAM2fO4I033oBUKsX48ePVz0nXcyz7nF1dXTXOW1hYwMnJic+5jPfffx8ZGRkIDAyEubk5lEolFi1ahDFjxgAAn7UB6OuZJiYmomHDhlr3KDnn6OhY7Toy3FCNM336dMTExODYsWNiV8XkxMfHY+bMmQgLC4OVlZXY1TFZKpUKHTp0wOLFiwEAbdu2RUxMDL7//nuMHz9e5NqZli1btmD9+vXYsGEDmjdvjnPnziEkJASenp581nUYu6WeUr169WBubq41myQpKQnu7u4i1ar2mjFjBnbt2oWDBw/Cy8tLfdzd3R0FBQVIS0vTKF/2Obu7u+v891Byjoq7nZKTk9GuXTtYWFjAwsIChw8fxtdffw0LCwu4ubnxOeuBh4cHmjVrpnGsadOmiIuLA1D6nCr6e8Pd3R3Jycka54uKipCamsrnXMasWbPw/vvv46WXXkLLli0xduxYvPnmmwgNDQXAZ20I+nqmhvy7hOHmKUmlUrRv3x7h4eHqYyqVCuHh4QgKChKxZrWLIAiYMWMGtm3bhgMHDmg1VbZv3x6WlpYaz/nKlSuIi4tTP+egoCBER0dr/IEKCwuDXC7X+qKpq/r164fo6GicO3dO/dOhQweMGTNG/Tuf89Pr1q2b1lIGV69ehY+PDwCgYcOGcHd313jOGRkZOHXqlMZzTktLQ2RkpLrMgQMHoFKp0LlzZyN8itohJycHZmaaX2Xm5uZQqVQA+KwNQV/PNCgoCEeOHEFhYaG6TFhYGAICAp6qSwoAp4Lrw6ZNmwSZTCasXbtWuHjxovDaa68JDg4OGrNJqGJTp04VFAqFcOjQISEhIUH9k5OToy4zZcoUoUGDBsKBAweEiIgIISgoSAgKClKfL5miPGDAAOHcuXPC3r17BRcXF05RfoKys6UEgc9ZH06fPi1YWFgIixYtEq5duyasX79esLGxEX799Vd1mSVLlggODg7Cjh07hAsXLghDhw7VOZW2bdu2wqlTp4Rjx44J/v7+dXp6si7jx48X6tevr54K/scffwj16tUT3n33XXUZPuuqy8zMFKKiooSoqCgBgPDll18KUVFRwu3btwVB0M8zTUtLE9zc3ISxY8cKMTExwqZNmwQbGxtOBa9JvvnmG6FBgwaCVCoVOnXqJJw8eVLsKtUqAHT+rFmzRl0mNzdXmDZtmuDo6CjY2NgIzz//vJCQkKBxn1u3bgmDBg0SrK2thXr16glvv/22UFhYaORPU7s8Hm74nPXjzz//FFq0aCHIZDIhMDBQWLlypcZ5lUolfPTRR4Kbm5sgk8mEfv36CVeuXNEo8+DBA2H06NGCnZ2dIJfLhYkTJwqZmZnG/Bg1XkZGhjBz5kyhQYMGgpWVldCoUSNhzpw5GtOL+ayr7uDBgzr/Th4/frwgCPp7pufPnxe6d+8uyGQyoX79+sKSJUv0Un+JIJRZxpGIiIioluOYGyIiIjIpDDdERERkUhhuiIiIyKQw3BAREZFJYbghIiIik8JwQ0RERCaF4YaIiIhMCsMNEdU5vr6++Oqrr8SuBhEZCMMNERnUhAkTMGzYMABA7969ERISYrT3Xrt2LRwcHLSOnzlzBq+99prR6kFExmUhdgWIiKqqoKAAUqm02te7uLjosTZEVNOw5YaIjGLChAk4fPgwli1bBolEAolEglu3bgEAYmJiMGjQINjZ2cHNzQ1jx45FSkqK+trevXtjxowZCAkJQb169RAcHAwA+PLLL9GyZUvY2trC29sb06ZNQ1ZWFgDg0KFDmDhxItLT09XvN3fuXADa3VJxcXEYOnQo7OzsIJfLMXLkSCQlJanPz507F23atMEvv/wCX19fKBQKvPTSS8jMzDTsQyOiamG4ISKjWLZsGYKCgjB58mQkJCQgISEB3t7eSEtLQ9++fdG2bVtERERg7969SEpKwsiRIzWuX7duHaRSKf755x98//33AAAzMzN8/fXXiI2Nxbp163DgwAG8++67AICuXbviq6++glwuV7/fO++8o1UvlUqFoUOHIjU1FYcPH0ZYWBhu3LiBUaNGaZS7fv06tm/fjl27dmHXrl04fPgwlixZYqCnRURPg91SRGQUCoUCUqkUNjY2cHd3Vx9fvnw52rZti8WLF6uPrV69Gt7e3rh69SqaNGkCAPD398dnn32mcc+y43d8fX2xcOFCTJkyBd999x2kUikUCgUkEonG+z0uPDwc0dHRuHnzJry9vQEAP//8M5o3b44zZ86gY8eOAIpD0Nq1a2Fvbw8AGDt2LMLDw7Fo0aKnezBEpHdsuSEiUZ0/fx4HDx6EnZ2d+icwMBBAcWtJifbt22tdu3//fvTr1w/169eHvb09xo4diwcPHiAnJ6fS73/p0iV4e3urgw0ANGvWDA4ODrh06ZL6mK+vrzrYAICHhweSk5Or9FmJyDjYckNEosrKysKzzz6LTz/9VOuch4eH+ndbW1uNc7du3cL//d//YerUqVi0aBGcnJxw7NgxTJo0CQUFBbCxsdFrPS0tLTVeSyQSqFQqvb4HEekHww0RGY1UKoVSqdQ41q5dO/z+++/w9fWFhUXl/0qKjIyESqXCF198ATOz4kboLVu2PPH9Hte0aVPEx8cjPj5e3Xpz8eJFpKWloVmzZpWuDxHVHOyWIiKj8fX1xalTp3Dr1i2kpKRApVJh+vTpSE1NxejRo3HmzBlcv34d+/btw8SJEysMJn5+figsLMQ333yDGzdu4JdfflEPNC77fllZWQgPD0dKSorO7qr+/fujZcuWGDNmDM6ePYvTp09j3Lhx6NWrFzp06KD3Z0BEhsdwQ0RG884778Dc3BzNmjWDi4sL4uLi4OnpiX/++QdKpRIDBgxAy5YtERISAgcHB3WLjC6tW7fGl19+iU8//RQtWrTA+vXrERoaqlGma9eumDJlCkaNGgUXFxetAclAcffSjh074OjoiJ49e6J///5o1KgRNm/erPfPT0TGIREEQRC7EkRERET6wpYbIiIiMikMN0RERGRSGG6IiIjIpDDcEBERkUlhuCEiIiKTwnBDREREJoXhhoiIiEwKww0RERGZFIYbIiIiMikMN0RERGRSGG6IiIjIpDDcEBERkUn5f18ynrWtXSDyAAAAAElFTkSuQmCC\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OAdaPBuMQmrl"
      },
      "source": [
        "---\n",
        "### Answer:\n",
        "\n",
        "Loss Curve Analysis: Impact of Multi-Head Attention on Model Performance\n",
        "The plot above shows the training loss curve of a model over 1000 iterations. The loss starts above 4.0, decreases sharply in the early iterations, and then gradually converges towards 2.0.\n",
        "\n",
        "Previously, when using a single-headed attention mechanism, the loss had converged around 2.3. However, after switching to a multi-headed attention mechanism, the loss further reduced to approximately 2.0, indicating an improvement in the model's learning capacity.\n",
        "\n",
        "The following are the key observations:\n",
        "\n",
        "1. Lower Final Loss: The model with multi-head attention reaches a lower loss than the single-headed version, suggesting improved expressiveness and generalization.\n",
        "\n",
        "2. Smooth & Stable Convergence: The curve shows a relatively stable and smooth descent, meaning the model is effectively optimizing without encountering significant instability.\n",
        "\n",
        "3. Effectiveness of Multi-Head Attention: Multi-head attention allows the model to capture multiple perspectives of the input by attending to different parts of the sequence in parallelly, which can enable better learning and thus reduce the loss.\n",
        "\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.to('cpu')\n",
        "torch.cuda.empty_cache()"
      ],
      "metadata": {
        "id": "yyt0Nahl7Ofo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X9XsUWpwG7uA"
      },
      "source": [
        "### 1.4: The Transformer Architecture: combining attention with deep learning"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "1GbGqwKWJzOK"
      },
      "outputs": [],
      "source": [
        "# run this cell to initialize this deep learning module that you should use in the code your write later\n",
        "# you don't need to edit this layer\n",
        "class FeedForward(nn.Module):\n",
        "    \"\"\" a simple linear layer followed by a non-linearity\n",
        "        Given to you, you don't need to write any code here!\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, embed_size):\n",
        "        super().__init__()\n",
        "        self.net = nn.Sequential(\n",
        "            nn.Linear(embed_size, 4 * embed_size),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(4 * embed_size, embed_size),\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.net(x)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WKJxVp6aJb6i"
      },
      "source": [
        "#### Question 1.4.1: Implement a transformer block\n",
        "\n",
        "Complete the code below to implement a transformer block"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8Jw2I6a8IYOi"
      },
      "source": [
        "To make the your implemenation easier to train, we have added two deep learning best practices:\n",
        "\n",
        "1. Residual connections.\n",
        "\n",
        "    In the `forward` method of the `TransformerBlock`, we have implemented a residual connection of the form\n",
        "    \n",
        "    \\begin{align*}\n",
        "    x \\mapsto x + f(x)\n",
        "    \\end{align*}\n",
        "    \n",
        "    where $f$ is a nonlinear function. The idea is that every layer is some adjustment of the identity function, which guards against vanishing gradients in a deep network during back propogation, especially at initialization.\n",
        "\n",
        "2. Prenorm via `LayerNorm`\n",
        "\n",
        "    Also in the `forward` method of the `TransformerBlock`, the nonlinearity first applied a `LayerNorm` to its arguments. The `LayerNorm` basically standardizes the activations in that layer so that they have mean 0 and variance 1. Doing so is very helpful for numerical stability, espeically of the gradients."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "hUDbIv9eISkf"
      },
      "outputs": [],
      "source": [
        "class TransformerBlock(nn.Module):\n",
        "    \"\"\" Transformer block: communication across sequence length, followed by communication across embedding space\n",
        "        Uses multi-headed attention\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, vocab_size, context_window_size, embed_size=384, num_heads=6):\n",
        "        super().__init__()\n",
        "        self.ln1 = nn.LayerNorm(embed_size)\n",
        "        self.ln2 = nn.LayerNorm(embed_size)\n",
        "\n",
        "        # TODO: your code below\n",
        "        self.feed_forward = FeedForward(embed_size)\n",
        "        self.atten_heads = MultiHeadAttention(context_window_size, num_heads, embed_size)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = x + self.atten_heads(self.ln1(x)) # communication over sequence length\n",
        "        x = x + self.feed_forward(self.ln2(x)) # communication across embedding space\n",
        "        return x"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vqCCiCYcKMD0"
      },
      "source": [
        "#### Question 1.4.2: Implement your baseline transformer model\n",
        "\n",
        "We now stack 6 `TransformerBlocks` (with a final layer norm applied after the blocks but before the logits) to create our basline `TransformerLM`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "t2veTg9N3ufJ"
      },
      "outputs": [],
      "source": [
        "class TransformerLM(nn.Module):\n",
        "\n",
        "    def __init__(self, vocab_size, context_window_size, embed_size=384, num_heads=6, n_layers=6):\n",
        "        \"\"\"\n",
        "          Args:\n",
        "              vocab_size: int, number of tokens in the vocabulary (V)\n",
        "              context_window_size: int, size of the context window (T)\n",
        "              embed_size: int, embedding size (D)\n",
        "              num_heads: int, number of heads (H)\n",
        "              n_layers: int, number of layers (M)\n",
        "        \"\"\"\n",
        "        super().__init__()\n",
        "        self.token_embedding_table = nn.Embedding(vocab_size, embed_size)\n",
        "        self.position_embedding_table = nn.Embedding(context_window_size, embed_size)\n",
        "        self.blocks = nn.Sequential(*[\n",
        "            TransformerBlock(vocab_size,\n",
        "                             context_window_size,\n",
        "                             embed_size=embed_size,\n",
        "                             num_heads=num_heads)\n",
        "            for _ in range(n_layers)])\n",
        "\n",
        "        # final layer norm\n",
        "        self.ln_f = nn.LayerNorm(embed_size)\n",
        "        self.lm_head = nn.Linear(embed_size, vocab_size)\n",
        "\n",
        "        # good initialization\n",
        "        self.apply(self._init_weights)\n",
        "\n",
        "    def _init_weights(self, module):\n",
        "        if isinstance(module, nn.Linear):\n",
        "            torch.nn.init.normal_(module.weight, mean=0.0, std=0.02)\n",
        "            if module.bias is not None:\n",
        "                torch.nn.init.zeros_(module.bias)\n",
        "        elif isinstance(module, nn.Embedding):\n",
        "            torch.nn.init.normal_(module.weight, mean=0.0, std=0.02)\n",
        "\n",
        "    def forward(self, token_ids, targets=None):\n",
        "        \"\"\"\n",
        "        Agrgs:\n",
        "            token_ids: tensor of integers, provides the contet, shape (B, T)\n",
        "            targets: tensor of integers, provides the tokens we are preidcitng, shape (B, T)\n",
        "        \"\"\"\n",
        "        B, T = token_ids.shape\n",
        "\n",
        "        # token_ids and targets are both (B, T) tensor of integers\n",
        "        tok_emb = self.token_embedding_table(token_ids) # (B, T, D)\n",
        "        pos_emb = self.position_embedding_table(torch.arange(T, device=device)) # (T, D)\n",
        "        x = tok_emb + pos_emb # (B, T, D)\n",
        "\n",
        "        # TODO: your code below\n",
        "        logits = ...\n",
        "        loss = ...\n",
        "\n",
        "        x = self.blocks(x)\n",
        "        x = self.ln_f(x)\n",
        "        logits = self.lm_head(x)\n",
        "\n",
        "        B, T, V = logits.shape\n",
        "        logits = logits.view(B*T, V)\n",
        "\n",
        "        if targets is None:\n",
        "            loss = None\n",
        "        else:\n",
        "            targets = targets.view(B*T)\n",
        "            loss = F.cross_entropy(logits, targets)\n",
        "\n",
        "        return logits, loss\n",
        "\n",
        "    @torch.no_grad()\n",
        "    def generate(self, token_ids, max_new_tokens):\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            token_ids: tensor of integers forming the context, shape (B, T)\n",
        "            max_new_tokens: int, max number of tokens to generate\n",
        "        \"\"\"\n",
        "        # TOOD, your code below\n",
        "        B, T = token_ids.shape\n",
        "        new_token_sequences = torch.zeros((B, T+max_new_tokens), dtype=torch.long, device=token_ids.device)\n",
        "        new_token_sequences[:, :T] = token_ids\n",
        "        for i in range(T, T+max_new_tokens):\n",
        "            pos_emb = self.position_embedding_table(torch.arange(T, device=device))\n",
        "            logits, loss = self(new_token_sequences[:, :i])\n",
        "            logits = logits.view(B, i, -1)\n",
        "            logits = logits[:, -1, :] # (B, V)\n",
        "            probs = F.softmax(logits, dim=-1) # (B, V)\n",
        "            new_token = torch.multinomial(probs, num_samples=1) # (B, 1)\n",
        "            new_token_sequences[:, i] = new_token.squeeze(-1) # (B, T+1)\n",
        "        return new_token_sequences"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JP8430nWKbZ6"
      },
      "source": [
        "Train your `TransformerLM` for `LARGE_ITERS` iterations and plot the loss curve. You may want to change the learning rate.\n",
        "\n",
        "We used a learning rate of `1e-4` and got to a final train loss of around 1.4 in around 15 minutes of training on a T4 GPU."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "jsnbDpdhLeKo",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "14ec852f-1d5b-450e-9973-2f6d3d601d62"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/10 [00:00<?, ?it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "iteration 0\n",
            "step 0: train loss 4.3102, val loss 4.3048\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 10/10 [00:07<00:00,  1.30it/s]\n"
          ]
        }
      ],
      "source": [
        "trans = TransformerLM(vocab_size, CONTEXT_WINDOW_SIZE)\n",
        "tlm = trans.to(device)\n",
        "learning_rate = 1e-4\n",
        "# TODO, your code below\n",
        "\n",
        "optimizer = torch.optim.AdamW(trans.parameters(), lr=learning_rate)\n",
        "\n",
        "eval_interval = 200\n",
        "\n",
        "loss_list = []\n",
        "\n",
        "for it in tqdm(range(10)):\n",
        "\n",
        "    # every once in a while evaluate the loss on train and val sets\n",
        "    if it % eval_interval == 0 or it == LARGE_ITERS - 1:\n",
        "      print(f\"iteration {it}\")\n",
        "      losses = estimate_loss(tlm, EVAL_ITERS, CONTEXT_WINDOW_SIZE, device)\n",
        "      print(f\"step {it}: train loss {losses['train']:.4f}, val loss {losses['val']:.4f}\")\n",
        "\n",
        "    # sample a batch of data\n",
        "    xb, yb = get_batch('train', CONTEXT_WINDOW_SIZE, device)\n",
        "\n",
        "    # evaluate the loss\n",
        "    logits, loss = tlm(xb, yb)\n",
        "    loss_list.append(loss.detach().item())\n",
        "    optimizer.zero_grad(set_to_none=True)\n",
        "    loss.backward()\n",
        "    optimizer.step()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## plot the loss_curve\n",
        "plt.plot(loss_list)\n",
        "plt.xlabel('Iteration')\n",
        "plt.ylabel('Loss')\n",
        "plt.title('Loss Curve')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "6-mnwj48rgMX",
        "outputId": "31a9cab5-f10c-45d4-d100-f32ffde8671c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 472
        }
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1SYG_iDFSNys"
      },
      "source": [
        "#### Question 1.4.3: Generating text!\n",
        "\n",
        "Now with our trained model, we can generate some text that is somewhat like the style of Shakespeare! Below we will do both unconditional and conditional generation."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "-FX-eEZEDH-n",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bb2ea732-244c-461a-fdd5-f765f75cf899"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "o 'ioOoKvHM\n",
            "t3.Et\n",
            "l hibAdmnolJ obOettaMpouet\n",
            "i Mf\n",
            "vr tooh,odnI 'D huCyWt WrZ  JE\n",
            "rmrVrru: x\n",
            "lI  lxsnKlDmon,auhrooetgou dlqLOV'utew bie yotofeelwtq tcoMtsF? u &em d\n",
            "enheb le'oy\n",
            "K\n",
            "z ,uobOs hi-isLKi eewocrrhe\n",
            "te  aqtecl\n",
            "iofsihhufniMfIee hn ijhie  ytbp.a h tt \n"
          ]
        }
      ],
      "source": [
        "# unconditional generation from the model\n",
        "start_context = torch.zeros((1, 1), dtype=torch.long, device=device)\n",
        "uncond_gen = (tlm.generate(start_context, max_new_tokens=CONTEXT_WINDOW_SIZE)[0].tolist())\n",
        "print(decode(uncond_gen))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "73du7-sWLH5c"
      },
      "outputs": [],
      "source": [
        "# conditional generation from the model\n",
        "\n",
        "context1 = \"\"\"ROMEO:\n",
        "He jests at scars that never felt a wound.\n",
        "But, soft! what light through yonder window breaks?\n",
        "It is the east, and Juliet is the sun.\n",
        "Arise, fair sun, and kill the envious moon,\n",
        "Who is already sick and pale with grief,\n",
        "That thou her maid art far more fair than she:\n",
        "Be not her maid, \"\"\"\n",
        "\n",
        "context1_tokens = torch.tensor(encode(context1), device=device).reshape(1, -1)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "context1_tokens.shape"
      ],
      "metadata": {
        "id": "vgc_GuNo45KJ",
        "outputId": "d99c4953-b957-4e62-8d08-d47544fa5fcb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([1, 290])"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "sZ4zkEJzMNA4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 375
        },
        "outputId": "4349d59b-b835-4000-b62e-960c8ef2efd0"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "CUDA error: device-side assert triggered\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-19-8456489a0510>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mcond_gen\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtlm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgenerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcontext1_tokens\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_new_tokens\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mCONTEXT_WINDOW_SIZE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcond_gen\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/utils/_contextlib.py\u001b[0m in \u001b[0;36mdecorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    114\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    115\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mctx_factory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 116\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    117\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    118\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-13-10bcc859015d>\u001b[0m in \u001b[0;36mgenerate\u001b[0;34m(self, token_ids, max_new_tokens)\u001b[0m\n\u001b[1;32m     80\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mT\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mmax_new_tokens\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     81\u001b[0m             \u001b[0mpos_emb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mposition_embedding_table\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 82\u001b[0;31m             \u001b[0mlogits\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew_token_sequences\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     83\u001b[0m             \u001b[0mlogits\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlogits\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mB\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     84\u001b[0m             \u001b[0mlogits\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlogits\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;31m# (B, V)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1735\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1736\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1737\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1745\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1746\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1748\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-13-10bcc859015d>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, token_ids, targets)\u001b[0m\n\u001b[1;32m     52\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m...\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 54\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mblocks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     55\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mln_f\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m         \u001b[0mlogits\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlm_head\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1735\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1736\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1737\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1745\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1746\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1748\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/container.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    248\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    249\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 250\u001b[0;31m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    251\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    252\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1735\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1736\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1737\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1745\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1746\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1748\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-12-1b8dc7e86289>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0matten_heads\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mln1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# communication over sequence length\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeed_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mln2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# communication across embedding space\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1735\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1736\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1737\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1745\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1746\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1748\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-11-b43382f78752>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1735\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1736\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1737\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1745\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1746\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1748\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/container.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    248\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    249\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 250\u001b[0;31m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    251\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    252\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1735\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1736\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1737\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1745\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1746\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1748\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/activation.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    131\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    132\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 133\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minplace\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minplace\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    134\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    135\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mrelu\u001b[0;34m(input, inplace)\u001b[0m\n\u001b[1;32m   1702\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1703\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1704\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1705\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1706\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: CUDA error: device-side assert triggered\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n"
          ]
        }
      ],
      "source": [
        "cond_gen = (tlm.generate(context1_tokens, max_new_tokens=CONTEXT_WINDOW_SIZE)[0].tolist())\n",
        "print(decode(cond_gen))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HdA0IXMh15cc"
      },
      "source": [
        "TODO: Choose your own context from Shakespeare, and perform conditional generation from that text. Does this look reasonable to you? Why or why not?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cR_0hrAO2Am_"
      },
      "outputs": [],
      "source": [
        "# TODO: your code here"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Caw-RM-J2Chj"
      },
      "source": [
        "---\n",
        "\n",
        "_your answer here_\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.cuda.empty_cache()"
      ],
      "metadata": {
        "id": "4z_QpV8a7lsL",
        "outputId": "8f512e7e-0ad7-4f16-c39a-e96528864fdb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 332
        }
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "CUDA error: device-side assert triggered\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-22-18bf08814031>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mempty_cache\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/cuda/memory.py\u001b[0m in \u001b[0;36mempty_cache\u001b[0;34m()\u001b[0m\n\u001b[1;32m    190\u001b[0m     \"\"\"\n\u001b[1;32m    191\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mis_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 192\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cuda_emptyCache\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    193\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    194\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: CUDA error: device-side assert triggered\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LgOzvWFDx_yH"
      },
      "source": [
        "#### Question 1.4.4\n",
        "\n",
        "The negative log-likelihood (averaged per token) we have been using to train our models can be expressed as\n",
        "\\begin{equation*}\n",
        "  L = -\\frac{1}{T} \\sum_{t = 1}^{T} \\log p(s[t] | \\text{context})\n",
        "\\end{equation*}\n",
        "for some document $s$, where $s[t]$ is the $t$th token of the doc. The natural language processing (NLP) community often reports the quantity\n",
        "\\begin{equation*}\n",
        "  \\text{perplexity} = \\exp(L).\n",
        "\\end{equation*}\n",
        "\n",
        "Give an intuitive interpretation of what perplexity is. Why might it be a more intuitive or natual measure to report than negative log-likelihood? Does the reported perplexity of your trained `TransformerLM` model make sense in terms of samples it generates? (Be sure to distinguish betwen `train` and `validation` perplexity. Which of `train` and `val` perplexity is more helpful for understanding your generated samples? Why?). (*Hint: your answer to Question 1.1.6 may be helpful*)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9Izr1wTOjzlo"
      },
      "source": [
        "## Part 2: Mini-Project"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5lF3jFrQj1f4"
      },
      "source": [
        "Quick recap: So far we have\n",
        "\n",
        "1. Preprocessed the Shakespeare dataset by encoding individual characters into integer tokens.\n",
        "2. Implemented single headed attention and then further generalized to multiheaded attention. We further combined multiheaded attention with deep learning to create the transformer architecture.\n",
        "3. Trained our transformer and generated output that looks to be in the style of Shakespeare.\n",
        "\n",
        "Up to this point, the performance of our simple language model has clearly made a lot of progress. We can see that our model has learned to generate text that is close to the style of Shakespeare, although there are still many quirks and room for improvement.\n",
        "\n",
        "### Project Outline\n",
        "\n",
        "Find some area of possible improvement.\n",
        "We interpret \"improvement\" quite loosely, but please state precisely why your proposed innovation might improve the model, and provide evidence that it does (or does not!) improve.\n",
        "For your idea, **formulate a hypothesis** for why this change should result in a better model. **Implement your changes** and **report any findings**.\n",
        "\n",
        "_Notes_: As this assignment is being treated as a project, you should expect training to take longer than previous assignments. However, please use your judgement to decide what is reasonable. We will not expect you to run training procedures that take more than 2 hours on the free Google Colab computing resources and we certainly do not expect you to acquire additional compute. The proposed improvements should not solely rely on increased computing demands.\n",
        "\n",
        "_Hints_: There are many aspects to assessing a model. For example, not only is quality of generated text important, it is also of interest to reduce costs associated with training.\n",
        "\n",
        "### Deliverables\n",
        "\n",
        "In addition to a pdf of your python notebook, the submission for this project will be a written report no more than 4 pages in length using the [NeurIPS LaTex template](https://neurips.cc/Conferences/2023/PaperInformation/StyleFiles). Your report should include detailed analysis of the hypotheses you chose to test along with any conclusions.\n",
        "\n",
        "The page limit for the report does not include bibliography or appendices. Make sure to keep the \"ready for submission\" option to help us grade anonymously. Your writeup should also contain a link to any code used to generate the project so that we can reference it while grading (Google Drive folder with colab notebooks or Github repo are both fine). You should have at least one plot in your main text (which is capped at 4 pages)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z7f7wY9I9jSF"
      },
      "source": [
        "## Submission Instructions\n",
        "\n",
        "You will generate two PDFs: one from Part 1, which involves completing this Colab to create a transformer baseline; and one from the mini-project in Part 2, which will be your write-up of no longer than 4 pages. Be sure to include a link to your code for Part 2 somewhere in your writeup.\n",
        "\n",
        "**Combine the two PDFs into a single PDF and submit on gradescope. Tag your PDF correctly.**\n",
        "\n",
        "If you work in a group of two, submit one assignment on gradescope and tag your group members. If you complete the assignment individually, submit as usual."
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "A100",
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.9"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}