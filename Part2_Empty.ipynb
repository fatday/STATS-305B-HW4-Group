{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/fatday/STATS-305B-HW4-Group/blob/main/Part2_Empty.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Part 1 Code Set up"
      ],
      "metadata": {
        "id": "2mw3nm5WWLGi"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_5IXGh6OOBZV"
      },
      "outputs": [],
      "source": [
        "# torch imports\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "from tqdm import tqdm\n",
        "import requests\n",
        "import os\n",
        "\n",
        "torch.manual_seed(305)\n",
        "\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fsgHl9JCuGBS"
      },
      "source": [
        "We set default values for some global hyperparameters, but feel free to change these during development as needed."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "A_Z5Jh74DH_E"
      },
      "outputs": [],
      "source": [
        "# Global hyperparameters\n",
        "SMALL_ITERS = 1000\n",
        "LARGE_ITERS = 2000\n",
        "EVAL_ITERS = 100\n",
        "CONTEXT_WINDOW_SIZE = 256"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lF6dgHnhOprg"
      },
      "source": [
        "## Part 0: Preprocessing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WF0_bhXNOxeS"
      },
      "source": [
        "### 0.1: Loading and preprocessing the dataset\n",
        "\n",
        "\n",
        "The first step is to download the dataset. We will be using a dataset from Andrej Karpathy consisting of a subset of works from Shakespeare.\n",
        "\n",
        "The dominant mode for preprocessing textual data is to tokenize it; that is, to split the dataset into a finite vocabulary of tokens. Then, we can set up a dictionaries mapping from counting numbers (representing tokens) to tokens and vice versa. Tokens can be characters, or words, or subwords; in fact, the \"best\" way to tokenize text is an active area of research.\n",
        "\n",
        "To keep things simple, we'll tokenize the text on a per-character level."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "53dGz7ExDkUv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a961db75-f59d-4b04-ae9b-f5a10fd8b471"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "length of dataset in characters: 1,115,394\n"
          ]
        }
      ],
      "source": [
        "# download the tiny shakespeare dataset\n",
        "input_file_path = 'input.txt'\n",
        "\n",
        "if not os.path.exists(input_file_path):\n",
        "    data_url = 'https://raw.githubusercontent.com/karpathy/char-rnn/master/data/tinyshakespeare/input.txt'\n",
        "    with open(input_file_path, 'w') as f:\n",
        "        f.write(requests.get(data_url).text)\n",
        "\n",
        "with open(input_file_path, 'r') as f:\n",
        "    data = f.read()\n",
        "print(f\"length of dataset in characters: {len(data):,}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "b2HuC2F9p_4K",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a2c9cd1a-d7d3-452a-b703-f7a47e6628d2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "all the unique characters: \n",
            " !$&',-.3:;?ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz\n",
            "vocab size: 65\n"
          ]
        }
      ],
      "source": [
        "# get all the unique characters that occur in this text\n",
        "chars = sorted(list(set(data)))\n",
        "vocab_size = len(chars)\n",
        "print(\"all the unique characters:\", ''.join(chars))\n",
        "print(f\"vocab size: {vocab_size:,}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JEWx5jnKqDzT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d197d728-ae8c-4cc5-c5bd-b66e83ca241a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train has 1,003,854 tokens\n",
            "val has 111,540 tokens\n"
          ]
        }
      ],
      "source": [
        "# create a mapping from characters to integers\n",
        "stoi = { ch:i for i,ch in enumerate(chars) }\n",
        "itos = { i:ch for i,ch in enumerate(chars) }\n",
        "\n",
        "def encode(s):\n",
        "    return [stoi[c] for c in s] # encoder: take a string, output a list of integers\n",
        "def decode(l):\n",
        "    return ''.join([itos[i] for i in l]) # decoder: take a list of integers, output a string\n",
        "\n",
        "# create the train and test splits\n",
        "n = len(data)\n",
        "train_chars = data[:int(n*0.9)]\n",
        "val_chars = data[int(n*0.9):]\n",
        "\n",
        "# encode both to integers\n",
        "train_data = encode(train_chars)\n",
        "val_data = encode(val_chars)\n",
        "\n",
        "# cast as torch tensors\n",
        "train_data = torch.tensor(train_data)\n",
        "val_data = torch.tensor(val_data)\n",
        "\n",
        "print(f\"train has {len(train_data):,} tokens\")\n",
        "print(f\"val has {len(val_data):,} tokens\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nsOs0_diEcjY"
      },
      "source": [
        "We also write helper functions to get batches of data and to evaluate the loss of various models on them."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AkAD0PfiEfjG"
      },
      "outputs": [],
      "source": [
        "# function for getting batches of data\n",
        "def get_batch(split, context_window_size, device, batch_size=32):\n",
        "    \"\"\"\n",
        "    generate a small batch of data of inputs x and targets y\n",
        "\n",
        "    Args:\n",
        "        split: 'train' or 'val'\n",
        "        device: 'cpu' or 'cuda' (should be 'cuda' if available)\n",
        "    \"\"\"\n",
        "    data = train_data if split == 'train' else val_data\n",
        "    ix = torch.randint(len(data) - context_window_size, (batch_size,))\n",
        "    x = torch.stack([data[i:i+context_window_size] for i in ix])\n",
        "    y = torch.stack([data[i+1:i+context_window_size+1] for i in ix])\n",
        "    x = x.to(device)\n",
        "    y = y.to(device)\n",
        "    return x, y\n",
        "\n",
        "# helper function for tracking loss during training\n",
        "# given to you\n",
        "@torch.no_grad()\n",
        "def estimate_loss(model, eval_iters, context_window_size, device):\n",
        "    \"\"\"\n",
        "    Args:\n",
        "      model: model being evaluated\n",
        "      eval_iters: number of batches to average over\n",
        "      context_window_size: size of the context window\n",
        "      device: 'cpu' or 'cuda' (should be 'cuda' if available)\n",
        "    \"\"\"\n",
        "    out = {}\n",
        "    for split in ['train', 'val']:\n",
        "        losses = torch.zeros(eval_iters)\n",
        "        for k in range(eval_iters):\n",
        "            X, Y = get_batch(split, context_window_size, device)\n",
        "            logits, loss = model(X, Y)\n",
        "            losses[k] = loss.item()\n",
        "        out[split] = losses.mean()\n",
        "    return out"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "O_eBPiT-Yy0q"
      },
      "outputs": [],
      "source": [
        "class Head(nn.Module):\n",
        "    \"\"\" one head of self-attention \"\"\"\n",
        "\n",
        "    def __init__(self, head_size, context_window_size, embed_size=384):\n",
        "        \"\"\"\n",
        "        Args:\n",
        "          head_size: int, size of the head embedding dimension (K)\n",
        "          context_window_size: int, number of tokens considered in the past for attention (T)\n",
        "          embed_size: int, size of the token embedding dimension (D)\n",
        "        \"\"\"\n",
        "        super().__init__()\n",
        "        self.head_size = head_size\n",
        "        self.key = nn.Linear(embed_size, head_size, bias=False)\n",
        "        self.query = nn.Linear(embed_size, head_size, bias=False)\n",
        "        self.value = nn.Linear(embed_size, embed_size, bias=False)\n",
        "\n",
        "        # not a param of the model, so registered as a buffer\n",
        "        self.register_buffer('tril', torch.tril(\n",
        "            torch.ones(context_window_size, context_window_size)))\n",
        "\n",
        "    def forward(self, x):\n",
        "        \"\"\"\n",
        "        Args:\n",
        "          x: (B,T,D) tensor of token embeddings\n",
        "\n",
        "        Returns:\n",
        "          (B,T,D) tensor of attention-weighted token embeddings\n",
        "        \"\"\"\n",
        "        # TODO: your code here\n",
        "        B,T,D = x.shape\n",
        "        k = self.key(x)\n",
        "        q = self.query(x)\n",
        "        v = self.value(x)\n",
        "        wei = q @ k.transpose(-2,-1) * self.head_size**-0.5\n",
        "        #tril = torch.tril(torch.ones(T, T, device=x.device))\n",
        "        wei = wei.masked_fill(self.tril[:T, :T] == 0, float('-inf'))\n",
        "        wei = F.softmax(wei, dim=-1)  ## wei.shape:\n",
        "        out = wei @ v\n",
        "        return out"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "REr3aWnS1xJL"
      },
      "outputs": [],
      "source": [
        "class SingleHeadedAttentionLM(nn.Module):\n",
        "\n",
        "    def __init__(self, vocab_size, context_window_size, head_size, embed_size=384):\n",
        "      \"\"\"\n",
        "      Args:\n",
        "        vocab_size: int, size of the vocabulary (V)\n",
        "        context_window_size: int, number of tokens considered in the past for attention (T)\n",
        "        head_size: int, size of the head embedding dimension (K)\n",
        "        embed_size: int, size of the token embedding dimension (D)\n",
        "      \"\"\"\n",
        "      super().__init__()\n",
        "      self.token_embedding_table = nn.Embedding(vocab_size, embed_size)\n",
        "      self.position_embedding_table = nn.Embedding(context_window_size, embed_size)\n",
        "      self.context_window_size = context_window_size\n",
        "\n",
        "      # TODO: your code below\n",
        "      self.atten_head = Head(head_size, context_window_size)\n",
        "      self.lm_head = nn.Linear(embed_size, vocab_size)\n",
        "      self.context_window_size = context_window_size\n",
        "\n",
        "    def forward(self, token_ids, targets=None):\n",
        "        \"\"\"\n",
        "        Args:\n",
        "          token_ids: (B, T) token ids that make up the context (batch has size B, each entry\n",
        "                     in the batch has length T)\n",
        "          targets: (B, T) token ids corresponding to the target of each context in token_ids\n",
        "\n",
        "        Returns:\n",
        "          logits: (B, T, V) logits[b,t] gives the length V vector of logits for the next token\n",
        "                   prediction in string b up to t tokens\n",
        "          loss: scalar, negative log likelihood of target given context\n",
        "        \"\"\"\n",
        "        B, T = token_ids.shape # (batch size, length)\n",
        "        tok_emb = self.token_embedding_table(token_ids) # (B,T,D)\n",
        "        pos_emb = self.position_embedding_table(torch.arange(T, device=device)) # (T,D)\n",
        "        x = tok_emb + pos_emb # (B,T,D)\n",
        "        x = self.atten_head(x) # (B,T,D)\n",
        "        logits = self.lm_head(x) # (B,T,V)\n",
        "\n",
        "        # TODO: your code here\n",
        "        B, T, V = logits.shape\n",
        "        logits = logits.view(B*T, V)\n",
        "        if targets is None:\n",
        "            loss = None\n",
        "        else:\n",
        "            targets = targets.view(B*T)\n",
        "            loss = -torch.mean(torch.log(F.softmax(logits, dim=1)[torch.arange(B*T), targets]))\n",
        "        return logits, loss\n",
        "\n",
        "    @torch.no_grad()\n",
        "    def generate(self, token_ids, max_new_tokens):\n",
        "        \"\"\"\n",
        "        Args:\n",
        "          token_ids: (B, T) tensor of token ids to provide as context\n",
        "          max_new_tokens: int, maximum number of new tokens to generate\n",
        "\n",
        "        Returns:\n",
        "          (B, T+max_new_tokens) tensor of context with new tokens appended\n",
        "        \"\"\"\n",
        "        #TODO\n",
        "        # your code below\n",
        "        B, T = token_ids.shape\n",
        "        new_token_sequences = torch.zeros((B, T+max_new_tokens), dtype=torch.long, device=token_ids.device)\n",
        "        new_token_sequences[:, :T] = token_ids\n",
        "        for t in range(max_new_tokens):\n",
        "          input_tokens = new_token_sequences[:, max(0, T + t - self.context_window_size): T + t]\n",
        "          logits, loss = self(input_tokens)\n",
        "          logits = logits.view(B, min(T + t, self.context_window_size), -1)\n",
        "          logits = logits[:, -1, :]\n",
        "          probs = F.softmax(logits, dim=-1)\n",
        "          new_token = torch.multinomial(probs, num_samples=1)\n",
        "          new_token_sequences[:, T + t] = new_token.squeeze(-1)\n",
        "        return new_token_sequences"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6vb8NU_s6Vfg"
      },
      "outputs": [],
      "source": [
        "\n",
        "class MultiHeadAttention(nn.Module):\n",
        "    def __init__(self, context_window_size, num_heads, embed_size):\n",
        "        super().__init__()\n",
        "        self.num_heads = num_heads\n",
        "        self.head_size = embed_size // num_heads  # 确保总维度匹配\n",
        "\n",
        "        self.heads = nn.ModuleList(\n",
        "            [Head(self.head_size, context_window_size, embed_size) for _ in range(num_heads)]\n",
        "        )\n",
        "        self.proj = nn.Linear(embed_size * num_heads, embed_size)  # 确保总维度匹配\n",
        "        self.dropout = nn.Dropout(0.1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = torch.cat([h(x) for h in self.heads], dim=-1)  # 拼接 heads\n",
        "\n",
        "        out = self.dropout(self.proj(out))  # 投影回 embed_size\n",
        "        return out\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LvWHwcCzI1yr"
      },
      "outputs": [],
      "source": [
        "class MultiHeadedAttentionLM(nn.Module):\n",
        "\n",
        "    def __init__(self, vocab_size, context_window_size, embed_size=384, num_heads=6):\n",
        "      super().__init__()\n",
        "      self.head_size = embed_size // num_heads\n",
        "      self.context_window_size = context_window_size\n",
        "      # TODO: your code below\n",
        "      self.token_embedding_table = nn.Embedding(vocab_size, embed_size)\n",
        "      self.position_embedding_table = nn.Embedding(context_window_size, embed_size)\n",
        "      self.atten_heads = MultiHeadAttention(context_window_size, num_heads, embed_size)\n",
        "      self.lm_head = nn.Linear(embed_size, vocab_size)\n",
        "\n",
        "\n",
        "    def forward(self, token_ids, targets=None):\n",
        "        \"\"\"\n",
        "        Args:\n",
        "          token_ids: (B, T) token ids that make up the context (batch has size B, each entry in the\n",
        "                     batch has length T)\n",
        "          targets: (B, T) token ids corresponding to the target of each context in token_ids\n",
        "\n",
        "        Returns:\n",
        "          logits: (B, T, V), logits[b,t] gives the length V vector of logits for the next token\n",
        "                  prediction in string b up to t tokens\n",
        "          loss: scalar, negative log likelihood of target given context\n",
        "        \"\"\"\n",
        "        # TODO: your code below\n",
        "        B, T = token_ids.shape\n",
        "        tok_emb = self.token_embedding_table(token_ids)\n",
        "        pos_emb = self.position_embedding_table(torch.arange(T, device=device))\n",
        "        x = tok_emb + pos_emb\n",
        "        x = self.atten_heads(x)\n",
        "        logits = self.lm_head(x)\n",
        "        if targets is None:\n",
        "            loss = None\n",
        "        else:\n",
        "            logits = logits.view(B*T, -1)\n",
        "            targets = targets.view(B*T)\n",
        "            loss = -torch.mean(torch.log(F.softmax(logits, dim=1)[torch.arange(B*T), targets]))\n",
        "\n",
        "        return logits, loss\n",
        "\n",
        "    @torch.no_grad()\n",
        "    def generate(self, token_ids, max_new_tokens):\n",
        "        \"\"\"\n",
        "        Args:\n",
        "          token_ids: (B, T) tensor of token ids to provide as context\n",
        "          max_new_tokens: int, maximum number of new tokens to generate\n",
        "\n",
        "        Returns:\n",
        "          (B, T+max_new_tokens) tensor of context with new tokens appended\n",
        "        \"\"\"\n",
        "        # TODO: your code below\n",
        "        B, T = token_ids.shape\n",
        "        new_token_sequences = torch.zeros((B, T+max_new_tokens), dtype=torch.long, device=token_ids.device)\n",
        "        new_token_sequences[:, :T] = token_ids\n",
        "        for t in range(max_new_tokens):\n",
        "          input_tokens = new_token_sequences[:, max(0, T + t - self.context_window_size): T + t]\n",
        "          logits, loss = self(input_tokens)\n",
        "          logits = logits.view(B,min(T + t, self.context_window_size), -1)\n",
        "          logits = logits[:, -1, :]\n",
        "          probs = F.softmax(logits, dim=-1)\n",
        "          new_token = torch.multinomial(probs, num_samples=1)\n",
        "          new_token_sequences[:, T + t] = new_token.squeeze(-1)\n",
        "        return new_token_sequences"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1GbGqwKWJzOK"
      },
      "outputs": [],
      "source": [
        "# run this cell to initialize this deep learning module that you should use in the code your write later\n",
        "# you don't need to edit this layer\n",
        "class FeedForward(nn.Module):\n",
        "    \"\"\" a simple linear layer followed by a non-linearity\n",
        "        Given to you, you don't need to write any code here!\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, embed_size):\n",
        "        super().__init__()\n",
        "        self.net = nn.Sequential(\n",
        "            nn.Linear(embed_size, 4 * embed_size),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(4 * embed_size, embed_size),\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.net(x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hUDbIv9eISkf"
      },
      "outputs": [],
      "source": [
        "class TransformerBlock(nn.Module):\n",
        "    \"\"\" Transformer block: communication across sequence length, followed by communication across embedding space\n",
        "        Uses multi-headed attention\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, vocab_size, context_window_size, embed_size=384, num_heads=6):\n",
        "        super().__init__()\n",
        "        self.ln1 = nn.LayerNorm(embed_size)\n",
        "        self.ln2 = nn.LayerNorm(embed_size)\n",
        "\n",
        "        # TODO: your code below\n",
        "        self.feed_forward = FeedForward(embed_size)\n",
        "        self.atten_heads = MultiHeadAttention(context_window_size, num_heads, embed_size)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = x + self.atten_heads(self.ln1(x)) # communication over sequence length\n",
        "        x = x + self.feed_forward(self.ln2(x)) # communication across embedding space\n",
        "        return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "t2veTg9N3ufJ"
      },
      "outputs": [],
      "source": [
        "class TransformerLM(nn.Module):\n",
        "\n",
        "    def __init__(self, vocab_size, context_window_size, embed_size=384, num_heads=6, n_layers=6):\n",
        "        \"\"\"\n",
        "          Args:\n",
        "              vocab_size: int, number of tokens in the vocabulary (V)\n",
        "              context_window_size: int, size of the context window (T)\n",
        "              embed_size: int, embedding size (D)\n",
        "              num_heads: int, number of heads (H)\n",
        "              n_layers: int, number of layers (M)\n",
        "        \"\"\"\n",
        "        super().__init__()\n",
        "        self.token_embedding_table = nn.Embedding(vocab_size, embed_size)\n",
        "        self.position_embedding_table = nn.Embedding(context_window_size, embed_size)\n",
        "        self.blocks = nn.Sequential(*[\n",
        "            TransformerBlock(vocab_size,\n",
        "                             context_window_size,\n",
        "                             embed_size=embed_size,\n",
        "                             num_heads=num_heads)\n",
        "            for _ in range(n_layers)])\n",
        "\n",
        "        # final layer norm\n",
        "        self.ln_f = nn.LayerNorm(embed_size)\n",
        "        self.lm_head = nn.Linear(embed_size, vocab_size)\n",
        "        self.context_window_size = context_window_size\n",
        "\n",
        "        # good initialization\n",
        "        self.apply(self._init_weights)\n",
        "\n",
        "    def _init_weights(self, module):\n",
        "        if isinstance(module, nn.Linear):\n",
        "            torch.nn.init.normal_(module.weight, mean=0.0, std=0.02)\n",
        "            if module.bias is not None:\n",
        "                torch.nn.init.zeros_(module.bias)\n",
        "        elif isinstance(module, nn.Embedding):\n",
        "            torch.nn.init.normal_(module.weight, mean=0.0, std=0.02)\n",
        "\n",
        "    def forward(self, token_ids, targets=None):\n",
        "        \"\"\"\n",
        "        Agrgs:\n",
        "            token_ids: tensor of integers, provides the contet, shape (B, T)\n",
        "            targets: tensor of integers, provides the tokens we are preidcitng, shape (B, T)\n",
        "        \"\"\"\n",
        "        B, T = token_ids.shape\n",
        "\n",
        "        # token_ids and targets are both (B, T) tensor of integers\n",
        "        tok_emb = self.token_embedding_table(token_ids) # (B, T, D)\n",
        "        pos_emb = self.position_embedding_table(torch.arange(T, device=device)) # (T, D)\n",
        "        x = tok_emb + pos_emb # (B, T, D)\n",
        "\n",
        "        # TODO: your code below\n",
        "        logits = ...\n",
        "        loss = ...\n",
        "\n",
        "        x = self.blocks(x)\n",
        "        x = self.ln_f(x)\n",
        "        logits = self.lm_head(x)\n",
        "\n",
        "        B, T, V = logits.shape\n",
        "        logits = logits.view(B*T, V)\n",
        "\n",
        "        if targets is None:\n",
        "            loss = None\n",
        "        else:\n",
        "            targets = targets.view(B*T)\n",
        "            loss = F.cross_entropy(logits, targets)\n",
        "\n",
        "        return logits, loss\n",
        "\n",
        "    @torch.no_grad()\n",
        "    def generate(self, token_ids, max_new_tokens):\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            token_ids: tensor of integers forming the context, shape (B, T)\n",
        "            max_new_tokens: int, max number of tokens to generate\n",
        "        \"\"\"\n",
        "        # TOOD, your code below\n",
        "        B, T = token_ids.shape\n",
        "        context_length = self.position_embedding_table.num_embeddings\n",
        "        new_token_sequences = torch.zeros((B, T+max_new_tokens), dtype=torch.long, device=token_ids.device)\n",
        "        new_token_sequences[:, :T] = token_ids\n",
        "        for t in range(max_new_tokens):\n",
        "            input_tokens = new_token_sequences[:, max(0,T + t - context_length):T + t]\n",
        "            logits, loss = self(input_tokens)\n",
        "            logits = logits.view(B,min(T + t, self.context_window_size), -1)\n",
        "            logits = logits[:, -1, :] # (B, V)\n",
        "            probs = F.softmax(logits, dim=-1) # (B, V)\n",
        "            new_token = torch.multinomial(probs, num_samples=1) # (B, 1)\n",
        "            new_token_sequences[:, T + t] = new_token.squeeze(-1) # (B, T+1)\n",
        "        return new_token_sequences"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jsnbDpdhLeKo",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7c21ab28-6bfe-49b6-9658-5c725881637d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/2000 [00:00<?, ?it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "iteration 0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 1/2000 [00:06<3:34:34,  6.44s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "step 0: train loss 4.2866, val loss 4.2850\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 10%|▉         | 199/2000 [00:25<02:50, 10.54it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "iteration 200\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 10%|█         | 201/2000 [00:31<31:15,  1.04s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "step 200: train loss 2.4913, val loss 2.5005\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 20%|█▉        | 399/2000 [00:50<02:31, 10.56it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "iteration 400\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 20%|██        | 401/2000 [00:56<27:43,  1.04s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "step 400: train loss 2.3444, val loss 2.3695\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 30%|██▉       | 599/2000 [01:15<02:12, 10.54it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "iteration 600\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 30%|███       | 601/2000 [01:22<24:15,  1.04s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "step 600: train loss 2.1089, val loss 2.1561\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 40%|███▉      | 799/2000 [01:40<01:53, 10.55it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "iteration 800\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 40%|████      | 801/2000 [01:47<20:46,  1.04s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "step 800: train loss 1.9199, val loss 2.0153\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 50%|████▉     | 999/2000 [02:06<01:35, 10.54it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "iteration 1000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 50%|█████     | 1001/2000 [02:12<17:19,  1.04s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "step 1000: train loss 1.7761, val loss 1.9142\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 60%|█████▉    | 1199/2000 [02:31<01:15, 10.54it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "iteration 1200\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 60%|██████    | 1201/2000 [02:37<13:51,  1.04s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "step 1200: train loss 1.6817, val loss 1.8326\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 70%|██████▉   | 1399/2000 [02:56<00:56, 10.59it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "iteration 1400\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 70%|███████   | 1401/2000 [03:03<10:23,  1.04s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "step 1400: train loss 1.6039, val loss 1.7801\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 80%|███████▉  | 1599/2000 [03:22<00:38, 10.53it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "iteration 1600\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 80%|████████  | 1601/2000 [03:28<06:55,  1.04s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "step 1600: train loss 1.5552, val loss 1.7327\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 90%|████████▉ | 1799/2000 [03:47<00:19, 10.55it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "iteration 1800\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 90%|█████████ | 1801/2000 [03:53<03:27,  1.04s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "step 1800: train loss 1.5017, val loss 1.7037\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|█████████▉| 1999/2000 [04:12<00:00, 10.54it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "iteration 1999\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r100%|██████████| 2000/2000 [04:18<00:00,  7.72it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "step 1999: train loss 1.4703, val loss 1.6787\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "trans = TransformerLM(vocab_size, CONTEXT_WINDOW_SIZE)\n",
        "tlm = trans.to(device)\n",
        "learning_rate = 1e-4\n",
        "# TODO, your code below\n",
        "\n",
        "optimizer = torch.optim.AdamW(trans.parameters(), lr=learning_rate)\n",
        "\n",
        "eval_interval = 200\n",
        "\n",
        "loss_list = []\n",
        "\n",
        "for it in tqdm(range(LARGE_ITERS)):\n",
        "\n",
        "    # every once in a while evaluate the loss on train and val sets\n",
        "    if it % eval_interval == 0 or it == LARGE_ITERS - 1:\n",
        "      print(f\"iteration {it}\")\n",
        "      losses = estimate_loss(tlm, EVAL_ITERS, CONTEXT_WINDOW_SIZE, device)\n",
        "      print(f\"step {it}: train loss {losses['train']:.4f}, val loss {losses['val']:.4f}\")\n",
        "\n",
        "    # sample a batch of data\n",
        "    xb, yb = get_batch('train', CONTEXT_WINDOW_SIZE, device)\n",
        "\n",
        "    # evaluate the loss\n",
        "    logits, loss = tlm(xb, yb)\n",
        "    loss_list.append(loss.detach().item())\n",
        "    optimizer.zero_grad(set_to_none=True)\n",
        "    loss.backward()\n",
        "    optimizer.step()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## plot the loss_curve\n",
        "plt.plot(loss_list)\n",
        "plt.xlabel('Iteration')\n",
        "plt.ylabel('Loss')\n",
        "plt.title('Loss Curve')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "6-mnwj48rgMX",
        "outputId": "776ce9cd-f6f9-4574-ddd3-a99a9c2dfbb5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 472
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1SYG_iDFSNys"
      },
      "source": [
        "#### Question 1.4.3: Generating text!\n",
        "\n",
        "Now with our trained model, we can generate some text that is somewhat like the style of Shakespeare! Below we will do both unconditional and conditional generation."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-FX-eEZEDH-n",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "778d453b-c3c4-4f49-9f8d-d68696bbec92"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Noriser:\n",
            "I'll not nime semmbatrous hath a marry.\n",
            "\n",
            "YORK:\n",
            "How nor, before hertefore how them to-mar3 morraw,\n",
            "Go talk three, 'etime king; wherein for the love thee\n",
            "More Henry and for much for here er swavey ar;\n",
            "And him wall forcUp me and their was they daught\n"
          ]
        }
      ],
      "source": [
        "# unconditional generation from the model\n",
        "start_context = torch.zeros((1, 1), dtype=torch.long, device=device)\n",
        "uncond_gen = (tlm.generate(start_context, max_new_tokens=CONTEXT_WINDOW_SIZE)[0].tolist())\n",
        "print(decode(uncond_gen))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "73du7-sWLH5c"
      },
      "outputs": [],
      "source": [
        "# conditional generation from the model\n",
        "\n",
        "context1 = \"\"\"ROMEO:\n",
        "He jests at scars that never felt a wound.\n",
        "But, soft! what light through yonder window breaks?\n",
        "It is the east, and Juliet is the sun.\n",
        "Arise, fair sun, and kill the envious moon,\n",
        "Who is already sick and pale with grief,\n",
        "That thou her maid art far more fair than she:\n",
        "Be not her maid, \"\"\"\n",
        "\n",
        "context1_tokens = torch.tensor(encode(context1), device=device).reshape(1, -1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sZ4zkEJzMNA4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3105658e-1859-4f8c-a287-5b2f68c5200a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ROMEO:\n",
            "He jests at scars that never felt a wound.\n",
            "But, soft! what light through yonder window breaks?\n",
            "It is the east, and Juliet is the sun.\n",
            "Arise, fair sun, and kill the envious moon,\n",
            "Who is already sick and pale with grief,\n",
            "That thou her maid art far more fair than she:\n",
            "Be not her maid, and the each wret of die ill serving un,\n",
            "Buoh his soverer shall the with not these ustood,\n",
            "To his grace us pousal comfort usuJuesues,\n",
            "But mode.\n",
            "\n",
            "ANTIUS:\n",
            "Is ever were word so chiecave of a doom to the sitter,\n",
            "Be a reames and look of all meance.\n",
            "Think you wi\n"
          ]
        }
      ],
      "source": [
        "cond_gen = (tlm.generate(context1_tokens, max_new_tokens=CONTEXT_WINDOW_SIZE)[0].tolist())\n",
        "print(decode(cond_gen))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HdA0IXMh15cc"
      },
      "source": [
        "TODO: Choose your own context from Shakespeare, and perform conditional generation from that text. Does this look reasonable to you? Why or why not?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cR_0hrAO2Am_"
      },
      "outputs": [],
      "source": [
        "# TODO: your code here\n",
        "my_text_con = \"\"\"First Citizen:\n",
        "Care for us! True, indeed! They ne'er cared for us\n",
        "yet: suffer us to famish, and their store-houses\n",
        "crammed with grain; make edicts for usury, to\n",
        "support usurers; repeal daily any wholesome act\n",
        "established against the rich, and provide more\n",
        "piercing statutes daily, to chain up and restrain\n",
        "the poor. If the wars eat us not up, they will; and\n",
        "there's all the love they bear us.\n",
        "\n",
        "MENENIUS: Either you must\n",
        "\"\"\"\n",
        "\n",
        "my_text_target = \"\"\"Confess yourselves wondrous malicious,\n",
        "Or be accused of folly. I shall tell you\n",
        "A pretty tale: it may be you have heard it;\n",
        "But, since it serves my purpose, I will venture\n",
        "To stale 't a little more.\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cond_text_token = encode(my_text_con)\n",
        "target_text_token = encode(my_text_target)\n",
        "\n",
        "# transfer back to text\n",
        "target_text_token_size = len(target_text_token)\n",
        "cond_text_token_size = len(cond_text_token)\n",
        "\n",
        "# transfer to torch\n",
        "cond_text_tokens = torch.tensor(cond_text_token, device=device).reshape(1, -1)"
      ],
      "metadata": {
        "id": "w1I9p9MalOnZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# My Input Text:"
      ],
      "metadata": {
        "id": "5-886_tYpf39"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(my_text_con)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xcoJe3v3ptnX",
        "outputId": "f2dcb4c1-f393-4bcf-d94c-01079391faf6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "First Citizen:\n",
            "Care for us! True, indeed! They ne'er cared for us\n",
            "yet: suffer us to famish, and their store-houses\n",
            "crammed with grain; make edicts for usury, to\n",
            "support usurers; repeal daily any wholesome act\n",
            "established against the rich, and provide more\n",
            "piercing statutes daily, to chain up and restrain\n",
            "the poor. If the wars eat us not up, they will; and\n",
            "there's all the love they bear us.\n",
            "\n",
            "MENENIUS: Either you must \n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Target Text"
      ],
      "metadata": {
        "id": "kmlyABuinXhQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(my_text_target)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6Zqtb7zinayj",
        "outputId": "37eb9cbf-f95c-4aef-d088-7d05c84f6f56"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Confess yourselves wondrous malicious,\n",
            "Or be accused of folly. I shall tell you\n",
            "A pretty tale: it may be you have heard it;\n",
            "But, since it serves my purpose, I will venture\n",
            "To stale 't a little more.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Text Generated for Target"
      ],
      "metadata": {
        "id": "6Iy5f84FsCwv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "my_tar_gen = (tlm.generate(cond_text_tokens, max_new_tokens=target_text_token_size)[0].tolist())\n",
        "my_target_gen_text = decode(my_tar_gen)[cond_text_token_size:]\n",
        "print(my_target_gen_text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CL5AG4ddlx2U",
        "outputId": "ec4da557-3a1a-4ae5-f1f2-b6d2f539baa4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "she creates of the holy subselTt you har:\n",
            "brow tidle I say you part.  Cammild, prit, not me if\n",
            "the grave behave again as I have: there you dut ruth,\n",
            "and for citie know of young! as if your father,\n",
            "M\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9Izr1wTOjzlo"
      },
      "source": [
        "## Part 2: Mini-Project"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5lF3jFrQj1f4"
      },
      "source": [
        "Quick recap: So far we have\n",
        "\n",
        "1. Preprocessed the Shakespeare dataset by encoding individual characters into integer tokens.\n",
        "2. Implemented single headed attention and then further generalized to multiheaded attention. We further combined multiheaded attention with deep learning to create the transformer architecture.\n",
        "3. Trained our transformer and generated output that looks to be in the style of Shakespeare.\n",
        "\n",
        "Up to this point, the performance of our simple language model has clearly made a lot of progress. We can see that our model has learned to generate text that is close to the style of Shakespeare, although there are still many quirks and room for improvement.\n",
        "\n",
        "### Project Outline\n",
        "\n",
        "Find some area of possible improvement.\n",
        "We interpret \"improvement\" quite loosely, but please state precisely why your proposed innovation might improve the model, and provide evidence that it does (or does not!) improve.\n",
        "For your idea, **formulate a hypothesis** for why this change should result in a better model. **Implement your changes** and **report any findings**.\n",
        "\n",
        "_Notes_: As this assignment is being treated as a project, you should expect training to take longer than previous assignments. However, please use your judgement to decide what is reasonable. We will not expect you to run training procedures that take more than 2 hours on the free Google Colab computing resources and we certainly do not expect you to acquire additional compute. The proposed improvements should not solely rely on increased computing demands.\n",
        "\n",
        "_Hints_: There are many aspects to assessing a model. For example, not only is quality of generated text important, it is also of interest to reduce costs associated with training.\n",
        "\n",
        "### Deliverables\n",
        "\n",
        "In addition to a pdf of your python notebook, the submission for this project will be a written report no more than 4 pages in length using the [NeurIPS LaTex template](https://neurips.cc/Conferences/2023/PaperInformation/StyleFiles). Your report should include detailed analysis of the hypotheses you chose to test along with any conclusions.\n",
        "\n",
        "The page limit for the report does not include bibliography or appendices. Make sure to keep the \"ready for submission\" option to help us grade anonymously. Your writeup should also contain a link to any code used to generate the project so that we can reference it while grading (Google Drive folder with colab notebooks or Github repo are both fine). You should have at least one plot in your main text (which is capped at 4 pages)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z7f7wY9I9jSF"
      },
      "source": [
        "## Submission Instructions\n",
        "\n",
        "You will generate two PDFs: one from Part 1, which involves completing this Colab to create a transformer baseline; and one from the mini-project in Part 2, which will be your write-up of no longer than 4 pages. Be sure to include a link to your code for Part 2 somewhere in your writeup.\n",
        "\n",
        "**Combine the two PDFs into a single PDF and submit on gradescope. Tag your PDF correctly.**\n",
        "\n",
        "If you work in a group of two, submit one assignment on gradescope and tag your group members. If you complete the assignment individually, submit as usual."
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}